{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import unicodedata\n",
    "import csv\n",
    "import itertools\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from nltk import word_tokenize, sent_tokenize, pos_tag, corpus\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import defaultdict, Counter\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the datasets\n",
    "df_directions = pd.read_excel('/Users/nessyliu/Desktop/RA/AllRecipes_Directions_2019-11-26.xlsx')\n",
    "df = pd.read_csv('/Users/nessyliu/Desktop/RA/AllReviews_26thNov2019.csv')\n",
    "df_ingredients_raw = pd.read_csv('/Users/nessyliu/Desktop/RA/part_2/Ingredients.csv')\n",
    "df_cluster = pd.read_excel('/Users/nessyliu/Desktop/RA/part_2/Cluster_names.xlsx')\n",
    "\n",
    "df_ingre_clean = pd.read_csv('/Users/nessyliu/Desktop/RA/part_2/ingredients_after_text_cleaning.csv')\n",
    "df_mod = pd.read_excel('/Users/nessyliu/Desktop/RA/part_2/Final_clusters_mod.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_directions_list = []\n",
    "recipe_id_list = list(set(df_directions.recipe_id.tolist()))\n",
    "for recipe_id in recipe_id_list:\n",
    "    full_dir_this_recipe = ' '.join(df_directions.loc[df_directions['recipe_id']==recipe_id, 'directions_step_text'])\n",
    "    full_directions_list.append(full_dir_this_recipe)\n",
    "dict_recipe_direction = dict(zip(recipe_id_list, full_directions_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of cluster names with spaces (e.g. apple juice) sorted by number of words in each name, \n",
    "# e.g. \"apple juice\" should appear before \"juice\"\n",
    "cluster_name_orig_list = df_cluster.cluster_name.tolist()\n",
    "cluster_name_orig_list.sort(key=lambda x: len(x.split()), reverse=True)\n",
    "\n",
    "# create dict to map recipe_id to ingredient_ids\n",
    "df_ingredients = df_ingredients_raw.groupby('recipe_id')['ingredient_id'].apply(list).reset_index(name ='ingredients')\n",
    "dict_recipe_ingredients = dict(zip(df_ingredients.recipe_id, df_ingredients.ingredients))\n",
    "\n",
    "# create dict to map ingredient_id to cluster_name\n",
    "df_cluster = df_cluster.replace(' ', '_', regex=True)\n",
    "dict_ingredient_clustername = dict(zip(df_cluster.ingredient_id, df_cluster.cluster_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatization dict\n",
    "lemma_list = pd.read_csv('/Users/nessyliu/Desktop/RA/lemma_list.csv')\n",
    "lemma_dict = lemma_list.set_index('word_list').to_dict()['lemma_list']\n",
    "\n",
    "# list of words that are forced not to lemmatize, those are the words appearing in cluster names\n",
    "force_keep_list = ['corned', 'sparkling', 'canning', 'roasted', 'baked', 'processed', 'flavored', \n",
    "                   'colored', 'candied', 'stuffing', 'dressing', 'shortening', \"pig's\", 'based',\n",
    "                   'stewed', 'curing', 'decorating', 'coated', 'evaporated', 'pickled', 'fried',\n",
    "                   'dripping', 'rising', \"confectioners'\", 'frying', 'coating', 'smoked', 'seasoned',\n",
    "                   'rolled', 'filling', \"devil's\", 'sweetened', 'dried', 'pickling', 'topping', 'frosting',\n",
    "                   'coloring', 'rose', 'pulled', 'crystallized', 'seasoning', 'whipped', 'condensed','baking',\n",
    "                  'frenchfries', 'fries', 'flavoring']\n",
    "\n",
    "def lemmatization(text):\n",
    "    \n",
    "    text = text.lower()\n",
    "    \n",
    "    text = text.replace('-n-', ' and ')\n",
    "    text = text.replace(' & ', ' and ')\n",
    "    text = text.replace('&', ' and ')\n",
    "    text = text.replace('-', ' ')\n",
    "    \n",
    "    text = text.replace('sugar substitute', 'sweetener').replace('french fries','frenchfries')\n",
    "    \n",
    "    text = text.replace('dry milk', 'milk powder').replace('powder milk', 'milk powder')\n",
    "    \n",
    "    text = text.replace('lowfat',\n",
    "                        'low fat').replace('nonfat',\n",
    "                                                    'non fat').replace('glutenfree',\n",
    "                                                                       'gluten free').replace('corn flakes',\n",
    "                                                                                              'cornflakes')\n",
    "    text = text.replace('flaxseed',\n",
    "                        'flax seed').replace('lemongrass', 'lemon grass')\n",
    "    \n",
    "    text = text.replace('coconutmilk',\n",
    "                        'coconut milk').replace('almondmilk',\n",
    "                                                'almond milk').replace('crab meat',\n",
    "                                                                       'crabmeat').replace('starfruit', \n",
    "                                                                                           'star fruit').replace('breadcrumb', \n",
    "                                                                                                                 'bread crumb')\n",
    "    text = text.replace('red and yellow bell pepper', \n",
    "                        'red bell pepper and yellow bell pepper').replace('red and green bell pepper', \n",
    "                                                                          'red bell pepper and green bell pepper')\n",
    "\n",
    "    # use the custom lemma dict first\n",
    "    text = \" \".join(str(lemma_dict.get(word, word)) for word in text.split())\n",
    "    \n",
    "    # then use the WordNetLemmatizer from nltk\n",
    "    wnl = WordNetLemmatizer()\n",
    "    \n",
    "    word_list = word_tokenize(text)\n",
    "    word_list_after = []\n",
    "    \n",
    "    for word in word_list:\n",
    "        # word by word (otherwise tag may differ), lemmatize each word based on its pos tagging, exclude words in force keep list\n",
    "        w,t = pos_tag([word])[0]\n",
    "        if t[0].lower() in ['a','n','v'] and word not in force_keep_list:\n",
    "            word = wnl.lemmatize(word,t[0].lower())\n",
    "        word_list_after.append(word)\n",
    "    return ' '.join(word_list_after)\n",
    "    \n",
    "#     for sent in sent_list:\n",
    "#         # sent by sent (otherwise tag may differ), lemmatize each word based on its pos tagging, exclude words in force keep list\n",
    "#         sent  = \" \".join([wnl.lemmatize(i,j[0].lower()) \n",
    "#                           if ((j[0].lower() in ['a','n','v']) and (i not in force_keep_list))\n",
    "#                           else i\n",
    "#                           for i,j in pos_tag(word_tokenize(sent))])\n",
    "#         sent_list_after.append(sent)\n",
    "# \n",
    "#     return ' '.join(sent_list_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cornichon'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = \"cornichons\"\n",
    "lemmatization(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_exclude_list = ['purpose','extra', 'whole', 'frying', 'cut', \n",
    "                        'sun', 'baby', 'five', 'star', 'non', 'dash', 'style',\n",
    "                        'white', 'green', 'black', 'red', 'pink', 'yellow', 'brown', 'golden', 'blue', \n",
    "                        'color', 'colored', 'half', 'alternative',\n",
    "                        'ground', 'sea', 'part', 'baked', 'raw', 'new', 'active',\n",
    "                        'italian', 'dark', 'light', 'fresh', 'sweet', 'candied',\n",
    "                        'dried', 'dry', 'heavy', 'condensed', 'firm', 'soft', 'free', \n",
    "                        'mixed', 'flavored', 'evaporated', 'peeled', 'pickled','cooked','chopped', 'broken',\n",
    "                        'hot', 'self', 'rising', 'split', 'cooking', 'stewed',\n",
    "                        'de', 'dr']\n",
    "unigram_exclude_list += corpus.stopwords.words('english')\n",
    "\n",
    "ngram_exclude_list = ['all_purpose', 'purpose_flour', 'free_all']\n",
    "\n",
    "ngram_not_start_end = ['for', 'of', 'and', 'with', 'in']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57709\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbdfb2e85e3b4317b9b91648e7263203",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=57709.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "valid_recipe_id_list = []\n",
    "for recipe_id in recipe_id_list:\n",
    "    try:\n",
    "        dict_recipe_ingredients[recipe_id]\n",
    "        valid_recipe_id_list.append(recipe_id)\n",
    "    except:\n",
    "        continue\n",
    "print(len(valid_recipe_id_list))\n",
    "\n",
    "# create dict for appearance times for each cluster name\n",
    "dict_cluster_count = defaultdict(int)\n",
    "for recipe_id in tqdm(valid_recipe_id_list):\n",
    "    recipe = [dict_ingredient_clustername[ingre_id] for ingre_id in dict_recipe_ingredients[recipe_id]]\n",
    "    for ingre in recipe:\n",
    "        dict_cluster_count[ingre] += 1 # this cluster appear +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create dict for appearance times for each cluster name\n",
    "# dict_cluster_count = defaultdict(int)\n",
    "\n",
    "# perfect_match_list = []\n",
    "# partial_match_list = []\n",
    "# no_match_list = []\n",
    "# recipe_list = []\n",
    "# direction_list = []\n",
    "# lemmatized_direction_list = []\n",
    "# # remain_direction_list = []\n",
    "\n",
    "# num_ingredient_list = []\n",
    "# num_perfect_match_list = []\n",
    "# num_partial_match_list = []\n",
    "# num_no_match_list = []\n",
    "\n",
    "# for recipe_id in tqdm(valid_recipe_id_list):\n",
    "    \n",
    "#     # list of ingre that appeared exactly the same in the direction\n",
    "#     perfect_match_this_recipe = []\n",
    "#     # list of ingre that matched shorter form in the direction\n",
    "#     partial_match_this_recipe = []\n",
    "#     # list fo ingre that are not matched\n",
    "#     no_match_this_recipe = []\n",
    "    \n",
    "#     # count number of ingredients\n",
    "#     num_perfect_match_this_recipe = 0\n",
    "#     num_partial_match_this_recipe = 0\n",
    "#     num_no_match_this_recipe = 0\n",
    "\n",
    "#     # get the ingredients of this recipe id and sort by length\n",
    "#     recipe = [dict_ingredient_clustername[ingre_id] for ingre_id in dict_recipe_ingredients[recipe_id]]\n",
    "#     recipe.sort(key=lambda x: len(x.split('_')), reverse=True)\n",
    "\n",
    "#     # get the direction of this recipe id\n",
    "#     direction = dict_recipe_direction[recipe_id]\n",
    "#     lemmatized_direction = lemmatization(dict_recipe_direction[recipe_id])\n",
    "\n",
    "# #     remain_direction = lemmatized_direction\n",
    "\n",
    "#     look_for_partial = [] # list containing ingre with no perfect full match in the direction\n",
    "\n",
    "#     # For each ingre: look for perfect match in the direction text\n",
    "#     for ingre in recipe:\n",
    "#         dict_cluster_count[ingre] += 1 # this cluster appear +1\n",
    "#         ingre_tokens = ingre.split('_')\n",
    "#         ingre_original = ' '.join(ingre_tokens)\n",
    "\n",
    "#         if ingre_original in lemmatized_direction:\n",
    "#             # perfect full match\n",
    "#             perfect_match_this_recipe.append(ingre)\n",
    "#             num_perfect_match_this_recipe += 1\n",
    "\n",
    "# #             # remove this match from the direction text, so that won't mess up with other partial match\n",
    "# #             # e.g. if \"parmesan_cheese\" is perfectly matched, won't match its \"cheese\" with \"goat_cheese\"\n",
    "# #             remain_direction = re.sub(r\"\\b\"+ ingre_original + r\"\\b\", \"INGRE\", remain_direction)\n",
    "\n",
    "#         else:\n",
    "#             if len(ingre_tokens) > 1:\n",
    "#                 look_for_partial.append(ingre)\n",
    "#             else: # if the ingre cluster name is unigram and does not have perfect match, count as no match\n",
    "#                 num_no_match_this_recipe += 1\n",
    "#                 no_match_this_recipe.append(ingre)\n",
    "\n",
    "# #     remain_direction_list.append(remain_direction)\n",
    "\n",
    "#     # For each multigram ingre with no perfect match: \n",
    "#     #     look for partial match in *direction text after removing all perfect matched ingre cluster names*\n",
    "#     for ingre in look_for_partial:\n",
    "\n",
    "#         ingre_tokens = ingre.split('_')\n",
    "#         ingre_original = ' '.join(ingre_tokens)\n",
    "\n",
    "#         partial_match_this_ingre = []\n",
    "\n",
    "#         n = len(ingre_tokens)-1 # n is the length of the short form\n",
    "#         while n > 0: \n",
    "#             for i in range(0,len(ingre_tokens)-n+1): # start index in the full cluster name\n",
    "#                 short_form = ' '.join(ingre_tokens[i:i+n])\n",
    "#                 if short_form in lemmatized_direction:\n",
    "#                     # the short form is a map to the ingre\n",
    "#                     # don't break the loop if matched, cuz 'oil for frying' may end up matched 'for frying' and break\n",
    "#                     # but ignore subsequence part, e.g. if 'firm tofu' is matched, ignore 'firm' & 'tofu'\n",
    "#                     if not any(short_form in existing_short_form for existing_short_form in partial_match_this_ingre):\n",
    "#                         if n >= 2: # if the short form >=2 words\n",
    "#                             if short_form.replace(' ','_') not in ngram_exclude_list \\\n",
    "#                                 and ingre_tokens[i] not in ngram_not_start_end \\\n",
    "#                                 and ingre_tokens[i+n-1] not in ngram_not_start_end \\\n",
    "#                                 and not any(short_form.replace(' ','_') in cluster for cluster in perfect_match_this_recipe):\n",
    "#                                     # if the short form not in ngram_exclude_list\n",
    "#                                     # and the short form does not start or end with words in ngram_not_start_end list\n",
    "#                                     # and the short form is not a substring of any perfect match\n",
    "#                                     partial_match_this_ingre.append(short_form.replace(' ','_'))\n",
    "#                         else: # if the short form is unigram\n",
    "#                             if short_form not in unigram_exclude_list \\\n",
    "#                                 and not any(short_form in cluster for cluster in perfect_match_this_recipe):\n",
    "#                                 partial_match_this_ingre.append(short_form)\n",
    "\n",
    "#             n -= 1\n",
    "\n",
    "#         if len(partial_match_this_ingre) == 0: # no partial match found for this ingre, count as no match\n",
    "#             no_match_this_recipe.append(ingre)\n",
    "#             num_no_match_this_recipe += 1\n",
    "#         else: # some partial match found for this ingre\n",
    "#             partial_match_this_recipe.append([ingre, partial_match_this_ingre])\n",
    "#             num_partial_match_this_recipe += 1\n",
    "        \n",
    "# #     if num_no_match_this_recipe > 0:\n",
    "# #         # if the direction contains \"ingredients\", ignore the missing ingre when calculating stats\n",
    "# #         if 'ingredients' in direction:\n",
    "# #             num_ignore_this_recipe = num_no_match_this_recipe\n",
    "    \n",
    "    \n",
    "#     recipe_list.append(recipe)\n",
    "#     direction_list.append(direction)\n",
    "#     lemmatized_direction_list.append(lemmatized_direction)\n",
    "#     perfect_match_list.append(perfect_match_this_recipe)\n",
    "#     partial_match_list.append(partial_match_this_recipe)\n",
    "#     no_match_list.append(no_match_this_recipe)\n",
    "#     num_perfect_match_list.append(num_perfect_match_this_recipe)\n",
    "#     num_partial_match_list.append(num_partial_match_this_recipe)\n",
    "#     num_no_match_list.append(num_no_match_this_recipe)\n",
    "#     num_ingredient_list.append(len(recipe))\n",
    "    \n",
    "\n",
    "# matched_df = pd.DataFrame({\n",
    "#     'recipe_id': valid_recipe_id_list, \n",
    "#     'recipe': recipe_list,\n",
    "#     'direction': direction_list,\n",
    "#     'lemma_direction': lemmatized_direction_list,\n",
    "#     # 'remain_direction': remain_direction_list,\n",
    "#     'perfect_match': perfect_match_list,\n",
    "#     'partial_match': partial_match_list,\n",
    "#     'no_match': no_match_list,\n",
    "#     'num_ingredient': num_ingredient_list,\n",
    "#     'num_perfect_match': num_perfect_match_list,\n",
    "#     'num_partial_match': num_partial_match_list,\n",
    "#     'num_no_match': num_no_match_list\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e097cd5d5e6e4a78b8f2ee7956bd3015",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=57709.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "perfect_match_list = []\n",
    "partial_match_list = []\n",
    "no_match_list = []\n",
    "recipe_list = []\n",
    "direction_list = []\n",
    "lemmatized_direction_list = []\n",
    "remain_direction_list = []\n",
    "\n",
    "num_ingredient_list = []\n",
    "num_perfect_match_list = []\n",
    "num_partial_match_list = []\n",
    "num_no_match_list = []\n",
    "\n",
    "for recipe_id in tqdm(valid_recipe_id_list):\n",
    "    \n",
    "    # list of ingre that appeared exactly the same in the direction\n",
    "    perfect_match_this_recipe = []\n",
    "    # list of ingre that matched shorter form in the direction\n",
    "    partial_match_this_recipe = []\n",
    "    # list fo ingre that are not matched\n",
    "    no_match_this_recipe = []\n",
    "    \n",
    "    # count number of ingredients\n",
    "    num_perfect_match_this_recipe = 0\n",
    "    num_partial_match_this_recipe = 0\n",
    "    num_no_match_this_recipe = 0\n",
    "    \n",
    "    # get the direction of this recipe id\n",
    "    direction = dict_recipe_direction[recipe_id]\n",
    "    lemmatized_direction = lemmatization(dict_recipe_direction[recipe_id])\n",
    "    \n",
    "    remain_direction = lemmatized_direction\n",
    "\n",
    "    # get the ingredients of this recipe id and sort by length\n",
    "    recipe = [dict_ingredient_clustername[ingre_id] for ingre_id in dict_recipe_ingredients[recipe_id]]\n",
    "    \n",
    "    # get all the short names of all ingre in this recipe and combine with full names, then sort by length\n",
    "    all_names = []\n",
    "    for ingre in recipe:\n",
    "        ingre_tokens = ingre.split('_')\n",
    "        n = len(ingre_tokens)-1\n",
    "        while n > 0:\n",
    "            for i in range(0,len(ingre_tokens)-n+1):\n",
    "                short_form = '_'.join(ingre_tokens[i:i+n])\n",
    "                if n > 1:\n",
    "                    if short_form not in ngram_exclude_list \\\n",
    "                       and ingre_tokens[i] not in ngram_not_start_end \\\n",
    "                       and ingre_tokens[i+n-1] not in ngram_not_start_end:\n",
    "                        all_names.append(short_form)\n",
    "                else:\n",
    "                    if short_form not in unigram_exclude_list:\n",
    "                        all_names.append(short_form)\n",
    "            n = n-1\n",
    "    all_names += recipe\n",
    "    all_names = list(set(all_names))\n",
    "    all_names.sort(key=lambda x: len(x.split('_')), reverse=True)\n",
    "    \n",
    "    remained_unmatched = recipe.copy()\n",
    "    look_for_partial = recipe.copy() # list of ingre with no perfect full match in the direction\n",
    "    \n",
    "    # match the names in all_names from longest to shortest\n",
    "    for name in all_names:\n",
    "        name_original = name.replace('_',' ')\n",
    "        # if name_original in remain_direction (using whole word matching)\n",
    "        if re.search(r'\\b' + name_original + r'\\b', remain_direction) is not None: # a match\n",
    "            if name in recipe: # a perfect full match\n",
    "                perfect_match_this_recipe.append(name)\n",
    "                if len(name.split('_')) > 1:\n",
    "                    # only remove this name from direction text if the name is multigram\n",
    "                    remain_direction = re.sub(r\"\\b\"+ name_original + r\"\\b\", \"INGRE\", remain_direction)\n",
    "                remained_unmatched.remove(name)\n",
    "                look_for_partial.remove(name)\n",
    "                num_perfect_match_this_recipe += 1\n",
    "            else: # a partial match exits\n",
    "                matched_ingres = [ingre for ingre in look_for_partial if re.search(r'\\b' + name_original + r'\\b', ingre.replace('_',' ')) is not None]\n",
    "                for ingre in matched_ingres: # for each ingre that this name has a partial match\n",
    "                    partial_match_this_recipe.append([ingre, [name]])\n",
    "                    if ingre in remained_unmatched: # if this ingre has a match for the first time\n",
    "                        remained_unmatched.remove(ingre)\n",
    "                        num_partial_match_this_recipe += 1\n",
    "                if len(matched_ingres) > 0 and len(name.split('_')) > 1:\n",
    "                    # only remove this name from direction text if the name is multigram and there's a match\n",
    "                    remain_direction = re.sub(r\"\\b\"+ name_original + r\"\\b\", \"INGRE\", remain_direction)\n",
    "    \n",
    "\n",
    "    no_match_list.append(remained_unmatched)\n",
    "    recipe_list.append(recipe)\n",
    "    direction_list.append(direction)\n",
    "    lemmatized_direction_list.append(lemmatized_direction)\n",
    "    perfect_match_list.append(perfect_match_this_recipe)\n",
    "    partial_match_list.append(partial_match_this_recipe)\n",
    "    num_perfect_match_list.append(num_perfect_match_this_recipe)\n",
    "    num_partial_match_list.append(num_partial_match_this_recipe)\n",
    "    num_no_match_list.append(len(remained_unmatched))\n",
    "    num_ingredient_list.append(len(recipe))\n",
    "    remain_direction_list.append(remain_direction)\n",
    "    \n",
    "\n",
    "matched_df = pd.DataFrame({\n",
    "    'recipe_id': valid_recipe_id_list, \n",
    "    'recipe': recipe_list,\n",
    "    'direction': direction_list,\n",
    "    'lemma_direction': lemmatized_direction_list,\n",
    "    'remain_direction': remain_direction_list,\n",
    "    'perfect_match': perfect_match_list,\n",
    "    'partial_match': partial_match_list,\n",
    "    'no_match': no_match_list,\n",
    "    'num_ingredient': num_ingredient_list,\n",
    "    'num_perfect_match': num_perfect_match_list,\n",
    "    'num_partial_match': num_partial_match_list,\n",
    "    'num_no_match': num_no_match_list\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matched_df.loc[matched_df['recipe_id'] == 132553,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(matched_df.shape)\n",
    "matched_df.to_csv('/Users/nessyliu/Desktop/RA/part_2/result/matched_directions_orgin_w6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test the 1-gram to (n-1)-gram shorter forms\n",
    "# ingre_tokens = ['fresh','white','chocolate','chips']\n",
    "\n",
    "# n = len(ingre_tokens)-1\n",
    "# while n > 0:\n",
    "#     for i in range(0,len(ingre_tokens)-n+1):\n",
    "#         short_form = ' '.join(ingre_tokens[i:i+n])\n",
    "#         print(short_form)\n",
    "#     n = n-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count of ingredients not matched in at least one recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "861"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_match_list_flat = list(itertools.chain.from_iterable(no_match_list))\n",
    "count_no_match = Counter(no_match_list_flat)\n",
    "count_no_match = count_no_match.most_common()\n",
    "len(count_no_match) # ingre at least not matched in 1 recipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Label2 in Final_clusters_mod for synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "salt 673\n",
      "['sodium']\n",
      "green_onion 254\n",
      "['scallion']\n",
      "garbanzo_bean 239\n",
      "['chickpea', 'liquid', 'gravy', 'crumb', 'bengal', 'gram']\n",
      "butter 202\n",
      "['sunbutter', 'variety', 'garlic', 'land']\n",
      "ground_cinnamon 195\n",
      "['mccormick', 'ceylon']\n",
      "water 187\n",
      "['orange', 'flower', 'spring']\n",
      "margarine 187\n",
      "['vegan', 'spread', 'fat', 'butter', 'soy', 'oil', 'corn', 'dairy', 'vegetable']\n",
      "pecan 182\n",
      "['decoration', 'extract']\n",
      "green_chile_pepper 162\n",
      "['hatch', 'mexico', 'chili']\n",
      "graham_cracker 160\n",
      "['crust', 'chocolate', 'pie', 'crumb', 'mini', 'cinnamon', 'fat', 'deep', 'dish', 'cooky', 'bear', 'snack', 'honey', 'maid']\n",
      "pie_crust 154\n",
      "['shell', 'tart', 'pastry', 'deep', 'dish', 'shortbread', 'mix', 'wheat', 'chocolate', 'sandwich', 'cookie', 'pillsbury', 'box', 'mini', 'phyllo', 'shortcake', 'recipe', 'ball', 'dough']\n",
      "ground_black_pepper 130\n",
      "['mccormick', 'coarse']\n",
      "egg 125\n",
      "[\"eggland's\", 'strip']\n",
      "ground_nutmeg 124\n",
      "['mccormick']\n",
      "vanilla_extract 120\n",
      "['imitation', 'mccormick', 'pure']\n",
      "crabmeat 109\n",
      "['crab', 'imitation', 'king', 'leg', 'thawed', 'alaskan', 'shell', 'snow', 'cluster']\n",
      "adobo_sauce 97\n",
      "['chipotle', 'pepper']\n",
      "ground_beef 97\n",
      "['lean', 'meatloaf', 'patty', 'hamburger', 'leftover', 'mix', 'round', 'chuck', 'burger']\n",
      "chocolate_cooky 90\n",
      "['cookie', 'sandwich', 'crumb', 'chip', 'mint', 'creme', 'butter', 'crust', 'oval', 'milk', 'candy', 'bit', 'caramel', 'bar', 'twix', 'carb', 'cereal']\n",
      "vegetable_oil 89\n",
      "['drop', 'hazelnut', 'flaxseed', 'garlic', 'cinnamon', 'medium', 'chain', 'triglyceride', 'almond', 'palm', 'orange', 'macadamia', 'nut', 'anise', 'pina', 'colada', 'candy', 'tomato', 'lemon', 'pumpkin', 'seed', 'popcorn', 'rice', 'bran', 'nutmeg', 'basil', 'poppyseed', 'ginger', 'mustard', 'substitute', 'pistachio', 'coriander']\n",
      "ground_clove 81\n",
      "['mccormick']\n",
      "baking_powder 77\n",
      "['sodium']\n",
      "honey 72\n",
      "['aunt', 'powder', 'butter']\n",
      "spaghetti 72\n",
      "['spaghettini', 'spinach', 'pasta', 'thin', 'wheat']\n",
      "kosher_salt 70\n",
      "['coarse']\n",
      "macaroni 69\n",
      "['elbow', 'wheat', 'multi', 'grain', 'multigrain']\n",
      "soy_sauce 67\n",
      "['sodium', 'tamari', 'lite']\n",
      "milk 67\n",
      "['lactose']\n",
      "garlic 66\n",
      "['clove', 'oil', 'juice', 'elephant']\n",
      "onion 66\n",
      "['purple', 'medium', 'ring', 'cipollini', 'welsh', 'matchstick', 'sauteed', 'butter']\n",
      "luncheon_meat 65\n",
      "['deli', 'turkey', 'thin', 'slice', 'beef', 'lite', 'sodium', 'chicken', 'pastrami', 'capicola', 'mortadella', 'meatless', 'hormel', 'choice']\n",
      "bread_crumb 64\n",
      "['panko', 'wheat', 'garlic', 'herb', 'parmesan', 'cheese', 'breadcrumb']\n",
      "mixed_berry 63\n",
      "['gooseberry', 'boysenberry', 'fruit', 'juice', 'juniper', 'acai', 'pulp', 'lychee', 'elderberry', 'mulberry', 'serviceberry', 'saskatoon', 'lingonberry', 'thawed', 'barberry', 'salmonberry', 'dewberry', 'framboise']\n",
      "half_and_half 63\n",
      "['fat']\n",
      "milk_powder 62\n",
      "['strawberry', 'skim', 'fat', 'instant']\n",
      "raisin 61\n",
      "['chocolate', 'yogurt', 'sultana', 'paste', 'cinnamon']\n",
      "sirloin 59\n",
      "['lean', 'cold', 'top', 'beef']\n",
      "chicken_broth 55\n",
      "['sodium', 'fat', 'base', 'swanson']\n",
      "sea_salt 55\n",
      "['coarse', 'fine']\n",
      "beef_chuck 54\n",
      "['roast', 'cubed', 'angus']\n",
      "jam 54\n",
      "['preserve', 'cherry', 'mango', 'plum', 'lingonberry', 'flavor', 'fruit', 'lemon', 'marmalade', 'cranberry']\n",
      "bean 54\n",
      "['soybean', 'soup', 'paste', 'dip', 'adzuki', 'curd', 'thread', 'bacon', 'mayocoba', 'soy', 'salad', 'garlic', 'sauce', 'soldier', 'liquid', 'corona', 'tri', 'blend', 'piece', 'block']\n",
      "carrot 53\n",
      "['food', 'juice', 'pureed']\n",
      "italian_seasoning 52\n",
      "['mccormick', 'perfect', 'pinch', 'blend']\n",
      "orange_jam 52\n",
      "['marmalade', 'sugar', \"smucker's\"]\n",
      "round_steak 52\n",
      "['eye']\n",
      "bread 51\n",
      "['loaf', 'multigrain', 'toast', \"nature's\", 'cubed', 'cinnamon', 'country', 'potato', 'sheet', 'lavash', 'sandwich', 'soda', 'farl', 'pumpkin', 'friendship', 'starter', 'garlic', 'oatnut', 'stale', 'cranberry', 'walnut', 'crosswise', 'swirl', 'banana', 'torn', 'cube', 'calorie', 'oatmeal', 'schr', 'artisan', 'baker', 'grain', 'seed', 'zwieback', 'anisette', 'bruschetta']\n",
      "potato 51\n",
      "['instant', 'fry', 'flake', 'leftover', 'mix', 'au', 'gratin', 'garlic', 'salad', 'idahoan', 'cheese', 'purple', 'creamer', 'crinkle']\n",
      "buttermilk 51\n",
      "['fat', 'powder']\n",
      "almond 49\n",
      "['honey', 'marcona', 'chocolate', 'cocoa']\n",
      "cornflakes_cereal 49\n",
      "['honey', 'corn', 'flake', 'nut', 'flavor', 'cornflake', 'crumb', 'sugar']\n",
      "beef_sirloin 48\n",
      "['boneless', 'steak', 'room', 'temperature']\n",
      "other_fish 48\n",
      "['fillet', 'mackerel', 'sardine', 'bluefish', 'perch', 'oil', 'bonito', 'orange', 'roughy', 'grouper', 'monkfish', 'bass', 'hake', 'amberjack', 'butterfish', 'pollock', 'rockfish', 'pompano', 'drum', 'stick', 'milkfish', 'water', 'skinless', 'boneless', 'head', 'bone', 'char', 'smelt', 'mullet', 'pacific', 'saury']\n",
      "cod 48\n",
      "['fillet', 'fish', 'lingcod', 'skin', 'bone']\n",
      "parsley 47\n",
      "['leaf', 'flake', 'root', 'chunk', 'mccormick', 'paste', 'chervil']\n",
      "hash_brown 47\n",
      "['potato', 'patty', \"o'brien\"]\n",
      "liqueur 46\n",
      "['chocolate', 'pumpkin', 'strawberry', 'honey', 'whiskey', 'daiquiri', 'mix', 'benedictine', 'creme', 'cassis', 'galliano', 'elderflower', 'praline', 'amaro', 'ginger', 'pomegranate', 'blackberry', 'maraschino', 'lychee', 'herb', 'spice', 'almond', 'maple', 'cranberry', 'coconut', 'peach', 'mai', 'tai', 'cocktail', 'chartreuse', 'cachaca', 'bottle', 'malt', 'liquor']\n",
      "orange_liqueur 46\n",
      "['brandy', 'curacao']\n",
      "syrup 44\n",
      "['cane', 'sugar', 'simple', 'chocolate', 'pancake', 'glucose', 'eagle', 'pomegranate']\n",
      "cooky 44\n",
      "['butter', 'peanut', 'sandwich', 'oatmeal', 'coconut', 'fudge', 'macaroon', 'speculoos', 'sugar', 'stripe', 'oreo', 'rectangular', 'oval', 'animal', 'cracker', 'ginger', 'nut', 'plain', 'meringue', 'caramel', 'stick', 'raisin', 'gingerbread', 'cookie', 'crumb', 'store', 'bought']\n",
      "strawberry 43\n",
      "['freeze', 'puree']\n",
      "oat 42\n",
      "['quick', 'fiber']\n"
     ]
    }
   ],
   "source": [
    "no_label2 = []\n",
    "\n",
    "# To find synonyms:\n",
    "# For each missing ingredient, check the label2 in Final_clusters_mod.csv\n",
    "for (missing_ingre, missing_count) in count_no_match:\n",
    "    missing_ingre_unigrams = missing_ingre.split('_')\n",
    "    all_label2 = ' '.join(df_mod.loc[df_mod['cluster_name'] == ' '.join(missing_ingre_unigrams),'label2'])\n",
    "    unigrams = all_label2.split(' ')\n",
    "    count_unigrams = Counter(unigrams).most_common()\n",
    "    if len(count_unigrams)>0:\n",
    "        possible_names = [unigram for (unigram, count) in count_unigrams if unigram \\\n",
    "                          not in unigram_exclude_list+missing_ingre_unigrams+['']\\\n",
    "                          and pos_tag([unigram])[0][1]=='NN']\n",
    "    if len(possible_names)>0:\n",
    "        if missing_count > 40:\n",
    "            print(missing_ingre, missing_count)\n",
    "            print(possible_names)\n",
    "    else:\n",
    "        no_label2.append(missing_ingre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingredients missing pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "700d788e6aa24b739ad37a2f1376e54b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8916, 861)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing (no match) pattern\n",
    "all_no_match_unique = set(no_match_list_flat)\n",
    "\n",
    "matched_df_missing = matched_df.loc[:,['recipe_id', 'no_match']]\n",
    "\n",
    "no_match_span_df = pd.concat([pd.Series(row['recipe_id'], row['no_match']) for _, row in tqdm(matched_df_missing.iterrows())]).reset_index()\n",
    "\n",
    "no_match_span_df.columns = ['missing_ingredient', 'recipe_id']\n",
    "missing_matrix = pd.pivot_table(no_match_span_df, values='missing_ingredient', index=['recipe_id'], columns=['missing_ingredient'], aggfunc=lambda x: len(x))\n",
    "\n",
    "missing_matrix = missing_matrix.fillna(0)\n",
    "\n",
    "missing_matrix.shape # row is each recipe, col is each (missing) ingre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 57709 recipes in total.\n",
      "There are 8916 recipes with at least 1 ingredient not matched.\n",
      "There are 861 unique ingredients not matched in at least 1 recipe out of 57709 recipes.\n",
      "There are 754 unique ingredients not matched in <= 20 % of its appearances.\n",
      "There are 107 unique ingredients not matched in > 20 % of its appearances.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Not matched in % of its appearances')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "missing_in_num_recipes = [(col, col_sum) for col, col_sum in missing_matrix.sum().iteritems()]\n",
    "missing_pct = [(col, (col_sum / dict_cluster_count[col])*100) for (col, col_sum) in missing_in_num_recipes]\n",
    "\n",
    "thres_pct = 20\n",
    "print('There are', len(no_match_list), 'recipes in total.')\n",
    "print('There are', len(missing_matrix), 'recipes with at least 1 ingredient not matched.')\n",
    "print('There are', len(all_no_match_unique), 'unique ingredients not matched in at least 1 recipe out of',len(no_match_list),'recipes.')\n",
    "print('There are', len([col for col, pct in missing_pct if pct <= thres_pct]), 'unique ingredients not matched in <=', thres_pct,'% of its appearances.')\n",
    "print('There are', len(all_no_match_unique) - len([col for col, pct in missing_pct if pct <= thres_pct]), 'unique ingredients not matched in >', thres_pct,'% of its appearances.')\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [8, 4]\n",
    "\n",
    "plt.hist([pct for col, pct in missing_pct], density=False, bins=200)\n",
    "plt.ylabel('Count of ingredients')\n",
    "plt.xlabel('Not matched in % of its appearances') ### change to pct, not matched / all it appearsï¼Œ sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [col for col, pct in missing_pct if pct > thres_pct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118, 107)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop the ingredients that only not matched in <= thres recipes\n",
    "# drop the recipes that contain more than 1 missing ingredient now\n",
    "\n",
    "missing_matrix_drop = missing_matrix.copy()\n",
    "\n",
    "missing_matrix_drop.drop([col for col, pct in missing_pct if pct <= thres_pct], axis=1, inplace=True)\n",
    "missing_matrix_drop = missing_matrix_drop.loc[(missing_matrix_drop.sum(axis=1) > 1),:]\n",
    "missing_matrix_drop.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing correlation\n",
    "\n",
    "# corr_matrix = missing_matrix_drop.corr()\n",
    "# plt.rcParams['figure.figsize'] = [15, 15]\n",
    "# sn.heatmap(corr_matrix, annot=True, cmap=\"Blues\")\n",
    "# plt.show()\n",
    "\n",
    "# corr_matrix_lower = corr_matrix.copy()\n",
    "\n",
    "# corr_matrix_lower.loc[:,:] =  np.tril(corr_matrix_lower, k=-1) # borrowed from Karl D's answer\n",
    "\n",
    "# already_in = set()\n",
    "# missing_ingredients_clusters = []\n",
    "# for col in corr_matrix_lower:\n",
    "#     high_corr = corr_matrix_lower[col][corr_matrix_lower[col] > 0.02].index.tolist()\n",
    "#     if high_corr and col not in already_in:\n",
    "#         already_in.update(set(high_corr))\n",
    "#         high_corr.append(col)\n",
    "#         missing_ingredients_clusters.append(high_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the direction texts missing the above clusters of ingredients\n",
    "\n",
    "# no_match_df = matched_df.loc[matched_df['num_no_match']>0,:]\n",
    "\n",
    "# check_list = no_match_df.loc[no_match_df.no_match.map(lambda x: 'baking_soda' in x), 'direction']\n",
    "# for direction in check_list:\n",
    "#     print(direction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dict containing all the mappings from above findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create a dict for cluster name mapping\n",
    "\n",
    "key: cluster name\n",
    "value: dict{'short': all appeared short forms (only for multi-gram cluster names), \n",
    "            'parent': parent names, \n",
    "            'child': child names,\n",
    "            'synonym': synonyms}\n",
    "'''\n",
    "dict_ingre_mapping = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "exchangeable_pairs = [('chili', 'chile'), ('cookie', 'cooky'), ('cocoa', 'cacao')]\n",
    "\n",
    "# iterate for all cluster names\n",
    "for ingre in dict_cluster_count: \n",
    "    \n",
    "    # add \"dry ingredient\" as parent term for ingredients with \"dried\"\n",
    "    if ('dried' in ingre) and ('dry_ingredient' not in dict_ingre_mapping[ingre]['parent']):\n",
    "        dict_ingre_mapping[ingre]['parent'].append('dry_ingredient')\n",
    "\n",
    "    # add parent names for ingredients with \"broth\"\n",
    "    if ('broth' in ingre) and ('stock' not in dict_ingre_mapping[ingre]['parent']):\n",
    "        dict_ingre_mapping[ingre]['parent'] += ['stock','consomme','soup']\n",
    "\n",
    "    # add parent names for ingredients with \"preserve\"\n",
    "    if ('jam' in ingre) and ('preserve' not in dict_ingre_mapping[ingre]['parent']):\n",
    "        dict_ingre_mapping[ingre]['parent'] += ['preserve']\n",
    "\n",
    "    # add synonyms for ingredients containing exchangeable pairs\n",
    "    for (A,B) in exchangeable_pairs:\n",
    "        if A in ingre or B in ingre:\n",
    "            if A in ingre: # e.g. A = origin = 'cooky', B = alter = 'cookie', ingre = 'chocolate_cooky'\n",
    "                origin = A\n",
    "                alter = B\n",
    "            else:\n",
    "                origin = B\n",
    "                alter = A\n",
    "            ingre_tokens = ingre.split('_')\n",
    "            ingre_syn = '_'.join([t if t != origin else alter for t in ingre_tokens])\n",
    "            if ingre_syn not in dict_ingre_mapping[ingre]['synonym']:\n",
    "                dict_ingre_mapping[ingre]['synonym'] += [ingre_syn] # e.g. add 'chocolate_cookie' as synonym\n",
    "\n",
    "\n",
    "# iterate for all partial matches\n",
    "for partial_match_this_recipe in partial_match_list:\n",
    "    for partial_match_this_ingre in partial_match_this_recipe:\n",
    "        ingre = partial_match_this_ingre[0]\n",
    "        \n",
    "        short_forms = partial_match_this_ingre[1]\n",
    "        \n",
    "        # add synonym names for ingredients containing exchangeable pairs\n",
    "        for (A,B) in exchangeable_pairs:\n",
    "            if A in ingre or B in ingre:\n",
    "                if A in ingre: # e.g. A = origin = 'cooky', B = alter = 'cookie', ingre = 'chocolate_cooky'\n",
    "                    origin = A\n",
    "                    alter = B\n",
    "                else:\n",
    "                    origin = B\n",
    "                    alter = A\n",
    "                # e.g. add \"cookie\" as a synonym name for \"chocolate_cooky\" iff \"cooky\" is a short name for it\n",
    "                short_synonym_forms = [re.sub(origin, alter, short) for short in short_forms if origin in short]\n",
    "                for name in short_synonym_forms:\n",
    "                    if name not in dict_ingre_mapping[ingre]['synonym']:\n",
    "                        dict_ingre_mapping[ingre]['synonym'] += [name] \n",
    "        \n",
    "        # insert in all short forms to the dict based on partial matching in previous step\n",
    "        for short_form in short_forms:\n",
    "            if short_form not in dict_ingre_mapping[ingre]['short']:\n",
    "                dict_ingre_mapping[ingre]['short'].append(short_form)\n",
    "        \n",
    "#         short_form = partial_match_this_ingre[1]\n",
    "        \n",
    "#         # add synonym names for ingredients containing exchangeable pairs\n",
    "#         for (A,B) in exchangeable_pairs:\n",
    "#             if A in ingre or B in ingre:\n",
    "#                 if A in ingre: # e.g. A = origin = 'cooky', B = alter = 'cookie', ingre = 'chocolate_cooky'\n",
    "#                     origin = A\n",
    "#                     alter = B\n",
    "#                 else:\n",
    "#                     origin = B\n",
    "#                     alter = A\n",
    "#                 # e.g. add \"cookie\" as a synonym name for \"chocolate_cooky\" iff \"cooky\" is a short name for it\n",
    "#                 if origin in short_form:\n",
    "#                     short_synonym_form = re.sub(origin, alter, short_form)\n",
    "#                     if short_synonym_form not in dict_ingre_mapping[ingre]['synonym']:\n",
    "#                         dict_ingre_mapping[ingre]['synonym'] += [short_synonym_form] \n",
    "        \n",
    "#         # insert in all short forms to the dict based on partial matching in previous step\n",
    "#         if short_form not in dict_ingre_mapping[ingre]['short']:\n",
    "#             dict_ingre_mapping[ingre]['short'].append(short_form)\n",
    "        \n",
    "        \n",
    "\n",
    "                \n",
    "#### add in parent terms\n",
    "# nut\n",
    "nut_cluster = ['walnut', 'pecan', 'almond']\n",
    "for ingre in nut_cluster:\n",
    "    dict_ingre_mapping[ingre]['parent'].append('nut')\n",
    "\n",
    "# spice\n",
    "spice_cluster = ['ground_cinnamon', 'ground_nutmeg', 'ground_allspice', 'ground_clove', \n",
    "                 'ground_black_pepper', 'ground_cardamom', 'ground_chile_pepper', 'ground_coriander', \n",
    "                'ground cumin', 'ground_ginger', 'ground_mace', 'ground_turmeric', 'ground_white_pepper']\n",
    "for ingre in spice_cluster:\n",
    "    dict_ingre_mapping[ingre]['parent'].append('spice')\n",
    "\n",
    "# meat\n",
    "meat_cluster = ['ground_beef', 'pork_sausage', 'beef_part', 'sirloin', 'pork']\n",
    "for ingre in meat_cluster:\n",
    "    dict_ingre_mapping[ingre]['parent'].append('meat')\n",
    "    \n",
    "# roast\n",
    "roast_cluster = ['beef_chuck', 'beef_tenderloin']\n",
    "for ingre in roast_cluster:\n",
    "    dict_ingre_mapping[ingre]['parent'].append('roast')\n",
    "\n",
    "# steak\n",
    "steak_cluster = ['beef', 'beef_sirloin', 'pork', 'sirloin']\n",
    "for ingre in steak_cluster:\n",
    "    dict_ingre_mapping[ingre]['parent'].append('steak')\n",
    "    \n",
    "# berry\n",
    "berry_cluster = ['blackberry','blueberry']\n",
    "for ingre in berry_cluster:\n",
    "    dict_ingre_mapping[ingre]['parent'].append('berry')\n",
    "\n",
    "# sorbet\n",
    "sorbet_cluster = ['ice_cream', 'strawberry_ice_cream']\n",
    "for ingre in sorbet_cluster:\n",
    "    dict_ingre_mapping[ingre]['parent'] += ['sorbet', 'sherbet']\n",
    "\n",
    "# syrup\n",
    "syrup_cluster = ['strawberry_topping']\n",
    "for ingre in syrup_cluster:\n",
    "    dict_ingre_mapping[ingre]['parent'] += ['syrup', 'glaze']\n",
    "\n",
    "# vegetable\n",
    "vegetable_cluster = ['carrot', 'celery','cauliflower','broccoli','sweet_potato','potato','tomato', 'zucchini']\n",
    "for ingre in vegetable_cluster:\n",
    "    dict_ingre_mapping[ingre]['parent'] += ['vegetable']\n",
    "\n",
    "\n",
    "dict_ingre_mapping['rose']['parent'].append('petal')\n",
    "dict_ingre_mapping['graham_cracker']['parent'] += ['crust', 'crumb']\n",
    "dict_ingre_mapping['ground_beef']['parent'] += ['meatloaf', 'patty']\n",
    "dict_ingre_mapping['sirloin']['parent']+= ['beef']\n",
    "dict_ingre_mapping['beef']['parent'] += ['rib', 'tamale']\n",
    "dict_ingre_mapping['cod']['parent'] += ['fish', 'fillet']\n",
    "dict_ingre_mapping['flounder']['parent'] += ['fish', 'fillet']\n",
    "dict_ingre_mapping['pork_sparerib']['parent'] += ['rib']\n",
    "dict_ingre_mapping['candied_citron']['parent'] += ['candied_fruit']\n",
    "\n",
    "dict_ingre_mapping['mixed_baby_green']['parent'] += ['green']\n",
    "\n",
    "dict_ingre_mapping['round_steak']['parent'] += ['beef']\n",
    "\n",
    "\n",
    "dict_ingre_mapping['ground_black_pepper']['parent'] += ['seasoning']\n",
    "\n",
    "dict_ingre_mapping['mixed_berry']['parent'] += ['fruit']\n",
    "\n",
    "dict_ingre_mapping['vanilla_extract']['parent'] += ['flavoring']\n",
    "\n",
    "dict_ingre_mapping['half_and_half']['parent'] += ['cream']\n",
    "\n",
    "\n",
    "\n",
    "#### add in child terms\n",
    "dict_ingre_mapping['topping']['child'].append('spice')\n",
    "dict_ingre_mapping['potato']['child'] += ['frenchfries', 'fries']\n",
    "dict_ingre_mapping[\"pig's_part\"]['child'] += ['pork', 'liver', 'ear', 'tail', 'foot', 'pig', 'jowl', 'stomach', 'cheek']\n",
    "dict_ingre_mapping[\"liqueur\"]['child'] += ['daiquiri','cocktail', 'chartreuse', 'cachaca', 'mezcal']\n",
    "dict_ingre_mapping[\"bean\"]['child'] += ['soybean']\n",
    "dict_ingre_mapping[\"other_fish\"]['child'] += ['bonito', 'fillet', 'milkfish', 'herring', 'mackerel', \n",
    "                                              'sardine', 'bluefish', 'perch', 'monkfish', 'bass', \n",
    "                                             'hake', 'amberjack', 'butterfish', 'pollock', 'rockfish', \n",
    "                                              'pompano', 'milkfish', 'char', 'smelt', 'mullet', 'saury']\n",
    "dict_ingre_mapping[\"other_meat\"]['child'] += ['buffalo', 'goat', 'alligator', 'kangaroo', 'turtle', 'bear',\n",
    "                                             'rattlesnake', 'bison', 'antelope', 'ostrich', 'elk', 'squirrel',\n",
    "                                             'octopus', 'quail', 'moose', 'shark', 'ostrich', 'boar', 'frog', 'grouse']\n",
    "\n",
    "dict_ingre_mapping[\"mixed_berry\"]['child'] += [ 'juniper','acai_pulp', 'lychee', 'elderberry', 'mulberry', \n",
    "                                               'serviceberry', \n",
    "                                               'gooseberry','boysenberry', 'lingonberry', 'barberry', 'salmonberry',\n",
    "                                              'dewberry', 'marionberry', 'framboise']\n",
    "\n",
    "\n",
    "dict_ingre_mapping['luncheon_meat']['child'] += ['turkey', 'beef', 'chicken']\n",
    "\n",
    "dict_ingre_mapping['pickle']['child'] += ['gherkin', 'relish', 'giardiniera', 'cornichon']\n",
    "dict_ingre_mapping['cake']['child'] += ['cupcake', 'jellyroll', 'hard_bread', 'fruitcake', 'twinkie']\n",
    "dict_ingre_mapping['mixed_spice']['child'] += ['chaat_masala', 'garam_masala', 'pav_bhaji_masala']\n",
    "dict_ingre_mapping['herb']['child'] += ['epazote', 'bouquet_garni', 'rosemary_leaf']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### add in synonyms\n",
    "\n",
    "dict_ingre_mapping['margarine']['synonym'].append('butter')\n",
    "dict_ingre_mapping['butter']['synonym'].append('margarine')\n",
    "dict_ingre_mapping['pasta']['synonym'].append('noodle')\n",
    "\n",
    "dict_ingre_mapping['garbanzo_bean']['synonym'].append('chickpea')\n",
    "dict_ingre_mapping['green_onion']['synonym'].append('scallion')\n",
    "dict_ingre_mapping['espresso']['synonym'].append('coffee_bean')\n",
    "dict_ingre_mapping['crabmeat']['synonym'].append('crab')\n",
    "dict_ingre_mapping['spaghetti']['synonym'] += ['spaghettini', 'pasta']\n",
    "dict_ingre_mapping['macaroni']['synonym'] += ['pasta']\n",
    "dict_ingre_mapping['pasta']['synonym'] += ['rotelle', 'cavatappi', 'fettuccini']\n",
    "dict_ingre_mapping['bread_crumb']['synonym'] += ['panko']\n",
    "dict_ingre_mapping['raisin']['synonym'] += ['sultana']\n",
    "dict_ingre_mapping['adobo_sauce']['synonym'] += ['chipotle']\n",
    "dict_ingre_mapping['sweetener']['synonym'] += ['fructose']\n",
    "dict_ingre_mapping['bread']['synonym'] += ['loaf', 'toast', 'challah', 'farl']\n",
    "dict_ingre_mapping['cornflakes_cereal']['synonym'] += ['cornflake']\n",
    "dict_ingre_mapping['parsley']['synonym'] += ['chervil']\n",
    "dict_ingre_mapping['cod']['synonym'] += ['lingcod']\n",
    "dict_ingre_mapping['soy_sauce']['synonym'] += ['tamari']\n",
    "dict_ingre_mapping['orange_jam']['synonym'] += ['marmalade']\n",
    "dict_ingre_mapping['pie_crust']['synonym'] += ['shell']\n",
    "dict_ingre_mapping['green_tea']['synonym'] += ['matcha']\n",
    "dict_ingre_mapping['beef_tenderloin']['synonym'] += ['mignon_filet', 'filet', 'mignon', 'steak']\n",
    "dict_ingre_mapping['beer']['synonym'] += ['stout', 'ale']\n",
    "dict_ingre_mapping['buttermilk']['synonym'] += ['sour_milk']\n",
    "dict_ingre_mapping['club_soda']['synonym'] += ['carbonated_water', 'seltzer', 'sparkling_water']\n",
    "dict_ingre_mapping['cooky']['synonym'] += ['biscuit']\n",
    "dict_ingre_mapping['nori']['synonym'] += ['seaweed']\n",
    "dict_ingre_mapping['cassava']['synonym'] += ['yuca', 'root']\n",
    "dict_ingre_mapping['kiwi']['synonym'] += ['kiwifruit']\n",
    "dict_ingre_mapping['mixed_baby_green']['synonym'] += ['pea_shoot']\n",
    "dict_ingre_mapping['cactus']['synonym'] += ['nopal']\n",
    "dict_ingre_mapping['roe']['synonym'] += ['caviar', 'tarama']\n",
    "dict_ingre_mapping['seaweed']['synonym'] += ['wakame', 'aonori', 'moss', 'kombu']\n",
    "dict_ingre_mapping['chocolate_flavored_syrup']['synonym'] += ['hot_fudge', 'fudge_topping']\n",
    "dict_ingre_mapping['animal_fat']['synonym'] += ['suet', 'tallow']\n",
    "dict_ingre_mapping['sucanat']['synonym'] += ['cane_sugar']\n",
    "dict_ingre_mapping['squid']['synonym'] += ['calamari']\n",
    "dict_ingre_mapping['vegetable_protein']['synonym'] += ['tvp']\n",
    "dict_ingre_mapping['pork']['synonym'] += ['pig']\n",
    "dict_ingre_mapping['ground_black_pepper']['synonym'] += ['peppercorn']\n",
    "dict_ingre_mapping['kosher_salt']['synonym'] += ['coarse_salt']\n",
    "dict_ingre_mapping['wheat']['synonym'] += ['freekeh']\n",
    "dict_ingre_mapping['rolled_oat']['synonym'] += ['oatmeal']\n",
    "dict_ingre_mapping['hash_brown']['synonym'] += ['potato']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'short': ['berry'],\n",
       "             'parent': ['fruit'],\n",
       "             'child': ['juniper',\n",
       "              'acai_pulp',\n",
       "              'lychee',\n",
       "              'elderberry',\n",
       "              'mulberry',\n",
       "              'serviceberry',\n",
       "              'gooseberry',\n",
       "              'boysenberry',\n",
       "              'lingonberry',\n",
       "              'barberry',\n",
       "              'salmonberry',\n",
       "              'dewberry',\n",
       "              'marionberry',\n",
       "              'framboise']})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_ingre_mapping['green_chile_pepper']\n",
    "dict_ingre_mapping['mixed_berry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8430b78fb3b845629c032266ba34a518",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=57709.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ignore_ingre_list = ['salt', 'water']\n",
    "\n",
    "from ast import literal_eval\n",
    "\n",
    "matched_df2 = pd.read_csv('/Users/nessyliu/Desktop/RA/part_2/result/matched_directions_orgin_w6.csv')\n",
    "\n",
    "#print(matched_df2.dtypes)\n",
    "dict_match_list = []\n",
    "num_dict_match_list = []\n",
    "num_ignore_list = []\n",
    "ignore_some_flag_list = []\n",
    "ignore_all_flag_list = []\n",
    "ignore_bean_flag_list = []\n",
    "ignore_unsaltedbutter_flag_list = []\n",
    "ignore_greenchile_flag_list = []\n",
    "new_no_match_list = []\n",
    "new_no_match_list_after_ignore = []\n",
    "\n",
    "for i in tqdm(range(0,len(matched_df2))):\n",
    "    row = matched_df2.iloc[i,:]\n",
    "    dict_match_this_recipe = [] # match of missing ingredients in this recipe by using the dict\n",
    "    num_dict_match_this_recipe = 0\n",
    "    num_ignore = 0\n",
    "    ignore_some_flag = False\n",
    "    ignore_bean_flag = False\n",
    "    ignore_unsaltedbutter_flag = False\n",
    "    ignore_greenchile_flag = False\n",
    "    ignore_all_flag = False\n",
    "    recipe = literal_eval(row.recipe)\n",
    "    no_match_this_recipe = literal_eval(row.no_match)\n",
    "    perfect_match_this_recipe = literal_eval(row.perfect_match)\n",
    "    direction = row.lemma_direction\n",
    "    \n",
    "    no_match_this_recipe_origin = no_match_this_recipe.copy()\n",
    "    if row.num_no_match > 0:\n",
    "        for missing_ingre in no_match_this_recipe_origin:\n",
    "            dict_match_this_ingre = []\n",
    "            parent = dict_ingre_mapping[missing_ingre]['parent']\n",
    "            # short = dict_ingre_mapping[missing_ingre]['short']\n",
    "            child = dict_ingre_mapping[missing_ingre]['child']\n",
    "            synonym = dict_ingre_mapping[missing_ingre]['synonym']\n",
    "            all_possible_names = synonym + parent + child\n",
    "            for name in all_possible_names:\n",
    "                if name.replace('_', ' ') in direction: # if there is a match between the missing ingre and name in the dict\n",
    "                    dict_match_this_ingre.append(name)\n",
    "\n",
    "            if len(dict_match_this_ingre) > 0:\n",
    "                dict_match_this_recipe.append([missing_ingre, dict_match_this_ingre])\n",
    "                num_dict_match_this_recipe += 1\n",
    "                # if this ingre is matched using dict, remove it from no_match column, and modify the num_no_match\n",
    "                no_match_this_recipe.remove(missing_ingre)\n",
    "                matched_df2.loc[i,'num_no_match'] -= 1\n",
    "    \n",
    "    no_match_this_recipe_after_ignore = no_match_this_recipe.copy()\n",
    "    \n",
    "    # for the ingre that are still missing, check if satisfy the ignore criterion\n",
    "    for missing_ingre in no_match_this_recipe:\n",
    "        # criteria 1: missing_ingre is in ignore_ingre_list (e.g. water)\n",
    "        if missing_ingre in ignore_ingre_list:\n",
    "            num_ignore += 1\n",
    "            ignore_some_flag = True\n",
    "            no_match_this_recipe_after_ignore.remove(missing_ingre)\n",
    "        # criteria 2: missing_ingre is bean, and it was caused by \"chili with bean\" in original recipes\n",
    "        elif (missing_ingre == 'bean') and ('chili_sauce' in recipe) and ('chili_sauce' not in no_match_this_recipe):\n",
    "            num_ignore += 1\n",
    "            ignore_bean_flag = True\n",
    "            no_match_this_recipe_after_ignore.remove(missing_ingre)\n",
    "        # criteria 3: missing_ingre is unsalted_butter, caused by both itself and \"butter\" in original recipes\n",
    "        elif (missing_ingre == 'unsalted_butter') and ('butter' in recipe) and ('butter' not in no_match_this_recipe):\n",
    "            num_ignore += 1\n",
    "            ignore_unsaltedbutter_flag = True\n",
    "            no_match_this_recipe_after_ignore.remove(missing_ingre)\n",
    "        # criteria 4: missing_ingre is green_chile_pepper, caused by \"diced tomato with green chile pepper\" in original recipes\n",
    "        elif (missing_ingre == 'green_chile_pepper') and ('tomato' in recipe) and ('tomato' not in no_match_this_recipe):\n",
    "            num_ignore += 1\n",
    "            ignore_greenchile_flag = True\n",
    "            no_match_this_recipe_after_ignore.remove(missing_ingre)\n",
    "    \n",
    "    # criteria 5:\n",
    "    # if there are still missing ingre, and if the direction contains 'ingredients', \n",
    "    #    then ignore all missing ingre when calculating stats\n",
    "    if ('ingredient' in row.direction) and (matched_df2.loc[i,'num_no_match'] > num_ignore):\n",
    "        num_ignore = matched_df2.loc[i,'num_no_match']\n",
    "        ignore_all_flag = True\n",
    "        no_match_this_recipe_after_ignore = []\n",
    "    \n",
    "    dict_match_list.append(dict_match_this_recipe)\n",
    "    num_dict_match_list.append(num_dict_match_this_recipe)\n",
    "    num_ignore_list.append(num_ignore)\n",
    "    new_no_match_list.append(no_match_this_recipe)\n",
    "    new_no_match_list_after_ignore.append(no_match_this_recipe_after_ignore)\n",
    "    ignore_some_flag_list.append(ignore_some_flag)\n",
    "    ignore_bean_flag_list.append(ignore_bean_flag)\n",
    "    ignore_unsaltedbutter_flag_list.append(ignore_unsaltedbutter_flag)\n",
    "    ignore_greenchile_flag_list.append(ignore_greenchile_flag)\n",
    "    ignore_all_flag_list.append(ignore_all_flag)\n",
    "\n",
    "    \n",
    "matched_df2 = matched_df2.drop(['no_match'], axis = 1)\n",
    "matched_df2.insert(7, 'dict_match', dict_match_list)\n",
    "matched_df2.insert(8, 'no_match', new_no_match_list)\n",
    "matched_df2.insert(12, 'num_dict_match', num_dict_match_list)\n",
    "matched_df2.insert(14, 'num_ignore', num_ignore_list)\n",
    "matched_df2.insert(15, 'ignore_some_flag', ignore_some_flag_list)\n",
    "matched_df2.insert(16, 'ignore_bean_flag', ignore_bean_flag_list)\n",
    "matched_df2.insert(17, 'ignore_unsaltedbutter_flag', ignore_unsaltedbutter_flag_list)\n",
    "matched_df2.insert(18, 'ignore_greenchile_flag', ignore_greenchile_flag_list)\n",
    "matched_df2.insert(19, 'ignore_all_flag', ignore_all_flag_list)\n",
    "matched_df2.insert(20, 'no_match_after_ignore', new_no_match_list_after_ignore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_df2.to_csv('/Users/nessyliu/Desktop/RA/part_2/result/matched_directions_w6.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ingredients in all recipes:\n",
      "510860\n",
      "Number of missing ingredients after one-to-one full match:\n",
      "155807\n",
      "Number of missing ingredients after partial match:\n",
      "13684 2.68%\n",
      "Number of missing ingredients after using our mapping dict:\n",
      "8957 1.75%\n",
      "Number of missing ingredients after ignoring ingre with criterion:\n",
      "4820 0.94%\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of ingredients in all recipes:\")\n",
    "print(sum(matched_df2.num_ingredient))\n",
    "print(\"Number of missing ingredients after one-to-one full match:\")\n",
    "print(sum(matched_df2.num_ingredient) - sum(matched_df2.num_perfect_match))\n",
    "print(\"Number of missing ingredients after partial match:\")\n",
    "print(sum(matched_df.num_no_match), \"{0:.2%}\".format(sum(matched_df.num_no_match) / sum(matched_df2.num_ingredient)))\n",
    "print(\"Number of missing ingredients after using our mapping dict:\")\n",
    "print(sum(matched_df2.num_no_match), \"{0:.2%}\".format(sum(matched_df2.num_no_match) / sum(matched_df2.num_ingredient)))\n",
    "print(\"Number of missing ingredients after ignoring ingre with criterion:\")\n",
    "print(sum(matched_df2.num_no_match) - sum(matched_df2.num_ignore), \"{0:.2%}\".format((sum(matched_df2.num_no_match) - sum(matched_df2.num_ignore)) / sum(matched_df2.num_ingredient)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('ground_black_pepper', 64),\n",
       " ('white_sugar', 55),\n",
       " ('kosher_salt', 53),\n",
       " ('sea_salt', 50),\n",
       " ('vanilla_extract', 46),\n",
       " ('onion', 44),\n",
       " ('orange_liqueur', 44),\n",
       " ('italian_seasoning', 42),\n",
       " ('french_baguette', 40),\n",
       " ('seasoned_salt', 38),\n",
       " ('syrup', 37),\n",
       " ('green_bell_pepper', 37),\n",
       " ('garlic', 35),\n",
       " ('tomato_juice', 35),\n",
       " ('strawberry', 34),\n",
       " ('mixed_salad_green', 33),\n",
       " ('parsley', 32),\n",
       " ('ghee', 32),\n",
       " ('cooking_spray', 31),\n",
       " ('cornstarch', 31),\n",
       " (\"confectioners'_coating\", 30),\n",
       " ('dill_pickle', 29),\n",
       " ('brown_sugar', 29),\n",
       " ('clam_juice', 28),\n",
       " ('raisin', 28),\n",
       " ('monosodium_glutamate', 28),\n",
       " ('club_soda', 28),\n",
       " ('pork', 27),\n",
       " ('garlic_powder', 27),\n",
       " ('dried_parsley', 26),\n",
       " ('bourbon', 26),\n",
       " ('seafood_seasoning', 25),\n",
       " ('vegetable_oil', 24),\n",
       " ('wafer', 24),\n",
       " ('hot_dog', 24),\n",
       " ('dried_thyme', 23),\n",
       " ('butter', 23),\n",
       " ('dried_basil', 23),\n",
       " ('mixed_spice', 22),\n",
       " ('pie_crust', 22),\n",
       " ('lemon_zest', 22),\n",
       " ('peanut', 22),\n",
       " ('green_onion', 22),\n",
       " ('potato_nugget', 22),\n",
       " ('bacon_dripping', 21),\n",
       " ('chocolate_candy', 21),\n",
       " ('lemon', 21),\n",
       " ('cornmeal', 21),\n",
       " ('dried_oregano', 21),\n",
       " ('extra_virgin_olive_oil', 20),\n",
       " ('cayenne_pepper', 20),\n",
       " ('sweetener', 20),\n",
       " ('liqueur', 20),\n",
       " ('oil_for_frying', 20),\n",
       " ('oat', 20),\n",
       " ('orange_zest', 20),\n",
       " ('peach', 20),\n",
       " ('luncheon_meat', 19),\n",
       " ('graham_cracker', 19),\n",
       " ('golden_raisin', 19),\n",
       " ('raspberry', 19),\n",
       " ('jam', 18),\n",
       " ('coleslaw', 18),\n",
       " ('coffee', 18),\n",
       " ('almond_extract', 18),\n",
       " ('lettuce', 17),\n",
       " ('red_pepper_flake', 17),\n",
       " ('parmesan_cheese', 17),\n",
       " ('sausage', 17),\n",
       " ('sprinkle', 16),\n",
       " ('wheat_gluten', 16),\n",
       " ('chile_paste', 16),\n",
       " ('hot_sauce', 16),\n",
       " ('flank_steak', 16),\n",
       " ('buttermilk', 16),\n",
       " ('tilapia', 16),\n",
       " ('red_bell_pepper', 16),\n",
       " ('egg', 16),\n",
       " ('halibut', 16),\n",
       " ('beef_chuck', 16),\n",
       " ('cilantro', 15),\n",
       " ('chocolate_cooky', 15),\n",
       " ('brandy', 15),\n",
       " ('red_snapper', 15),\n",
       " ('red_onion', 15),\n",
       " ('sucralose_sweetener', 15),\n",
       " ('frosting', 15),\n",
       " ('bean', 15),\n",
       " ('hazelnut', 15),\n",
       " ('basil', 15),\n",
       " ('lemon_lime_soda', 15),\n",
       " ('candied_cherry', 15),\n",
       " ('hamburger_bun', 15),\n",
       " ('dry_mustard', 15),\n",
       " ('red_wine', 14),\n",
       " ('pumpkin_seed', 14),\n",
       " ('broccoli', 14),\n",
       " ('caramel', 14),\n",
       " ('ground_beef', 14),\n",
       " ('butter_extract', 14),\n",
       " ('pimento_pepper', 14),\n",
       " ('mushroom', 14),\n",
       " ('mandarin_orange', 14),\n",
       " ('stevia', 14),\n",
       " ('radish', 13),\n",
       " ('venison', 13),\n",
       " ('food_coloring', 13),\n",
       " ('pasta', 13),\n",
       " ('dried_rosemary', 13),\n",
       " ('all_purpose_flour', 12),\n",
       " ('paprika', 12),\n",
       " ('olive_oil', 12),\n",
       " ('matzo', 12),\n",
       " ('bread', 12),\n",
       " ('milk', 12),\n",
       " ('chicken', 12),\n",
       " ('vegetable_bouillon', 12),\n",
       " ('vinaigrette', 12),\n",
       " ('baking_soda', 11),\n",
       " ('lime', 11),\n",
       " ('mixed_berry', 11),\n",
       " ('lentil', 11),\n",
       " ('jalapeno_pepper', 11),\n",
       " ('banana', 11),\n",
       " ('round_steak', 11),\n",
       " ('cheddar_cheese', 11),\n",
       " ('wine', 11),\n",
       " ('rosemary', 11),\n",
       " ('pineapple', 11),\n",
       " ('portobello_mushroom', 11),\n",
       " ('ground_cumin', 11),\n",
       " ('beef_part', 11),\n",
       " ('dried_onion', 11),\n",
       " ('skewer', 11),\n",
       " ('vegetarian_crumbles', 10),\n",
       " ('cheese', 10),\n",
       " ('ham', 10),\n",
       " ('milk_chocolate', 10),\n",
       " ('date', 10),\n",
       " ('carrot', 10),\n",
       " ('chicken_base', 10),\n",
       " ('cornflakes_cereal', 10),\n",
       " ('onion_powder', 10),\n",
       " ('cereal', 10),\n",
       " ('shiitake_mushroom', 10),\n",
       " ('lemon_juice', 10),\n",
       " ('pork_shoulder', 10),\n",
       " ('celery_root', 9),\n",
       " ('apple_jam', 9),\n",
       " ('spread_dip', 9),\n",
       " ('mixed_nut', 9),\n",
       " ('trout', 9),\n",
       " ('chicken_bouillon', 9),\n",
       " ('champagne', 9),\n",
       " ('corned_beef', 9),\n",
       " ('sauce', 9),\n",
       " ('kombu', 9),\n",
       " ('white_wine', 9),\n",
       " ('dried_currant', 9),\n",
       " ('whole_black_peppercorn', 9),\n",
       " ('toffee', 9),\n",
       " ('chorizo_sausage', 9),\n",
       " ('sea_bass', 9),\n",
       " ('hoagie_roll', 9),\n",
       " ('beef_tri_tip', 9),\n",
       " ('salmon', 9),\n",
       " ('garbanzo_bean', 9),\n",
       " ('catfish', 9),\n",
       " ('fruit_juice', 9),\n",
       " ('mixed_baby_green', 9),\n",
       " ('baking_powder', 8),\n",
       " ('mint', 8),\n",
       " ('triple_sec', 8),\n",
       " ('whole_wheat_bread', 8),\n",
       " ('ground_nutmeg', 8),\n",
       " ('mustard', 8),\n",
       " ('gumdrop', 8),\n",
       " ('pork_chop', 8),\n",
       " ('candied_pineapple', 8),\n",
       " ('cashew', 8),\n",
       " ('lemonade', 8),\n",
       " ('egg_noodle', 8),\n",
       " ('gochujang', 8),\n",
       " ('ground_cinnamon', 8),\n",
       " ('thyme', 8),\n",
       " ('shrimp', 8),\n",
       " ('chive', 8),\n",
       " ('salsa', 8),\n",
       " ('bottom_round_roast', 8),\n",
       " ('sweet_potato', 8),\n",
       " ('whiskey', 8),\n",
       " ('seafood_stock', 7),\n",
       " ('cream_cheese', 7),\n",
       " ('mayonnaise', 7),\n",
       " ('ginger', 7),\n",
       " ('bacon', 7),\n",
       " ('apple', 7),\n",
       " ('white_onion', 7),\n",
       " ('pepper_jam', 7),\n",
       " ('irish_cream_liqueur', 7),\n",
       " ('dried_savory', 7),\n",
       " ('cooky', 7),\n",
       " ('rom_tomato', 7),\n",
       " ('nori', 7),\n",
       " ('curry_powder', 7),\n",
       " ('fettuccine_pasta', 7),\n",
       " ('tomato', 7),\n",
       " ('margarine', 7),\n",
       " ('black_walnut', 7),\n",
       " ('pistachio', 7),\n",
       " ('mixed_vegetable', 7),\n",
       " ('chipotle_pepper', 7),\n",
       " ('pea', 7),\n",
       " ('cherry_liqueur', 7),\n",
       " ('dried_sage', 7),\n",
       " ('chili_sauce', 7),\n",
       " ('orange', 7),\n",
       " ('plum', 7),\n",
       " ('evaporated_milk', 7),\n",
       " ('whole_milk', 7),\n",
       " ('yellow_bell_pepper', 7),\n",
       " ('sour_cream', 7),\n",
       " ('brioche', 6),\n",
       " ('french_fried_onion', 6),\n",
       " ('dried_cranberry', 6),\n",
       " ('coconut_extract', 6),\n",
       " ('pink_peppercorn', 6),\n",
       " ('semisweet_chocolate_chip', 6),\n",
       " ('whole_kernel_corn', 6),\n",
       " ('seasoning', 6),\n",
       " ('egg_white', 6),\n",
       " ('candied_citron', 6),\n",
       " ('crescent_roll', 6),\n",
       " ('candy_coated_chocolate', 6),\n",
       " ('buckwheat', 6),\n",
       " ('shortening', 6),\n",
       " ('dried_marjoram', 6),\n",
       " ('blueberry', 6),\n",
       " ('haddock', 6),\n",
       " ('sherry', 6),\n",
       " ('endive', 6),\n",
       " ('chili_powder', 6),\n",
       " ('grape_jam', 6),\n",
       " ('collard_green', 6),\n",
       " ('coconut', 6),\n",
       " ('chocolate_flavored_syrup', 6),\n",
       " (\"confectioners'_sugar\", 6),\n",
       " ('worcestershire_sauce', 6),\n",
       " ('ground_bison', 6),\n",
       " ('yukon_gold_potato', 6),\n",
       " ('bay_leaf', 6),\n",
       " ('beer', 6),\n",
       " ('soy_sauce', 6),\n",
       " ('beef_dripping', 6),\n",
       " ('cinnamon_stick', 5),\n",
       " ('chicken_stock', 5),\n",
       " ('rose_water', 5),\n",
       " ('edamame', 5),\n",
       " ('ground_ginger', 5),\n",
       " ('sweet_onion', 5),\n",
       " ('steak_seasoning', 5),\n",
       " ('red_potato', 5),\n",
       " ('raw_sugar', 5),\n",
       " ('sparkling_wine', 5),\n",
       " ('crabmeat', 5),\n",
       " ('squash', 5),\n",
       " ('zucchini', 5),\n",
       " ('ground_clove', 5),\n",
       " ('plain_yogurt', 5),\n",
       " ('wheat_cereal', 5),\n",
       " ('almond_meal', 5),\n",
       " ('tea', 5),\n",
       " ('frozen_whipped_topping', 5),\n",
       " ('dried_fig', 5),\n",
       " ('lemon_extract', 5),\n",
       " ('applesauce', 5),\n",
       " ('candy', 5),\n",
       " ('oatmeal', 5),\n",
       " ('yellow_squash', 5),\n",
       " ('heavy_cream', 5),\n",
       " ('pepper', 5),\n",
       " ('pork_loin', 5),\n",
       " ('prosciutto', 5),\n",
       " ('beef_stock', 5),\n",
       " ('apricot', 5),\n",
       " ('cucumber', 5),\n",
       " ('granny_smith_apple', 5),\n",
       " ('orange_juice', 5),\n",
       " ('smoked_sausage', 5),\n",
       " ('seedless_grape', 5),\n",
       " ('schnapps', 5),\n",
       " ('italian_salad_dressing', 5),\n",
       " ('bitter', 5),\n",
       " ('oregano', 5),\n",
       " ('prawn', 5),\n",
       " ('mango_nectar', 5),\n",
       " ('white_vinegar', 5),\n",
       " ('beef_sirloin', 5),\n",
       " ('herbes_de_provence', 5),\n",
       " ('barbeque_seasoning', 5),\n",
       " ('strawberry_jam', 5),\n",
       " ('cauliflower', 5),\n",
       " ('sucanat', 5),\n",
       " ('macaroni', 5),\n",
       " ('flavored_syrup', 5),\n",
       " ('ciabatta_roll', 5),\n",
       " ('sparkling_water', 5),\n",
       " ('beau_monde_seasoning', 5),\n",
       " ('chocolate_hazelnut_spread', 4),\n",
       " ('cherry_tomato', 4),\n",
       " ('soup_mix', 4),\n",
       " ('fire_roasted_tomato', 4),\n",
       " ('ground_white_pepper', 4),\n",
       " ('beef', 4),\n",
       " ('pepperoncini_pepper', 4),\n",
       " ('ranch_dressing', 4),\n",
       " ('maple_syrup', 4),\n",
       " ('himalayan_salt', 4),\n",
       " ('cracker', 4),\n",
       " ('cranberry_juice', 4),\n",
       " ('bulgur', 4),\n",
       " ('anise_liqueur', 4),\n",
       " ('whipped_topping', 4),\n",
       " ('avocado', 4),\n",
       " ('green_bean', 4),\n",
       " ('raspberry_jam', 4),\n",
       " ('seashell_pasta', 4),\n",
       " ('ground_turmeric', 4),\n",
       " ('turnip', 4),\n",
       " ('dried_cherry', 4),\n",
       " ('rolled_oat', 4),\n",
       " ('prune', 4),\n",
       " ('other_meat', 4),\n",
       " ('linguine_pasta', 4),\n",
       " ('stewed_tomato', 4),\n",
       " ('beef_tenderloin', 4),\n",
       " ('red_currant_jam', 4),\n",
       " ('tuna', 4),\n",
       " ('flower', 4),\n",
       " ('shallot', 4),\n",
       " ('browning_sauce', 4),\n",
       " ('dried_dill_weed', 4),\n",
       " ('honey', 4),\n",
       " ('wonton_wrapper', 4),\n",
       " ('ketchup', 4),\n",
       " ('farfalle_pasta', 4),\n",
       " ('bratwurst', 4),\n",
       " ('pineapple_juice', 4),\n",
       " ('chuck_roast', 4),\n",
       " ('red_wine_vinegar', 4),\n",
       " ('bread_crumb', 4),\n",
       " ('yam', 4),\n",
       " ('sourdough_bread', 4),\n",
       " ('raspberry_vinaigrette', 4),\n",
       " ('french_bread', 4),\n",
       " ('doughnut', 4),\n",
       " ('arugula', 4),\n",
       " ('lime_juice', 4),\n",
       " ('coconut_sugar', 4),\n",
       " ('spaghetti', 4),\n",
       " ('dinner_roll', 4),\n",
       " ('sherbet', 4),\n",
       " ('queso_fresco', 4),\n",
       " ('garlic_salt', 4),\n",
       " ('celery', 3),\n",
       " ('skirt_steak', 3),\n",
       " ('swordfish', 3),\n",
       " ('lime_zest', 3),\n",
       " ('stuffing', 3),\n",
       " ('maple_extract', 3),\n",
       " ('barley_cereal', 3),\n",
       " ('dry_active_yeast', 3),\n",
       " ('coconut_milk', 3),\n",
       " ('poppy_seed', 3),\n",
       " ('gummy_candy', 3),\n",
       " ('rutabaga', 3),\n",
       " ('parsnip', 3),\n",
       " ('cinnamon_candy', 3),\n",
       " ('apple_juice', 3),\n",
       " ('whole_clove', 3),\n",
       " ('topping', 3),\n",
       " ('black_bean', 3),\n",
       " ('tomato_sauce', 3),\n",
       " ('pear', 3),\n",
       " ('turkey_stock', 3),\n",
       " ('eggplant', 3),\n",
       " ('black_olive', 3),\n",
       " ('adobo_sauce', 3),\n",
       " ('vegetable_protein', 3),\n",
       " ('dried_apricot', 3),\n",
       " ('biscuit', 3),\n",
       " ('marshmallow', 3),\n",
       " ('spearmint', 3),\n",
       " ('cider_vinegar', 3),\n",
       " ('peach_nectar', 3),\n",
       " ('pancetta', 3),\n",
       " ('egg_yolk', 3),\n",
       " ('rice_vermicelli', 3),\n",
       " ('cranberry', 3),\n",
       " ('chicken_broth', 3),\n",
       " ('flavored_vodka', 3),\n",
       " ('bread_roll', 3),\n",
       " ('sunflower_seed', 3),\n",
       " ('sesame_seed', 3),\n",
       " ('sage', 3),\n",
       " ('green_olive', 3),\n",
       " ('marinade', 3),\n",
       " ('corn_tortilla', 3),\n",
       " ('monterey_jack_cheese', 3),\n",
       " ('chayote_squash', 3),\n",
       " ('tomato_paste', 3),\n",
       " ('cantaloupe', 3),\n",
       " ('animal_fat', 3),\n",
       " ('flatbread', 3),\n",
       " ('citric_acid_powder', 3),\n",
       " ('coffee_liqueur', 3),\n",
       " ('dijon_mustard', 3),\n",
       " ('mustard_green', 3),\n",
       " ('walleye', 3),\n",
       " ('cake', 3),\n",
       " ('mixed_fruit', 3),\n",
       " ('cornbread', 3),\n",
       " ('decorating_gel', 3),\n",
       " ('artichoke', 2),\n",
       " ('sriracha_sauce', 2),\n",
       " ('almond_flour', 2),\n",
       " ('hawaiian_bread_roll', 2),\n",
       " ('skinless_boneless_chicken_breast', 2),\n",
       " ('barbeque_sauce', 2),\n",
       " ('dark_chocolate', 2),\n",
       " ('poultry_seasoning', 2),\n",
       " ('cassava_flour', 2),\n",
       " ('candied_citrus_peel', 2),\n",
       " ('masa_harina', 2),\n",
       " ('popcorn', 2),\n",
       " ('candied_orange_peel', 2),\n",
       " ('asparagus', 2),\n",
       " ('wood_chip', 2),\n",
       " ('fish_stock', 2),\n",
       " ('poblano_pepper', 2),\n",
       " ('espresso', 2),\n",
       " ('walnut', 2),\n",
       " ('pecan', 2),\n",
       " ('hazelnut_liqueur', 2),\n",
       " ('celery_salt', 2),\n",
       " ('ladyfinger', 2),\n",
       " ('mint_chocolate_chip', 2),\n",
       " ('oat_cereal', 2),\n",
       " ('lamb_shoulder', 2),\n",
       " ('semisweet_chocolate', 2),\n",
       " ('cocoa_powder', 2),\n",
       " ('sea_scallop', 2),\n",
       " ('cherry', 2),\n",
       " ('banana_liqueur', 2),\n",
       " ('angel_hair_pasta', 2),\n",
       " ('processed_cheese', 2),\n",
       " ('onion_salt', 2),\n",
       " ('cabbage', 2),\n",
       " ('vegetable_juice', 2),\n",
       " ('green_tomato', 2),\n",
       " ('roasted_red_pepper', 2),\n",
       " ('vermicelli_pasta', 2),\n",
       " ('maraschino_cherry', 2),\n",
       " ('low_fat_milk', 2),\n",
       " ('green_pea', 2),\n",
       " ('potato_chip', 2),\n",
       " ('romaine_lettuce', 2),\n",
       " ('tortellini', 2),\n",
       " ('veal', 2),\n",
       " ('hash_brown', 2),\n",
       " ('ground_mace', 2),\n",
       " ('kiwi', 2),\n",
       " ('gingersnap_cooky', 2),\n",
       " ('taco_sauce', 2),\n",
       " ('watermelon', 2),\n",
       " ('pierogies', 2),\n",
       " ('rice', 2),\n",
       " ('steak', 2),\n",
       " ('ground_lamb', 2),\n",
       " ('blackberry_jam', 2),\n",
       " ('soda', 2),\n",
       " ('dry_vermouth', 2),\n",
       " ('limeade', 2),\n",
       " ('raspberry_liqueur', 2),\n",
       " ('whole_wheat_tortilla', 2),\n",
       " ('sirloin', 2),\n",
       " ('noodle', 2),\n",
       " ('huckleberry', 2),\n",
       " ('sweet_pickle', 2),\n",
       " ('corn_chip', 2),\n",
       " ('molasses', 2),\n",
       " ('ice', 2),\n",
       " ('habanero_pepper', 2),\n",
       " ('creme_fraiche', 2),\n",
       " ('tomato_puree', 2),\n",
       " ('jicama', 2),\n",
       " ('ground_pork', 2),\n",
       " ('dark_chocolate_chip', 2),\n",
       " ('absinthe_liqueur', 2),\n",
       " ('apple_cider', 2),\n",
       " ('thousand_island_dressing', 2),\n",
       " ('pesto', 2),\n",
       " ('okra', 2),\n",
       " ('caraway_seed', 2),\n",
       " ('fennel_seed', 2),\n",
       " ('aluminum_foil', 2),\n",
       " ('black_eyed_pea', 2),\n",
       " ('chocolate_chip', 2),\n",
       " ('white_chocolate', 2),\n",
       " ('dill', 2),\n",
       " ('rice_flour', 2),\n",
       " ('egg_substitute', 2),\n",
       " ('green_chile_pepper', 2),\n",
       " ('crystallized_ginger', 2),\n",
       " ('pita_bread', 2),\n",
       " ('cannellini_bean', 2),\n",
       " ('kale', 2),\n",
       " ('lard', 2),\n",
       " ('leek', 2),\n",
       " ('chili_oil', 2),\n",
       " ('dried_cilantro', 2),\n",
       " ('colby_cheese', 2),\n",
       " ('pigeon_pea', 2),\n",
       " ('jelly_bean', 2),\n",
       " ('liquid_smoke', 2),\n",
       " ('feta_cheese', 2),\n",
       " ('zucchini_blossom', 2),\n",
       " ('rice_vinegar', 2),\n",
       " ('pork_sausage', 2),\n",
       " ('pine_nut', 2),\n",
       " ('mirin', 2),\n",
       " ('white_fish', 2),\n",
       " ('bologna', 2),\n",
       " ('hot_dog_bun', 2),\n",
       " ('chickpea_flour', 2),\n",
       " ('flavored_gelatin', 2),\n",
       " ('sweet_pickle_relish', 2),\n",
       " ('hemp_seed', 2),\n",
       " ('papaya', 2),\n",
       " ('crouton', 2),\n",
       " ('rib_eye_steak', 2),\n",
       " ('smoked_paprika', 2),\n",
       " ('ground_coriander', 2),\n",
       " ('ground_chile_pepper', 2),\n",
       " ('kitchen_twine', 2),\n",
       " ('salami', 2),\n",
       " ('garlic_paste', 1),\n",
       " ('flavored_rum', 1),\n",
       " ('chicken_carcass', 1),\n",
       " ('key_lime_juice', 1),\n",
       " ('flounder', 1),\n",
       " ('rice_wine', 1),\n",
       " ('puff_pastry', 1),\n",
       " ('ground_allspice', 1),\n",
       " ('skim_milk', 1),\n",
       " ('licorice', 1),\n",
       " ('persimmon', 1),\n",
       " ('walnut_oil', 1),\n",
       " ('apricot_jam', 1),\n",
       " ('nut_butter', 1),\n",
       " ('mexican_crema', 1),\n",
       " ('orange_extract', 1),\n",
       " ('blackberry', 1),\n",
       " ('rice_cereal', 1),\n",
       " ('peppermint_extract', 1),\n",
       " ('peanut_butter', 1),\n",
       " ('apricot_nectar', 1),\n",
       " ('milk_chocolate_chip', 1),\n",
       " ('candy_cane', 1),\n",
       " ('corn_syrup', 1),\n",
       " ('light_cream', 1),\n",
       " ('chocolate_pudding_mix', 1),\n",
       " ('yellow_corn', 1),\n",
       " ('tapioca', 1),\n",
       " ('mussel', 1),\n",
       " ('teriyaki_sauce', 1),\n",
       " ('hominy', 1),\n",
       " ('amaranth', 1),\n",
       " ('tarragon', 1),\n",
       " ('firm_tofu', 1),\n",
       " ('raisin_bread', 1),\n",
       " ('pie_filling', 1),\n",
       " ('golden_delicious_apple', 1),\n",
       " ('cheese_tortellini', 1),\n",
       " ('snow_pea', 1),\n",
       " ('fajita_seasoning', 1),\n",
       " ('baby_carrot', 1),\n",
       " ('pork_roast', 1),\n",
       " ('cherry_pie_filling', 1),\n",
       " ('chicken_breast', 1),\n",
       " ('radicchio', 1),\n",
       " ('white_bean', 1),\n",
       " ('leg_of_lamb', 1),\n",
       " ('white_wine_vinegar', 1),\n",
       " ('biscuit_dough', 1),\n",
       " ('turkey', 1),\n",
       " ('whipped_cream', 1),\n",
       " ('ham_hock', 1),\n",
       " ('apple_butter', 1),\n",
       " ('other_fish', 1),\n",
       " ('drink_mix', 1),\n",
       " ('hot_chocolate_mix', 1),\n",
       " ('fava_bean', 1),\n",
       " ('chicken_drumstick', 1),\n",
       " ('corn', 1),\n",
       " ('sweetened_condensed_milk', 1),\n",
       " ('chocolate_cake_mix', 1),\n",
       " ('phyllo_dough', 1),\n",
       " ('macintosh_apple', 1),\n",
       " ('canning_jar_with_lid_and_ring', 1),\n",
       " ('miso_paste', 1),\n",
       " ('picante_sauce', 1),\n",
       " ('peppermint_candy', 1),\n",
       " ('ear_corn', 1),\n",
       " ('kaffir_lime_leaf', 1),\n",
       " ('kimchi', 1),\n",
       " ('morel_mushroom', 1),\n",
       " ('chanterelle_mushroom', 1),\n",
       " ('garlic_pepper_seasoning', 1),\n",
       " ('celery_seed', 1),\n",
       " ('split_pea', 1),\n",
       " ('goose', 1),\n",
       " ('lamb_stew_meat', 1),\n",
       " ('whole_wheat_flour', 1),\n",
       " ('wheat_berry', 1),\n",
       " ('millet', 1),\n",
       " ('barley', 1),\n",
       " ('toothpick', 1),\n",
       " ('champagne_vinegar', 1),\n",
       " ('chocolate', 1),\n",
       " ('dr_pepper_soda', 1),\n",
       " ('soy_milk', 1),\n",
       " ('rib_roast', 1),\n",
       " ('sweet_and_sour_sauce', 1),\n",
       " ('caper', 1),\n",
       " ('candied_mixed_fruit', 1),\n",
       " ('mahi_mahi', 1),\n",
       " ('sour_cherry', 1),\n",
       " ('baby_corn', 1),\n",
       " ('steak_sauce', 1),\n",
       " ('dill_pickle_juice', 1),\n",
       " ('chile_pepper', 1),\n",
       " ('meat_tenderizer', 1),\n",
       " ('ricotta_cheese', 1),\n",
       " ('creamy_salad_dressing', 1),\n",
       " ('goat_cheese', 1),\n",
       " ('grapefruit', 1),\n",
       " ('spinach', 1),\n",
       " ('cola_soda', 1),\n",
       " ('pumpernickel_bread', 1),\n",
       " ('salt_pork', 1),\n",
       " ('beet', 1),\n",
       " ('greek_yogurt', 1),\n",
       " ('fennel', 1),\n",
       " ('serrano_pepper', 1),\n",
       " ('tomato_soup', 1),\n",
       " ('penne_pasta', 1),\n",
       " ('beef_consomme', 1),\n",
       " ('beef_brisket', 1),\n",
       " ('asiago_cheese', 1),\n",
       " ('other_milk', 1),\n",
       " ('mango', 1),\n",
       " ('pomegranate', 1),\n",
       " ('chia_seed', 1),\n",
       " ('maple_sugar', 1),\n",
       " ('creme_de_cacao_liqueur', 1),\n",
       " ('chocolate_ice_cream', 1),\n",
       " ('water_chestnut', 1),\n",
       " ('grape_leaf', 1),\n",
       " ('tortilla_chip', 1),\n",
       " ('baking_mix', 1),\n",
       " ('spanish_onion', 1),\n",
       " ('banana_pepper', 1),\n",
       " ('balsamic_vinegar', 1),\n",
       " ('dried_apple', 1),\n",
       " ('pickled_ginger', 1),\n",
       " ('dried_mixed_fruit', 1),\n",
       " ('blue_cheese_dressing', 1),\n",
       " ('mung_bean', 1),\n",
       " ('salt_free_seasoning', 1),\n",
       " (\"pig's_part\", 1),\n",
       " ('heart_of_palm', 1),\n",
       " ('eggnog', 1),\n",
       " ('superfine_sugar', 1),\n",
       " ('oyster_sauce', 1),\n",
       " ('coconut_flour', 1),\n",
       " ('enchilada_sauce', 1),\n",
       " ('new_potato', 1),\n",
       " ('chipotle_chile_pepper', 1),\n",
       " ('mexican_style_corn', 1),\n",
       " ('blackening_seasoning', 1),\n",
       " ('turkey_dripping', 1),\n",
       " ('russet_potato', 1),\n",
       " ('herb', 1),\n",
       " ('brown_rice', 1),\n",
       " ('rice_noodle', 1),\n",
       " ('white_rice', 1),\n",
       " ('melon', 1),\n",
       " ('scotch_whiskey', 1),\n",
       " ('cheese_sauce', 1),\n",
       " ('lamb_shank', 1),\n",
       " ('kaiser_roll', 1),\n",
       " ('pumpkin_pie_spice', 1),\n",
       " ('fusilli_pasta', 1),\n",
       " ('sugar', 1),\n",
       " ('southern_comfort_liqueur', 1),\n",
       " ('corn_flour', 1),\n",
       " ('citrus_soda', 1),\n",
       " ('clementine', 1),\n",
       " ('tofu', 1),\n",
       " ('mexican_cheese_blend', 1),\n",
       " ('mozzarella_cheese', 1),\n",
       " ('turkey_carcass', 1),\n",
       " ('sun_dried_tomato', 1),\n",
       " ('sweet_chocolate', 1),\n",
       " ('rose', 1),\n",
       " ('mustard_seed', 1),\n",
       " ('pumpkin_puree', 1),\n",
       " ('tequila', 1),\n",
       " ('liquid_amino', 1),\n",
       " ('canola_oil', 1),\n",
       " ('pearl_onion', 1),\n",
       " ('anise_seed', 1),\n",
       " ('asafoetida_powder', 1),\n",
       " ('pastry_flour', 1),\n",
       " ('cumin_seed', 1),\n",
       " ('unsalted_butter', 1),\n",
       " ('potato', 1),\n",
       " ('wheat', 1),\n",
       " ('buttery_cracker', 1),\n",
       " ('pizza', 1),\n",
       " ('coconut_amino', 1),\n",
       " ('chestnut', 1),\n",
       " ('escarole', 1),\n",
       " ('vanilla_ice_cream', 1),\n",
       " ('protein_powder', 1),\n",
       " ('garam_masala', 1),\n",
       " ('corn_cereal', 1),\n",
       " ('gluten_free_all_purpose_flour', 1),\n",
       " ('roasted_garlic', 1),\n",
       " ('sake', 1),\n",
       " ('peppercorn', 1),\n",
       " ('chutney', 1),\n",
       " ('gouda_cheese', 1),\n",
       " ('cassava', 1),\n",
       " ('coconut_flavored_rum', 1),\n",
       " ('pickle', 1),\n",
       " ('vegetable_stock', 1),\n",
       " ('caramel_topping', 1),\n",
       " ('duck', 1),\n",
       " ('butternut_squash', 1),\n",
       " ('raspberry_extract', 1),\n",
       " ('star_anise', 1),\n",
       " ('cardamom', 1),\n",
       " ('blood_orange', 1),\n",
       " ('beef_bouillon', 1),\n",
       " ('rye_bread', 1),\n",
       " ('pork_tenderloin', 1),\n",
       " ('nutritional_yeast', 1),\n",
       " ('porcini_mushroom', 1),\n",
       " ('milk_powder', 1),\n",
       " ('cornish_game_hen', 1)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ignore_flag = True\n",
    "\n",
    "if ignore_flag:    \n",
    "    # uncomment below to ignore some ingre\n",
    "    no_match_list_flat_2 = list(itertools.chain.from_iterable(matched_df2.no_match_after_ignore))\n",
    "else:\n",
    "    no_match_list_flat_2 = list(itertools.chain.from_iterable(matched_df2.no_match))\n",
    "\n",
    "count_no_match_2 = Counter(no_match_list_flat_2)\n",
    "count_no_match_2 = count_no_match_2.most_common()\n",
    "print(len(count_no_match_2))\n",
    "count_no_match_2 # ingre at least not matched in 1 recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3b1f6aa6f374c869c157f938a335fea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=57709.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dict_cluster_count_ignore = defaultdict(int)\n",
    "for i in tqdm(range(0,len(matched_df2))):\n",
    "    recipe_id = matched_df2.loc[i, 'recipe_id']\n",
    "    recipe = [dict_ingredient_clustername[ingre_id] for ingre_id in dict_recipe_ingredients[recipe_id]]\n",
    "    ignore_bean_flag = matched_df2.loc[i, 'ignore_bean_flag']\n",
    "    ignore_some_flag = matched_df2.loc[i, 'ignore_some_flag']\n",
    "    ignore_unsaltedbutter_flag = matched_df2.loc[i, 'ignore_unsaltedbutter_flag']\n",
    "    ignore_greenchile_flag = matched_df2.loc[i, 'ignore_greenchile_flag']\n",
    "    ignore_all_flag = matched_df2.loc[i, 'ignore_all_flag']\n",
    "    \n",
    "    for ingre in recipe:\n",
    "        if ((ingre in ignore_ingre_list) and (ignore_some_flag == True)) \\\n",
    "            or ((ingre == 'bean') and (ignore_bean_flag == True)) \\\n",
    "            or ((ingre == 'unsalted_butter') and (ignore_unsaltedbutter_flag == True))\\\n",
    "            or ((ingre == 'green_chile_pepper') and (ignore_greenchile_flag == True)) \\\n",
    "            or (ignore_all_flag == True):\n",
    "            continue\n",
    "        else:\n",
    "            dict_cluster_count_ignore[ingre] += 1 # this cluster appear +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba1b7e4d5d454a4aaac42e4be86adc2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(4161, 762)\n",
      "There are 57709 recipes in total.\n",
      "There are 4161 recipes with at least 1 ingredient not matched.\n",
      "There are 762 unique ingredients not matched in at least 1 recipe out of 57709 recipes.\n",
      "There are 713 unique ingredients not matched in <= 20 % of its appearances.\n",
      "There are 49 unique ingredients not matched in > 20 % of its appearances.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Not matched in % of its appearances')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_no_match_unique_2 = set(no_match_list_flat_2)\n",
    "\n",
    "if ignore_flag == True:\n",
    "    matched_df_missing_2 = matched_df2.loc[:,['recipe_id', 'no_match_after_ignore']]\n",
    "    no_match_span_df_2 = pd.concat([pd.Series(row['recipe_id'], row['no_match_after_ignore']) for _, row in tqdm(matched_df_missing_2.iterrows())]).reset_index()\n",
    "    no_match_span_df_2.columns = ['missing_ingredient', 'recipe_id']\n",
    "    missing_matrix_2 = pd.pivot_table(no_match_span_df_2, values='missing_ingredient', index=['recipe_id'], columns=['missing_ingredient'], aggfunc=lambda x: len(x))\n",
    "    missing_matrix_2 = missing_matrix_2.fillna(0)\n",
    "    print(missing_matrix_2.shape) # row is each recipe, col is each (missing) ingre\n",
    "    missing_in_num_recipes_2 = [(col, col_sum) for col, col_sum in missing_matrix_2.sum().iteritems()]\n",
    "    missing_pct_2 = [(col, (col_sum / dict_cluster_count_ignore[col])*100) for (col, col_sum) in missing_in_num_recipes_2]\n",
    "else:    \n",
    "    matched_df_missing_2 = matched_df2.loc[:,['recipe_id', 'no_match']]\n",
    "    no_match_span_df_2 = pd.concat([pd.Series(row['recipe_id'], row['no_match']) for _, row in tqdm(matched_df_missing_2.iterrows())]).reset_index()\n",
    "    no_match_span_df_2.columns = ['missing_ingredient', 'recipe_id']\n",
    "    missing_matrix_2 = pd.pivot_table(no_match_span_df_2, values='missing_ingredient', index=['recipe_id'], columns=['missing_ingredient'], aggfunc=lambda x: len(x))\n",
    "    missing_matrix_2 = missing_matrix_2.fillna(0)\n",
    "    print(missing_matrix_2.shape) # row is each recipe, col is each (missing) ingre\n",
    "    missing_in_num_recipes_2 = [(col, col_sum) for col, col_sum in missing_matrix_2.sum().iteritems()]\n",
    "    missing_pct_2 = [(col, (col_sum / dict_cluster_count[col])*100) for (col, col_sum) in missing_in_num_recipes_2]\n",
    "\n",
    "\n",
    "thres_pct = 20\n",
    "print('There are', len(no_match_list), 'recipes in total.')\n",
    "print('There are', len(missing_matrix_2), 'recipes with at least 1 ingredient not matched.')\n",
    "print('There are', len(all_no_match_unique_2), 'unique ingredients not matched in at least 1 recipe out of',len(no_match_list),'recipes.')\n",
    "print('There are', len([col for col, pct in missing_pct_2 if pct <= thres_pct]), 'unique ingredients not matched in <=', thres_pct,'% of its appearances.')\n",
    "print('There are', len(all_no_match_unique_2) - len([col for col, pct in missing_pct_2 if pct <= thres_pct]), 'unique ingredients not matched in >', thres_pct,'% of its appearances.')\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [8, 4]\n",
    "\n",
    "plt.hist([pct for col, pct in missing_pct_2], density=False, bins=200)\n",
    "plt.ylabel('Count of ingredients')\n",
    "plt.xlabel('Not matched in % of its appearances') ### change to pct, not matched / all it appearsï¼Œ sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sea_bass', 45.0),\n",
       " ('beef_part', 44.0),\n",
       " ('gumdrop', 42.10526315789473),\n",
       " ('kombu', 40.909090909090914),\n",
       " ('mixed_spice', 40.74074074074074),\n",
       " ('brioche', 40.0),\n",
       " (\"confectioners'_coating\", 40.0),\n",
       " ('pink_peppercorn', 37.5),\n",
       " ('monosodium_glutamate', 36.36363636363637),\n",
       " ('red_snapper', 35.714285714285715),\n",
       " ('sparkling_wine', 35.714285714285715),\n",
       " ('potato_nugget', 34.92063492063492),\n",
       " ('ghee', 34.40860215053764),\n",
       " ('anise_liqueur', 33.33333333333333),\n",
       " ('beau_monde_seasoning', 33.33333333333333),\n",
       " ('beef_tri_tip', 33.33333333333333),\n",
       " ('bottom_round_roast', 33.33333333333333),\n",
       " ('flower', 30.76923076923077),\n",
       " ('wheat_gluten', 30.18867924528302),\n",
       " ('flatbread', 30.0),\n",
       " ('vinaigrette', 29.268292682926827),\n",
       " ('french_baguette', 29.1970802919708),\n",
       " ('butter_extract', 28.57142857142857),\n",
       " ('seafood_stock', 28.000000000000004),\n",
       " ('sucanat', 27.77777777777778),\n",
       " ('candied_pineapple', 27.586206896551722),\n",
       " ('beef_dripping', 27.27272727272727),\n",
       " ('rice_vermicelli', 27.27272727272727),\n",
       " ('doughnut', 26.666666666666668),\n",
       " ('ground_bison', 26.08695652173913),\n",
       " ('apple_jam', 25.71428571428571),\n",
       " ('orange_liqueur', 25.142857142857146),\n",
       " ('black_walnut', 25.0),\n",
       " ('candied_citron', 25.0),\n",
       " ('cherry_liqueur', 25.0),\n",
       " ('gochujang', 25.0),\n",
       " ('pepper_jam', 25.0),\n",
       " ('spearmint', 25.0),\n",
       " ('vegetarian_crumbles', 25.0),\n",
       " ('walleye', 25.0),\n",
       " ('buckwheat', 22.22222222222222),\n",
       " ('haddock', 22.22222222222222),\n",
       " ('mixed_salad_green', 21.29032258064516),\n",
       " ('pork', 21.25984251968504),\n",
       " ('red_currant_jam', 21.052631578947366),\n",
       " ('celery_root', 20.930232558139537),\n",
       " ('mixed_baby_green', 20.930232558139537),\n",
       " ('ciabatta_roll', 20.833333333333336),\n",
       " ('liqueur', 20.618556701030926)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls = [(col,pct) for col, pct in missing_pct_2 if pct > thres_pct]\n",
    "ls.sort(key=lambda x:x[1], reverse = True)\n",
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strawberry_ice_cream: 222071, 56444, 49410\n",
    "# unsalted_butter (appear together with butter in recipe but not mentioned separately in direction): 268066, 234625\n",
    "# ground_black_pepper (appear together with pepper in recipe but not mentioned separately in direction): 275314\n",
    "# green_chile_pepper: caused by \"diced tomato with green chile pepper\", like chili with beans, e.g. 268767, 8673, 271151\n",
    "df_ingre_clean.loc[df_ingre_clean['recipe_id'].isin([271151]), :].sort_values(['recipe_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the missing ingredient, check the label2 in Final_clusters_mod.csv\n",
    "missing_ingre = 'hash_brown'\n",
    "missing_ingre_unigrams = missing_ingre.split('_')\n",
    "\n",
    "print(df_mod.loc[df_mod['cluster_name'] == ' '.join(missing_ingre_unigrams),'label2'])\n",
    "\n",
    "all_label2 = ' '.join(df_mod.loc[df_mod['cluster_name'] == ' '.join(missing_ingre_unigrams),'label2'])\n",
    "unigrams = all_label2.split(' ')\n",
    "count_unigrams = Counter(unigrams).most_common()\n",
    "if len(count_unigrams)>0:\n",
    "    possible_names = [unigram for (unigram, count) in count_unigrams if unigram \\\n",
    "                      not in unigram_exclude_list+missing_ingre_unigrams+['']\\\n",
    "                      and pos_tag([unigram])[0][1]=='NN']\n",
    "print(possible_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_ingredients_raw.loc[df_ingredients_raw['recipe_id'] == 267902,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_ingredient_clustername[84]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_recipe_list = []\n",
    "for recipe_id in tqdm(matched_df2.recipe_id):\n",
    "    # number of ingre in ingredients_after_text_cleaning.csv\n",
    "    num_ingre_1 = len(df_ingre_clean.loc[df_ingre_clean['recipe_id'] == recipe_id, :])\n",
    "    # number of ingre in Ingredients.csv\n",
    "    num_ingre_2 = len(df_ingredients_raw.loc[df_ingredients_raw['recipe_id'] == recipe_id,:])\n",
    "    if num_ingre_1 != num_ingre_2:\n",
    "        error_recipe_list.append(recipe_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output file for counting each mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd4b039261cf405ba97d9277ce6ce8be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=57709.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "# Create dict to store the count of each mapping\n",
    "dict_mapping_count = copy.deepcopy(dict_ingre_mapping)\n",
    "\n",
    "for cluster, values in dict_mapping_count.items():\n",
    "    # initialize parent count\n",
    "    parent_list = values['parent']\n",
    "    values['parent'] = {}\n",
    "    for parent in parent_list:\n",
    "        values['parent'][parent] = 0\n",
    "    \n",
    "    # initialize child count\n",
    "    child_list = values['child']\n",
    "    values['child'] = {}\n",
    "    for child in child_list:\n",
    "        values['child'][child] = 0\n",
    "    \n",
    "    # initialize synonym count\n",
    "    synonym_list = values['synonym']\n",
    "    values['synonym'] = {}\n",
    "    for synonym in synonym_list:\n",
    "        values['synonym'][synonym] = 0\n",
    "    \n",
    "    # initialize short term count\n",
    "    short_list = values['short']\n",
    "    values['short'] = {}\n",
    "    for short in short_list:\n",
    "        values['short'][short] = 0\n",
    "    \n",
    "    # initialize full match count\n",
    "    values['full'] = 0\n",
    "    \n",
    "    # initialize no match count\n",
    "    values['no'] = 0\n",
    "\n",
    "\n",
    "for cluster_name,_ in dict_cluster_count.items():\n",
    "    if cluster_name not in dict_mapping_count.keys():\n",
    "        dict_mapping_count[cluster_name]['full'] = 0\n",
    "        dict_mapping_count[cluster_name]['no'] = 0\n",
    "        dict_mapping_count[cluster_name]['short'] = {}\n",
    "        dict_mapping_count[cluster_name]['parent'] = {}\n",
    "        dict_mapping_count[cluster_name]['synonym'] = {}\n",
    "        dict_mapping_count[cluster_name]['child'] = {}\n",
    "\n",
    "# calculate the counts\n",
    "for i in tqdm(range(0,len(matched_df2))):\n",
    "    row = matched_df2.iloc[i,:]\n",
    "    perfect_match = literal_eval(row.perfect_match)\n",
    "    partial_match = literal_eval(row.partial_match)\n",
    "    dict_match = row.dict_match\n",
    "    no_match = row.no_match\n",
    "    \n",
    "    # count full match\n",
    "    for match in perfect_match:\n",
    "        dict_mapping_count[match]['full'] += 1\n",
    "    \n",
    "    # count partial match\n",
    "    for match in partial_match:\n",
    "        cluster_name = match[0]\n",
    "        short_terms = match[1]\n",
    "        for short in short_terms:\n",
    "            dict_mapping_count[cluster_name]['short'][short] += 1\n",
    "    \n",
    "    # count parent, child, synonym match\n",
    "    for match in dict_match:\n",
    "        cluster_name = match[0]\n",
    "        matched_terms = match[1]\n",
    "        parents = dict_ingre_mapping[cluster_name]['parent']\n",
    "        childs = dict_ingre_mapping[cluster_name]['child']\n",
    "        synonyms = dict_ingre_mapping[cluster_name]['synonym']\n",
    "        for term in matched_terms:\n",
    "            if term in parents:\n",
    "                dict_mapping_count[cluster_name]['parent'][term] += 1\n",
    "            elif term in childs:\n",
    "                dict_mapping_count[cluster_name]['child'][term] += 1\n",
    "            elif term in synonyms:\n",
    "                dict_mapping_count[cluster_name]['synonym'][term] += 1\n",
    "            else:\n",
    "                print(\"error!\")\n",
    "    \n",
    "    # count no match\n",
    "    for cluster_name in no_match:\n",
    "        dict_mapping_count[cluster_name]['no'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df storing the counts in dict_mapping_count\n",
    "cluster_name_list = []\n",
    "cluster_count_list = []\n",
    "full_match_count_list = []\n",
    "no_match_count_list = []\n",
    "partial_match_count_list = []\n",
    "partial_match_total_list = []\n",
    "parent_match_count_list = []\n",
    "parent_match_total_list = []\n",
    "child_match_count_list = []\n",
    "child_match_total_list = []\n",
    "synonym_match_count_list = []\n",
    "synonym_match_total_list = []\n",
    "\n",
    "for cluster_name, values in dict_mapping_count.items():\n",
    "    cluster_name_list.append(cluster_name)\n",
    "    cluster_count_list.append(dict_cluster_count[cluster_name])\n",
    "    full_match_count_list.append(values['full'])\n",
    "    no_match_count_list.append(values['no'])\n",
    "    \n",
    "    partial_matches = values['short']\n",
    "    parent_matches = values['parent']\n",
    "    child_matches = values['child']\n",
    "    synonym_matches = values['synonym']\n",
    "    \n",
    "    partial_match_total = 0\n",
    "    parent_match_total = 0\n",
    "    child_match_total = 0\n",
    "    synonym_match_total = 0\n",
    "    \n",
    "    partial_matches_this_cluster = []\n",
    "    for term, value in partial_matches.items():\n",
    "        partial_matches_this_cluster.append([term, value])\n",
    "        partial_match_total += value\n",
    "        \n",
    "    parent_matches_this_cluster = []\n",
    "    for term, value in parent_matches.items():\n",
    "        parent_matches_this_cluster.append([term, value])\n",
    "        parent_match_total += value\n",
    "            \n",
    "    child_matches_this_cluster = []\n",
    "    for term, value in child_matches.items():\n",
    "        child_matches_this_cluster.append([term, value])\n",
    "        child_match_total += value\n",
    "    \n",
    "    synonym_matches_this_cluster = []\n",
    "    for term, value in synonym_matches.items():\n",
    "        synonym_matches_this_cluster.append([term, value])\n",
    "        synonym_match_total += value\n",
    "\n",
    "    partial_match_count_list.append(partial_matches_this_cluster)\n",
    "    parent_match_count_list.append(parent_matches_this_cluster)\n",
    "    child_match_count_list.append(child_matches_this_cluster)\n",
    "    synonym_match_count_list.append(synonym_matches_this_cluster)\n",
    "    \n",
    "    partial_match_total_list.append(partial_match_total)\n",
    "    parent_match_total_list.append(parent_match_total)\n",
    "    child_match_total_list.append(child_match_total)\n",
    "    synonym_match_total_list.append(synonym_match_total)\n",
    "\n",
    "df_stats = pd.DataFrame({\n",
    "    'cluster_name': cluster_name_list,\n",
    "    'num_of_recipes': cluster_count_list,\n",
    "    'full_match_stat': full_match_count_list,\n",
    "    'no_match_stat': no_match_count_list,\n",
    "    'partial_match': partial_match_count_list,\n",
    "    'partial_match_stat': partial_match_total_list,\n",
    "    'parent_match': parent_match_count_list,\n",
    "    'parent_match_stat': parent_match_total_list,\n",
    "    'child_match': child_match_count_list,\n",
    "    'child_match_stat': child_match_total_list,\n",
    "    'synonym_match': synonym_match_count_list,\n",
    "    'synonym_match_stat': synonym_match_total_list,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats.to_csv('/Users/nessyliu/Desktop/RA/part_2/result/df_stats_w6.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
