{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import unicodedata\n",
    "import csv\n",
    "import itertools\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from nltk import word_tokenize, sent_tokenize, pos_tag, corpus\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import defaultdict, Counter\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "\n",
    "import dill as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for reading and saving Python objects\n",
    "\n",
    "def save_obj(obj, name):\n",
    "    with open('OUTPUT_OF_FINAL_CODE/'+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name):\n",
    "    with open('OUTPUT_OF_FINAL_CODE/' + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the datasets\n",
    "df_directions = pd.read_excel('input_data/AllRecipes_Directions_2019-11-26.xlsx')\n",
    "df = pd.read_csv('input_data/AllReviews_26thNov2019.csv')\n",
    "df_ingredients_raw = pd.read_csv('input_data/Ingredients.csv')\n",
    "df_cluster = pd.read_excel('input_data/Cluster_names.xlsx')\n",
    "\n",
    "df_ingre_clean = pd.read_csv('input_data/ingredients_after_text_cleaning.csv')\n",
    "df_mod = pd.read_excel('input_data/Final_clusters_mod.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_directions_list = []\n",
    "recipe_id_list = list(set(df_directions.recipe_id.tolist()))\n",
    "for recipe_id in recipe_id_list:\n",
    "    full_dir_this_recipe = ' '.join(df_directions.loc[df_directions['recipe_id']==recipe_id, 'directions_step_text'])\n",
    "    full_directions_list.append(full_dir_this_recipe)\n",
    "dict_recipe_direction = dict(zip(recipe_id_list, full_directions_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of cluster names with spaces (e.g. apple juice) sorted by number of words in each name, \n",
    "# e.g. \"apple juice\" should appear before \"juice\"\n",
    "cluster_name_orig_list = df_cluster.cluster_name.tolist()\n",
    "cluster_name_orig_list.sort(key=lambda x: len(x.split()), reverse=True)\n",
    "\n",
    "# create dict to map recipe_id to ingredient_ids\n",
    "df_ingredients = df_ingredients_raw.groupby('recipe_id')['ingredient_id'].apply(list).reset_index(name ='ingredients')\n",
    "dict_recipe_ingredients = dict(zip(df_ingredients.recipe_id, df_ingredients.ingredients))\n",
    "\n",
    "# create dict to map ingredient_id to cluster_name\n",
    "df_cluster = df_cluster.replace(' ', '_', regex=True)\n",
    "dict_ingredient_clustername = dict(zip(df_cluster.ingredient_id, df_cluster.cluster_name))\n",
    "\n",
    "# get all the recipe_id that has review data\n",
    "recipe_id_has_review_list = list(set(df['recipe_id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatization dict\n",
    "lemma_list = pd.read_csv('input_data/lemma_list.csv')\n",
    "lemma_dict = lemma_list.set_index('word_list').to_dict()['lemma_list']\n",
    "\n",
    "def lemmatization(text):\n",
    "    \n",
    "    # list of words that are forced not to lemmatize, those are the words appearing in cluster names\n",
    "    force_keep_list = ['corned', 'sparkling', 'canning', 'roasted', 'baked', 'processed', 'flavored', \n",
    "                       'colored', 'candied', 'stuffing', 'dressing', 'shortening', \"pig's\", 'based',\n",
    "                       'stewed', 'curing', 'decorating', 'coated', 'evaporated', 'pickled', 'fried',\n",
    "                       'dripping', 'rising', \"confectioners'\", 'frying', 'coating', 'smoked', 'seasoned',\n",
    "                       'rolled', 'filling', \"devil's\", 'sweetened', 'dried', 'pickling', 'topping', 'frosting',\n",
    "                       'coloring', 'rose', 'pulled', 'crystallized', 'seasoning', 'whipped', 'condensed','baking',\n",
    "                      'frenchfries', 'fries', 'flavoring']\n",
    "    \n",
    "    text = text.lower()\n",
    "    \n",
    "    text = text.replace('-n-', ' and ')\n",
    "    text = text.replace(' & ', ' and ')\n",
    "    text = text.replace('&', ' and ')\n",
    "    text = text.replace('-', ' ')\n",
    "    \n",
    "    text = text.replace('sugar substitute', 'sweetener').replace('french fries','frenchfries')\n",
    "    text = text.replace('dry milk', 'milk powder').replace('powder milk', 'milk powder')\n",
    "    text = text.replace('lowfat',\n",
    "                        'low fat').replace('nonfat',\n",
    "                                                    'non fat').replace('glutenfree',\n",
    "                                                                       'gluten free').replace('corn flakes',\n",
    "                                                                                              'cornflakes')\n",
    "    text = text.replace('flaxseed',\n",
    "                        'flax seed').replace('lemongrass', 'lemon grass')\n",
    "    text = text.replace('coconutmilk',\n",
    "                        'coconut milk').replace('almondmilk',\n",
    "                                                'almond milk').replace('crab meat',\n",
    "                                                                       'crabmeat').replace('starfruit', \n",
    "                                                                                           'star fruit').replace('breadcrumb', \n",
    "                                                                                                                 'bread crumb')\n",
    "    text = text.replace('red and yellow bell pepper', \n",
    "                        'red bell pepper and yellow bell pepper').replace('red and green bell pepper', \n",
    "                                                                          'red bell pepper and green bell pepper')\n",
    "\n",
    "    # use the custom lemma dict first\n",
    "    text = \" \".join(str(lemma_dict.get(word, word)) for word in text.split())\n",
    "    \n",
    "    # then use the WordNetLemmatizer from nltk\n",
    "    wnl = WordNetLemmatizer()\n",
    "    \n",
    "    word_list = word_tokenize(text)\n",
    "    word_list_after = []\n",
    "    \n",
    "    for word in word_list:\n",
    "        # word by word (otherwise tag may differ), lemmatize each word based on its pos tagging, exclude words in force keep list\n",
    "        w,t = pos_tag([word])[0]\n",
    "        if t[0].lower() in ['a','n','v'] and word not in force_keep_list:\n",
    "            word = wnl.lemmatize(word,t[0].lower())\n",
    "        word_list_after.append(word)\n",
    "    return ' '.join(word_list_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "unigram_exclude_list = ['purpose','extra', 'whole', 'frying', 'cut', \n",
    "                        'sun', 'baby', 'five', 'star', 'non', 'dash', 'style',\n",
    "                        'white', 'green', 'black', 'red', 'pink', 'yellow', 'brown', 'golden', 'blue', \n",
    "                        'color', 'colored', 'half', 'alternative',\n",
    "                        'ground', 'sea', 'part', 'baked', 'raw', 'new', 'active',\n",
    "                        'italian', 'dark', 'light', 'fresh', 'sweet', 'candied',\n",
    "                        'dried', 'dry', 'heavy', 'condensed', 'firm', 'soft', 'free', \n",
    "                        'mixed', 'flavored', 'evaporated', 'peeled', 'pickled','cooked','chopped', 'broken',\n",
    "                        'hot', 'self', 'rising', 'split', 'cooking', 'stewed',\n",
    "                        'de', 'dr']\n",
    "unigram_exclude_list += corpus.stopwords.words('english')\n",
    "\n",
    "ngram_exclude_list = ['all_purpose', 'purpose_flour', 'free_all']\n",
    "\n",
    "ngram_not_start_end = ['for', 'of', 'and', 'with', 'in']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of valid recipes: 57709\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de2c024bb70b45c2b7887519c8a017cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=57709.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fa0275b14394dbe870de7f61c649080",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=57709.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "valid_recipe_id_list = []\n",
    "for recipe_id in recipe_id_list:\n",
    "    try:\n",
    "        dict_recipe_ingredients[recipe_id]\n",
    "        valid_recipe_id_list.append(recipe_id)\n",
    "    except:\n",
    "        continue\n",
    "print('Number of valid recipes:',len(valid_recipe_id_list))\n",
    "\n",
    "# create dict for appearance times for each cluster name\n",
    "dict_cluster_count = defaultdict(int)\n",
    "for recipe_id in tqdm(valid_recipe_id_list):\n",
    "    recipe = [dict_ingredient_clustername[ingre_id] for ingre_id in dict_recipe_ingredients[recipe_id]]\n",
    "    for ingre in recipe:\n",
    "        dict_cluster_count[ingre] += 1 # this cluster appear +1\n",
    "\n",
    "# create dict for appearance times for each cluster name but ONLY count recipes with review data\n",
    "dict_cluster_count_has_review = copy.deepcopy(dict_cluster_count)\n",
    "dict_cluster_count_has_review = dict.fromkeys(dict_cluster_count_has_review, 0)\n",
    "for recipe_id in tqdm(valid_recipe_id_list):\n",
    "    if recipe_id in recipe_id_has_review_list:\n",
    "        recipe = [dict_ingredient_clustername[ingre_id] for ingre_id in dict_recipe_ingredients[recipe_id]]\n",
    "        for ingre in recipe:\n",
    "            dict_cluster_count_has_review[ingre] += 1 # this cluster appear +1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1st Round: Initial Full Match & Partial Match\n",
    "\n",
    "Logic:\n",
    "\n",
    "* Get all possible full names and short names for each ingredient in the recipe, and then sort the names by length. \n",
    "\n",
    "* From longest to shortest, map each name to the direction. If it’s a multi-gram match, then remove it from direction text before matching the next name. \n",
    "\n",
    "\n",
    "In this way, won’t double count partial match which is a substring of another full match. Also, won’t miss any matches when an ingre is substring of another ingre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d37a19332b304b66bd10ef8fdee2a368",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=57709.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "perfect_match_list = []\n",
    "partial_match_list = []\n",
    "no_match_list = []\n",
    "recipe_list = []\n",
    "direction_list = []\n",
    "lemmatized_direction_list = []\n",
    "remain_direction_list = []\n",
    "\n",
    "num_ingredient_list = []\n",
    "num_perfect_match_list = []\n",
    "num_partial_match_list = []\n",
    "num_no_match_list = []\n",
    "\n",
    "for recipe_id in tqdm(valid_recipe_id_list):\n",
    "    \n",
    "    # list of ingre that appeared exactly the same in the direction\n",
    "    perfect_match_this_recipe = []\n",
    "    # list of ingre that matched shorter form in the direction\n",
    "    partial_match_this_recipe = []\n",
    "    # list fo ingre that are not matched\n",
    "    no_match_this_recipe = []\n",
    "    \n",
    "    # count number of ingredients\n",
    "    num_perfect_match_this_recipe = 0\n",
    "    num_partial_match_this_recipe = 0\n",
    "    num_no_match_this_recipe = 0\n",
    "    \n",
    "    # get the direction of this recipe id\n",
    "    direction = dict_recipe_direction[recipe_id]\n",
    "    lemmatized_direction = lemmatization(dict_recipe_direction[recipe_id])\n",
    "    \n",
    "    remain_direction = lemmatized_direction\n",
    "\n",
    "    # get the ingredients of this recipe id and sort by length\n",
    "    recipe = [dict_ingredient_clustername[ingre_id] for ingre_id in dict_recipe_ingredients[recipe_id]]\n",
    "    \n",
    "    # get all the short names of all ingre in this recipe and combine with full names, then sort by length\n",
    "    all_names = []\n",
    "    for ingre in recipe:\n",
    "        ingre_tokens = ingre.split('_')\n",
    "        n = len(ingre_tokens)-1\n",
    "        while n > 0:\n",
    "            for i in range(0,len(ingre_tokens)-n+1):\n",
    "                short_form = '_'.join(ingre_tokens[i:i+n])\n",
    "                if n > 1:\n",
    "                    if short_form not in ngram_exclude_list \\\n",
    "                       and ingre_tokens[i] not in ngram_not_start_end \\\n",
    "                       and ingre_tokens[i+n-1] not in ngram_not_start_end:\n",
    "                        all_names.append(short_form)\n",
    "                else:\n",
    "                    if short_form not in unigram_exclude_list:\n",
    "                        all_names.append(short_form)\n",
    "            n = n-1\n",
    "    all_names += recipe\n",
    "    all_names = list(set(all_names))\n",
    "    all_names.sort(key=lambda x: len(x.split('_')), reverse=True)\n",
    "    \n",
    "    remained_unmatched = recipe.copy()\n",
    "    look_for_partial = recipe.copy() # list of ingre with no perfect full match in the direction\n",
    "    \n",
    "    # match the names in all_names from longest to shortest\n",
    "    for name in all_names:\n",
    "        name_original = name.replace('_',' ')\n",
    "        # if name_original in remain_direction (using whole word matching)\n",
    "        if re.search(r'\\b' + name_original + r'\\b', remain_direction) is not None: # a match\n",
    "            if name in recipe: # a perfect full match\n",
    "                perfect_match_this_recipe.append(name)\n",
    "                if len(name.split('_')) > 1:\n",
    "                    # only remove this name from direction text if the name is multigram\n",
    "                    remain_direction = re.sub(r\"\\b\"+ name_original + r\"\\b\", \"INGRE\", remain_direction)\n",
    "                remained_unmatched.remove(name)\n",
    "                look_for_partial.remove(name)\n",
    "                num_perfect_match_this_recipe += 1\n",
    "            else: # a partial match exits\n",
    "                matched_ingres = [ingre for ingre in look_for_partial if re.search(r'\\b' + name_original + r'\\b', ingre.replace('_',' ')) is not None]\n",
    "                for ingre in matched_ingres: # for each ingre that this name has a partial match\n",
    "                    partial_match_this_recipe.append([ingre, [name]])\n",
    "                    if ingre in remained_unmatched: # if this ingre has a match for the first time\n",
    "                        remained_unmatched.remove(ingre)\n",
    "                        num_partial_match_this_recipe += 1\n",
    "                if len(matched_ingres) > 0 and len(name.split('_')) > 1:\n",
    "                    # only remove this name from direction text if the name is multigram and there's a match\n",
    "                    remain_direction = re.sub(r\"\\b\"+ name_original + r\"\\b\", \"INGRE\", remain_direction)\n",
    "    \n",
    "\n",
    "    no_match_list.append(remained_unmatched)\n",
    "    recipe_list.append(recipe)\n",
    "    direction_list.append(direction)\n",
    "    lemmatized_direction_list.append(lemmatized_direction)\n",
    "    perfect_match_list.append(perfect_match_this_recipe)\n",
    "    partial_match_list.append(partial_match_this_recipe)\n",
    "    num_perfect_match_list.append(num_perfect_match_this_recipe)\n",
    "    num_partial_match_list.append(num_partial_match_this_recipe)\n",
    "    num_no_match_list.append(len(remained_unmatched))\n",
    "    num_ingredient_list.append(len(recipe))\n",
    "    remain_direction_list.append(remain_direction)\n",
    "    \n",
    "\n",
    "matched_df = pd.DataFrame({\n",
    "    'recipe_id': valid_recipe_id_list, \n",
    "    'recipe': recipe_list,\n",
    "    'direction': direction_list,\n",
    "    'lemma_direction': lemmatized_direction_list,\n",
    "    'remain_direction': remain_direction_list,\n",
    "    'perfect_match': perfect_match_list,\n",
    "    'partial_match': partial_match_list,\n",
    "    'no_match': no_match_list,\n",
    "    'num_ingredient': num_ingredient_list,\n",
    "    'num_perfect_match': num_perfect_match_list,\n",
    "    'num_partial_match': num_partial_match_list,\n",
    "    'num_no_match': num_no_match_list\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the above initial matching result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57709, 12)\n"
     ]
    }
   ],
   "source": [
    "print(matched_df.shape)\n",
    "matched_df.to_csv('OUTPUT_OF_FINAL_CODE/matched_directions_initial.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect missing ingredients (i.e. no match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count of ingredients not matched in at least one recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "861"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_match_list_flat = list(itertools.chain.from_iterable(no_match_list))\n",
    "count_no_match = Counter(no_match_list_flat)\n",
    "count_no_match = count_no_match.most_common()\n",
    "len(count_no_match) # ingre at least not matched in 1 recipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Label2 in Final_clusters_mod for synonyms detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "salt 673\n",
      "['sodium']\n",
      "green_onion 254\n",
      "['scallion']\n",
      "garbanzo_bean 239\n",
      "['chickpea', 'liquid', 'gravy', 'crumb', 'bengal', 'gram']\n",
      "butter 202\n",
      "['sunbutter', 'variety', 'garlic', 'land']\n",
      "ground_cinnamon 195\n",
      "['mccormick', 'ceylon']\n",
      "water 187\n",
      "['orange', 'flower', 'spring']\n",
      "margarine 187\n",
      "['vegan', 'spread', 'fat', 'butter', 'soy', 'oil', 'corn', 'dairy', 'vegetable']\n",
      "pecan 182\n",
      "['decoration', 'extract']\n",
      "green_chile_pepper 162\n",
      "['hatch', 'mexico', 'chili']\n",
      "graham_cracker 160\n",
      "['crust', 'chocolate', 'pie', 'crumb', 'mini', 'cinnamon', 'fat', 'deep', 'dish', 'cooky', 'bear', 'snack', 'honey', 'maid']\n",
      "pie_crust 154\n",
      "['shell', 'tart', 'pastry', 'deep', 'dish', 'shortbread', 'mix', 'wheat', 'chocolate', 'sandwich', 'cookie', 'pillsbury', 'box', 'mini', 'phyllo', 'shortcake', 'recipe', 'ball', 'dough']\n",
      "ground_black_pepper 130\n",
      "['mccormick', 'coarse']\n",
      "egg 125\n",
      "[\"eggland's\", 'strip']\n",
      "ground_nutmeg 124\n",
      "['mccormick']\n",
      "vanilla_extract 120\n",
      "['imitation', 'mccormick', 'pure']\n",
      "crabmeat 109\n",
      "['crab', 'imitation', 'king', 'leg', 'thawed', 'alaskan', 'shell', 'snow', 'cluster']\n",
      "adobo_sauce 97\n",
      "['chipotle', 'pepper']\n",
      "ground_beef 97\n",
      "['lean', 'meatloaf', 'patty', 'hamburger', 'leftover', 'mix', 'round', 'chuck', 'burger']\n",
      "chocolate_cooky 90\n",
      "['cookie', 'sandwich', 'crumb', 'chip', 'mint', 'creme', 'butter', 'crust', 'oval', 'milk', 'candy', 'bit', 'caramel', 'bar', 'twix', 'carb', 'cereal']\n",
      "vegetable_oil 89\n",
      "['drop', 'hazelnut', 'flaxseed', 'garlic', 'cinnamon', 'medium', 'chain', 'triglyceride', 'almond', 'palm', 'orange', 'macadamia', 'nut', 'anise', 'pina', 'colada', 'candy', 'tomato', 'lemon', 'pumpkin', 'seed', 'popcorn', 'rice', 'bran', 'nutmeg', 'basil', 'poppyseed', 'ginger', 'mustard', 'substitute', 'pistachio', 'coriander']\n",
      "ground_clove 81\n",
      "['mccormick']\n",
      "baking_powder 77\n",
      "['sodium']\n",
      "honey 72\n",
      "['aunt', 'powder', 'butter']\n",
      "spaghetti 72\n",
      "['spaghettini', 'spinach', 'pasta', 'thin', 'wheat']\n",
      "kosher_salt 70\n",
      "['coarse']\n",
      "macaroni 69\n",
      "['elbow', 'wheat', 'multi', 'grain', 'multigrain']\n",
      "soy_sauce 67\n",
      "['sodium', 'tamari', 'lite']\n",
      "milk 67\n",
      "['lactose']\n",
      "garlic 66\n",
      "['clove', 'oil', 'juice', 'elephant']\n",
      "onion 66\n",
      "['purple', 'medium', 'ring', 'cipollini', 'welsh', 'matchstick', 'sauteed', 'butter']\n",
      "luncheon_meat 65\n",
      "['deli', 'turkey', 'thin', 'slice', 'beef', 'lite', 'sodium', 'chicken', 'pastrami', 'capicola', 'mortadella', 'meatless', 'hormel', 'choice']\n",
      "bread_crumb 64\n",
      "['panko', 'wheat', 'garlic', 'herb', 'parmesan', 'cheese', 'breadcrumb']\n",
      "mixed_berry 63\n",
      "['gooseberry', 'boysenberry', 'fruit', 'juice', 'juniper', 'acai', 'pulp', 'lychee', 'elderberry', 'mulberry', 'serviceberry', 'saskatoon', 'lingonberry', 'thawed', 'barberry', 'salmonberry', 'dewberry', 'framboise']\n",
      "half_and_half 63\n",
      "['fat']\n",
      "milk_powder 62\n",
      "['strawberry', 'skim', 'fat', 'instant']\n",
      "raisin 61\n",
      "['chocolate', 'yogurt', 'sultana', 'paste', 'cinnamon']\n",
      "sirloin 59\n",
      "['lean', 'cold', 'top', 'beef']\n",
      "chicken_broth 55\n",
      "['sodium', 'fat', 'base', 'swanson']\n",
      "sea_salt 55\n",
      "['coarse', 'fine']\n",
      "beef_chuck 54\n",
      "['roast', 'cubed', 'angus']\n",
      "jam 54\n",
      "['preserve', 'cherry', 'mango', 'plum', 'lingonberry', 'flavor', 'fruit', 'lemon', 'marmalade', 'cranberry']\n",
      "bean 54\n",
      "['soybean', 'soup', 'paste', 'dip', 'adzuki', 'curd', 'thread', 'bacon', 'mayocoba', 'soy', 'salad', 'garlic', 'sauce', 'soldier', 'liquid', 'corona', 'tri', 'blend', 'piece', 'block']\n",
      "carrot 53\n",
      "['food', 'juice', 'pureed']\n",
      "italian_seasoning 52\n",
      "['mccormick', 'perfect', 'pinch', 'blend']\n",
      "orange_jam 52\n",
      "['marmalade', 'sugar', \"smucker's\"]\n",
      "round_steak 52\n",
      "['eye']\n",
      "bread 51\n",
      "['loaf', 'multigrain', 'toast', \"nature's\", 'cubed', 'cinnamon', 'country', 'potato', 'sheet', 'lavash', 'sandwich', 'soda', 'farl', 'pumpkin', 'friendship', 'starter', 'garlic', 'oatnut', 'stale', 'cranberry', 'walnut', 'crosswise', 'swirl', 'banana', 'torn', 'cube', 'calorie', 'oatmeal', 'schr', 'artisan', 'baker', 'grain', 'seed', 'zwieback', 'anisette', 'bruschetta']\n",
      "potato 51\n",
      "['instant', 'fry', 'flake', 'leftover', 'mix', 'au', 'gratin', 'garlic', 'salad', 'idahoan', 'cheese', 'purple', 'creamer', 'crinkle']\n",
      "buttermilk 51\n",
      "['fat', 'powder']\n",
      "almond 49\n",
      "['honey', 'marcona', 'chocolate', 'cocoa']\n",
      "cornflakes_cereal 49\n",
      "['honey', 'corn', 'flake', 'nut', 'flavor', 'cornflake', 'crumb', 'sugar']\n",
      "beef_sirloin 48\n",
      "['boneless', 'steak', 'room', 'temperature']\n",
      "other_fish 48\n",
      "['fillet', 'mackerel', 'sardine', 'bluefish', 'perch', 'oil', 'bonito', 'orange', 'roughy', 'grouper', 'monkfish', 'bass', 'hake', 'amberjack', 'butterfish', 'pollock', 'rockfish', 'pompano', 'drum', 'stick', 'milkfish', 'water', 'skinless', 'boneless', 'head', 'bone', 'char', 'smelt', 'mullet', 'pacific', 'saury']\n",
      "cod 48\n",
      "['fillet', 'fish', 'lingcod', 'skin', 'bone']\n",
      "parsley 47\n",
      "['leaf', 'flake', 'root', 'chunk', 'mccormick', 'paste', 'chervil']\n",
      "hash_brown 47\n",
      "['potato', 'patty', \"o'brien\"]\n",
      "liqueur 46\n",
      "['chocolate', 'pumpkin', 'strawberry', 'honey', 'whiskey', 'daiquiri', 'mix', 'benedictine', 'creme', 'cassis', 'galliano', 'elderflower', 'praline', 'amaro', 'ginger', 'pomegranate', 'blackberry', 'maraschino', 'lychee', 'herb', 'spice', 'almond', 'maple', 'cranberry', 'coconut', 'peach', 'mai', 'tai', 'cocktail', 'chartreuse', 'cachaca', 'bottle', 'malt', 'liquor']\n",
      "orange_liqueur 46\n",
      "['brandy', 'curacao']\n",
      "syrup 44\n",
      "['cane', 'sugar', 'simple', 'chocolate', 'pancake', 'glucose', 'eagle', 'pomegranate']\n",
      "cooky 44\n",
      "['butter', 'peanut', 'sandwich', 'oatmeal', 'coconut', 'fudge', 'macaroon', 'speculoos', 'sugar', 'stripe', 'oreo', 'rectangular', 'oval', 'animal', 'cracker', 'ginger', 'nut', 'plain', 'meringue', 'caramel', 'stick', 'raisin', 'gingerbread', 'cookie', 'crumb', 'store', 'bought']\n",
      "strawberry 43\n",
      "['freeze', 'puree']\n",
      "oat 42\n",
      "['quick', 'fiber']\n"
     ]
    }
   ],
   "source": [
    "no_label2 = []\n",
    "\n",
    "# To find synonyms:\n",
    "# For each missing ingredient, check the label2 in Final_clusters_mod.csv\n",
    "for (missing_ingre, missing_count) in count_no_match:\n",
    "    missing_ingre_unigrams = missing_ingre.split('_')\n",
    "    all_label2 = ' '.join(df_mod.loc[df_mod['cluster_name'] == ' '.join(missing_ingre_unigrams),'label2'])\n",
    "    unigrams = all_label2.split(' ')\n",
    "    count_unigrams = Counter(unigrams).most_common()\n",
    "    if len(count_unigrams)>0:\n",
    "        possible_names = [unigram for (unigram, count) in count_unigrams if unigram \\\n",
    "                          not in unigram_exclude_list+missing_ingre_unigrams+['']\\\n",
    "                          and pos_tag([unigram])[0][1]=='NN']\n",
    "    if len(possible_names)>0:\n",
    "        if missing_count > 40:\n",
    "            print(missing_ingre, missing_count)\n",
    "            print(possible_names)\n",
    "    else:\n",
    "        no_label2.append(missing_ingre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Ingredient Mapping Dictionary\n",
    "\n",
    "This Dict will be saved and used for altering detection in FINAL CODE 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Create a dict for cluster name mapping\n",
    "\n",
    "key: cluster name\n",
    "value: dict{'short': all appeared short forms (only for multi-gram cluster names), \n",
    "            'parent': parent names, \n",
    "            'child': child names,\n",
    "            'synonym': synonyms}\n",
    "'''\n",
    "dict_ingre_mapping = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "exchangeable_pairs = [('chili', 'chile'), ('cookie', 'cooky'), ('cocoa', 'cacao')]\n",
    "\n",
    "# iterate for all cluster names\n",
    "for ingre in dict_cluster_count: \n",
    "    \n",
    "    # add \"dry ingredient\" as parent term for ingredients with \"dried\"\n",
    "    if ('dried' in ingre) and ('dry_ingredient' not in dict_ingre_mapping[ingre]['parent']):\n",
    "        dict_ingre_mapping[ingre]['parent'].append('dry_ingredient')\n",
    "\n",
    "    # add parent names for ingredients with \"broth\"\n",
    "    if ('broth' in ingre) and ('stock' not in dict_ingre_mapping[ingre]['parent']):\n",
    "        dict_ingre_mapping[ingre]['parent'] += ['stock','consomme','soup']\n",
    "\n",
    "    # add parent names for ingredients with \"preserve\"\n",
    "    if ('jam' in ingre) and ('preserve' not in dict_ingre_mapping[ingre]['parent']):\n",
    "        dict_ingre_mapping[ingre]['parent'] += ['preserve']\n",
    "\n",
    "    # add synonyms for ingredients containing exchangeable pairs\n",
    "    for (A,B) in exchangeable_pairs:\n",
    "        if A in ingre or B in ingre:\n",
    "            if A in ingre: # e.g. A = origin = 'cooky', B = alter = 'cookie', ingre = 'chocolate_cooky'\n",
    "                origin = A\n",
    "                alter = B\n",
    "            else:\n",
    "                origin = B\n",
    "                alter = A\n",
    "            ingre_tokens = ingre.split('_')\n",
    "            ingre_syn = '_'.join([t if t != origin else alter for t in ingre_tokens])\n",
    "            if ingre_syn not in dict_ingre_mapping[ingre]['synonym']:\n",
    "                dict_ingre_mapping[ingre]['synonym'] += [ingre_syn] # e.g. add 'chocolate_cookie' as synonym\n",
    "\n",
    "\n",
    "# iterate for all partial matches\n",
    "for partial_match_this_recipe in partial_match_list:\n",
    "    for partial_match_this_ingre in partial_match_this_recipe:\n",
    "        ingre = partial_match_this_ingre[0]\n",
    "        \n",
    "        short_forms = partial_match_this_ingre[1]\n",
    "        \n",
    "        # add synonym names for ingredients containing exchangeable pairs\n",
    "        for (A,B) in exchangeable_pairs:\n",
    "            if A in ingre or B in ingre:\n",
    "                if A in ingre: # e.g. A = origin = 'cooky', B = alter = 'cookie', ingre = 'chocolate_cooky'\n",
    "                    origin = A\n",
    "                    alter = B\n",
    "                else:\n",
    "                    origin = B\n",
    "                    alter = A\n",
    "                # e.g. add \"cookie\" as a synonym name for \"chocolate_cooky\" iff \"cooky\" is a short name for it\n",
    "                short_synonym_forms = [re.sub(origin, alter, short) for short in short_forms if origin in short]\n",
    "                for name in short_synonym_forms:\n",
    "                    if name not in dict_ingre_mapping[ingre]['synonym']:\n",
    "                        dict_ingre_mapping[ingre]['synonym'] += [name] \n",
    "        \n",
    "        # insert in all short forms to the dict based on partial matching in previous step\n",
    "        for short_form in short_forms:\n",
    "            if short_form not in dict_ingre_mapping[ingre]['short']:\n",
    "                dict_ingre_mapping[ingre]['short'].append(short_form)        \n",
    "        \n",
    "\n",
    "                \n",
    "#### add in parent terms\n",
    "# nut\n",
    "nut_cluster = ['walnut', 'pecan', 'almond']\n",
    "for ingre in nut_cluster:\n",
    "    dict_ingre_mapping[ingre]['parent'].append('nut')\n",
    "\n",
    "# spice\n",
    "spice_cluster = ['ground_cinnamon', 'ground_nutmeg', 'ground_allspice', 'ground_clove', \n",
    "                 'ground_black_pepper', 'ground_cardamom', 'ground_chile_pepper', 'ground_coriander', \n",
    "                'ground_cumin', 'ground_ginger', 'ground_mace', 'ground_turmeric', 'ground_white_pepper']\n",
    "for ingre in spice_cluster:\n",
    "    dict_ingre_mapping[ingre]['parent'].append('spice')\n",
    "\n",
    "# meat\n",
    "meat_cluster = ['ground_beef', 'pork_sausage', 'beef_part', 'sirloin', 'pork']\n",
    "for ingre in meat_cluster:\n",
    "    dict_ingre_mapping[ingre]['parent'].append('meat')\n",
    "    \n",
    "# roast\n",
    "roast_cluster = ['beef_chuck', 'beef_tenderloin']\n",
    "for ingre in roast_cluster:\n",
    "    dict_ingre_mapping[ingre]['parent'].append('roast')\n",
    "\n",
    "# steak\n",
    "steak_cluster = ['beef', 'beef_sirloin', 'pork', 'sirloin']\n",
    "for ingre in steak_cluster:\n",
    "    dict_ingre_mapping[ingre]['parent'].append('steak')\n",
    "    \n",
    "# berry\n",
    "berry_cluster = ['blackberry','blueberry']\n",
    "for ingre in berry_cluster:\n",
    "    dict_ingre_mapping[ingre]['parent'].append('berry')\n",
    "\n",
    "# sorbet\n",
    "sorbet_cluster = ['ice_cream', 'strawberry_ice_cream']\n",
    "for ingre in sorbet_cluster:\n",
    "    dict_ingre_mapping[ingre]['parent'] += ['sorbet', 'sherbet']\n",
    "\n",
    "# syrup\n",
    "syrup_cluster = ['strawberry_topping']\n",
    "for ingre in syrup_cluster:\n",
    "    dict_ingre_mapping[ingre]['parent'] += ['syrup', 'glaze']\n",
    "\n",
    "# vegetable\n",
    "vegetable_cluster = ['carrot', 'celery','cauliflower','broccoli','sweet_potato','potato','tomato', 'zucchini']\n",
    "for ingre in vegetable_cluster:\n",
    "    dict_ingre_mapping[ingre]['parent'] += ['vegetable']\n",
    "\n",
    "\n",
    "dict_ingre_mapping['rose']['parent'].append('petal')\n",
    "dict_ingre_mapping['graham_cracker']['parent'] += ['crust', 'crumb']\n",
    "dict_ingre_mapping['ground_beef']['parent'] += ['meatloaf', 'patty']\n",
    "dict_ingre_mapping['sirloin']['parent']+= ['beef']\n",
    "dict_ingre_mapping['beef']['parent'] += ['rib', 'tamale']\n",
    "dict_ingre_mapping['cod']['parent'] += ['fish', 'fillet']\n",
    "dict_ingre_mapping['flounder']['parent'] += ['fish', 'fillet']\n",
    "dict_ingre_mapping['pork_sparerib']['parent'] += ['rib']\n",
    "dict_ingre_mapping['candied_citron']['parent'] += ['candied_fruit']\n",
    "\n",
    "dict_ingre_mapping['mixed_baby_green']['parent'] += ['green']\n",
    "\n",
    "dict_ingre_mapping['round_steak']['parent'] += ['beef']\n",
    "\n",
    "\n",
    "dict_ingre_mapping['ground_black_pepper']['parent'] += ['seasoning']\n",
    "\n",
    "dict_ingre_mapping['mixed_berry']['parent'] += ['fruit']\n",
    "\n",
    "dict_ingre_mapping['vanilla_extract']['parent'] += ['flavoring']\n",
    "\n",
    "dict_ingre_mapping['half_and_half']['parent'] += ['cream']\n",
    "dict_ingre_mapping['sea_bass']['parent'] += ['fish']\n",
    "\n",
    "\n",
    "\n",
    "#### add in child terms\n",
    "dict_ingre_mapping['topping']['child'].append('spice')\n",
    "dict_ingre_mapping['potato']['child'] += ['frenchfries', 'fries']\n",
    "dict_ingre_mapping[\"pig's_part\"]['child'] += ['pork', 'liver', 'ear', 'tail', 'foot', 'pig', 'jowl', 'stomach', 'cheek']\n",
    "dict_ingre_mapping[\"liqueur\"]['child'] += ['daiquiri','cocktail', 'chartreuse', 'cachaca', 'mezcal']\n",
    "dict_ingre_mapping[\"bean\"]['child'] += ['soybean']\n",
    "dict_ingre_mapping[\"other_fish\"]['child'] += ['bonito', 'fillet', 'milkfish', 'herring', 'mackerel', \n",
    "                                              'sardine', 'bluefish', 'perch', 'monkfish', 'bass', \n",
    "                                             'hake', 'amberjack', 'butterfish', 'pollock', 'rockfish', \n",
    "                                              'pompano', 'milkfish', 'char', 'smelt', 'mullet', 'saury']\n",
    "dict_ingre_mapping[\"other_meat\"]['child'] += ['buffalo', 'goat', 'alligator', 'kangaroo', 'turtle', 'bear',\n",
    "                                             'rattlesnake', 'bison', 'antelope', 'ostrich', 'elk', 'squirrel',\n",
    "                                             'octopus', 'quail', 'moose', 'shark', 'ostrich', 'boar', 'frog', 'grouse']\n",
    "\n",
    "dict_ingre_mapping[\"mixed_berry\"]['child'] += [ 'juniper','acai_pulp', 'lychee', 'elderberry', 'mulberry', \n",
    "                                               'serviceberry', \n",
    "                                               'gooseberry','boysenberry', 'lingonberry', 'barberry', 'salmonberry',\n",
    "                                              'dewberry', 'marionberry', 'framboise']\n",
    "\n",
    "\n",
    "dict_ingre_mapping['luncheon_meat']['child'] += ['turkey', 'beef', 'chicken']\n",
    "\n",
    "dict_ingre_mapping['pickle']['child'] += ['gherkin', 'relish', 'giardiniera', 'cornichon']\n",
    "dict_ingre_mapping['cake']['child'] += ['cupcake', 'jellyroll', 'hard_bread', 'fruitcake', 'twinkie']\n",
    "dict_ingre_mapping['mixed_spice']['child'] += ['chaat_masala', 'garam_masala', 'pav_bhaji_masala']\n",
    "dict_ingre_mapping['herb']['child'] += ['epazote', 'bouquet_garni', 'rosemary_leaf']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### add in synonyms\n",
    "\n",
    "dict_ingre_mapping['garbanzo_bean']['synonym'].append('chickpea')\n",
    "dict_ingre_mapping['green_onion']['synonym'].append('scallion')\n",
    "dict_ingre_mapping['espresso']['synonym'].append('coffee_bean')\n",
    "dict_ingre_mapping['crabmeat']['synonym'].append('crab')\n",
    "dict_ingre_mapping['spaghetti']['synonym'] += ['spaghettini', 'pasta']\n",
    "dict_ingre_mapping['macaroni']['synonym'] += ['pasta']\n",
    "dict_ingre_mapping['pasta']['synonym'] += ['rotelle', 'cavatappi', 'fettuccini']\n",
    "dict_ingre_mapping['bread_crumb']['synonym'] += ['panko']\n",
    "dict_ingre_mapping['raisin']['synonym'] += ['sultana']\n",
    "dict_ingre_mapping['adobo_sauce']['synonym'] += ['chipotle']\n",
    "dict_ingre_mapping['sweetener']['synonym'] += ['fructose']\n",
    "dict_ingre_mapping['bread']['synonym'] += ['loaf', 'toast', 'challah', 'farl']\n",
    "dict_ingre_mapping['cornflakes_cereal']['synonym'] += ['cornflake']\n",
    "dict_ingre_mapping['parsley']['synonym'] += ['chervil']\n",
    "dict_ingre_mapping['cod']['synonym'] += ['lingcod']\n",
    "dict_ingre_mapping['soy_sauce']['synonym'] += ['tamari']\n",
    "dict_ingre_mapping['orange_jam']['synonym'] += ['marmalade']\n",
    "dict_ingre_mapping['pie_crust']['synonym'] += ['shell']\n",
    "dict_ingre_mapping['green_tea']['synonym'] += ['matcha']\n",
    "dict_ingre_mapping['beef_tenderloin']['synonym'] += ['mignon_filet', 'filet', 'mignon', 'steak']\n",
    "dict_ingre_mapping['beer']['synonym'] += ['stout', 'ale']\n",
    "dict_ingre_mapping['buttermilk']['synonym'] += ['sour_milk']\n",
    "dict_ingre_mapping['club_soda']['synonym'] += ['carbonated_water', 'seltzer', 'sparkling_water']\n",
    "dict_ingre_mapping['cooky']['synonym'] += ['biscuit']\n",
    "dict_ingre_mapping['nori']['synonym'] += ['seaweed']\n",
    "dict_ingre_mapping['cassava']['synonym'] += ['yuca', 'root']\n",
    "dict_ingre_mapping['kiwi']['synonym'] += ['kiwifruit']\n",
    "dict_ingre_mapping['mixed_baby_green']['synonym'] += ['pea_shoot']\n",
    "dict_ingre_mapping['cactus']['synonym'] += ['nopal']\n",
    "dict_ingre_mapping['roe']['synonym'] += ['caviar', 'tarama']\n",
    "dict_ingre_mapping['seaweed']['synonym'] += ['wakame', 'aonori', 'moss', 'kombu']\n",
    "dict_ingre_mapping['chocolate_flavored_syrup']['synonym'] += ['hot_fudge', 'fudge_topping']\n",
    "dict_ingre_mapping['animal_fat']['synonym'] += ['suet', 'tallow']\n",
    "dict_ingre_mapping['sucanat']['synonym'] += ['cane_sugar']\n",
    "dict_ingre_mapping['squid']['synonym'] += ['calamari']\n",
    "dict_ingre_mapping['vegetable_protein']['synonym'] += ['tvp']\n",
    "dict_ingre_mapping['pork']['synonym'] += ['pig']\n",
    "dict_ingre_mapping['ground_black_pepper']['synonym'] += ['peppercorn']\n",
    "dict_ingre_mapping['kosher_salt']['synonym'] += ['coarse_salt']\n",
    "dict_ingre_mapping['wheat']['synonym'] += ['freekeh']\n",
    "dict_ingre_mapping['rolled_oat']['synonym'] += ['oatmeal']\n",
    "dict_ingre_mapping['hash_brown']['synonym'] += ['potato']\n",
    "\n",
    "########## add ignore flag\n",
    "# dict_ingre_mapping['margarine']['synonym'].append('butter')\n",
    "# dict_ingre_mapping['butter']['synonym'].append('margarine')\n",
    "# dict_ingre_mapping['pasta']['synonym'].append('noodle') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dict using pickle\n",
    "save_obj(dict_ingre_mapping, 'dict_ingre_mapping')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2nd Round: \n",
    "## Matching of the 1st round missing ingre using the mapping dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "011f1ad1e6ae49358d9b63e348566dc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=57709.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ignore_ingre_list = ['salt', 'water']\n",
    "\n",
    "from ast import literal_eval\n",
    "\n",
    "matched_df2 = pd.read_csv('OUTPUT_OF_FINAL_CODE/matched_directions_initial.csv')\n",
    "\n",
    "#print(matched_df2.dtypes)\n",
    "dict_match_list = []\n",
    "num_dict_match_list = []\n",
    "num_ignore_list = []\n",
    "ignore_some_flag_list = []\n",
    "ignore_all_flag_list = []\n",
    "ignore_bean_flag_list = []\n",
    "ignore_unsaltedbutter_flag_list = []\n",
    "ignore_greenchile_flag_list = []\n",
    "ignore_butter_pasta_flag_list = []\n",
    "new_no_match_list = []\n",
    "new_no_match_list_after_ignore = []\n",
    "\n",
    "for i in tqdm(range(0,len(matched_df2))):\n",
    "    row = matched_df2.iloc[i,:]\n",
    "    dict_match_this_recipe = [] # match of missing ingredients in this recipe by using the dict\n",
    "    num_dict_match_this_recipe = 0\n",
    "    num_ignore = 0\n",
    "    ignore_some_flag = False\n",
    "    ignore_bean_flag = False\n",
    "    ignore_unsaltedbutter_flag = False\n",
    "    ignore_greenchile_flag = False\n",
    "    ignore_butter_pasta_flag = False\n",
    "    ignore_all_flag = False\n",
    "    recipe = literal_eval(row.recipe)\n",
    "    no_match_this_recipe = literal_eval(row.no_match)\n",
    "    perfect_match_this_recipe = literal_eval(row.perfect_match)\n",
    "    direction = row.lemma_direction\n",
    "    \n",
    "    no_match_this_recipe_origin = no_match_this_recipe.copy()\n",
    "    if row.num_no_match > 0:\n",
    "        for missing_ingre in no_match_this_recipe_origin:\n",
    "            dict_match_this_ingre = []\n",
    "            parent = dict_ingre_mapping[missing_ingre]['parent']\n",
    "            # short = dict_ingre_mapping[missing_ingre]['short']\n",
    "            child = dict_ingre_mapping[missing_ingre]['child']\n",
    "            synonym = dict_ingre_mapping[missing_ingre]['synonym']\n",
    "            all_possible_names = synonym + parent + child\n",
    "            for name in all_possible_names:\n",
    "                if name.replace('_', ' ') in direction: # if there is a match between the missing ingre and name in the dict\n",
    "                    dict_match_this_ingre.append(name)\n",
    "\n",
    "            if len(dict_match_this_ingre) > 0:\n",
    "                dict_match_this_recipe.append([missing_ingre, dict_match_this_ingre])\n",
    "                num_dict_match_this_recipe += 1\n",
    "                # if this ingre is matched using dict, remove it from no_match column, and modify the num_no_match\n",
    "                no_match_this_recipe.remove(missing_ingre)\n",
    "                matched_df2.loc[i,'num_no_match'] -= 1\n",
    "    \n",
    "    no_match_this_recipe_after_ignore = no_match_this_recipe.copy()\n",
    "    \n",
    "    # for the ingre that are still missing, check if satisfy the ignore criterion\n",
    "    for missing_ingre in no_match_this_recipe:\n",
    "        # criteria 1: missing_ingre is in ignore_ingre_list (e.g. water)\n",
    "        if missing_ingre in ignore_ingre_list:\n",
    "            num_ignore += 1\n",
    "            ignore_some_flag = True\n",
    "            no_match_this_recipe_after_ignore.remove(missing_ingre)\n",
    "        # criteria 2: missing_ingre is bean, and it was caused by \"chili with bean\" in original recipes\n",
    "        elif (missing_ingre == 'bean') and ('chili_sauce' in recipe) and ('chili_sauce' not in no_match_this_recipe):\n",
    "            num_ignore += 1\n",
    "            ignore_bean_flag = True\n",
    "            no_match_this_recipe_after_ignore.remove(missing_ingre)\n",
    "        # criteria 3: missing_ingre is unsalted_butter, caused by both itself and \"butter\" in original recipes\n",
    "        elif (missing_ingre == 'unsalted_butter') and ('butter' in recipe) and ('butter' not in no_match_this_recipe):\n",
    "            num_ignore += 1\n",
    "            ignore_unsaltedbutter_flag = True\n",
    "            no_match_this_recipe_after_ignore.remove(missing_ingre)\n",
    "        # criteria 4: missing_ingre is green_chile_pepper, caused by \"diced tomato with green chile pepper\" in original recipes\n",
    "        elif (missing_ingre == 'green_chile_pepper') and ('tomato' in recipe) and ('tomato' not in no_match_this_recipe):\n",
    "            num_ignore += 1\n",
    "            ignore_greenchile_flag = True\n",
    "            no_match_this_recipe_after_ignore.remove(missing_ingre)\n",
    "        # criteria 5: missing_ingre is one of (butter, margarine) or one of (pasta / noodle), \n",
    "        #             caused by the other one is called in the direction\n",
    "        for (A,B) in [('butter','margarine'),('pasta','noodle')]:\n",
    "            if A == missing_ingre or B == missing_ingre:\n",
    "                if A == missing_ingre: # e.g. A = missing = 'butter', B = alter = 'margarine'\n",
    "                    alter = B\n",
    "                else:\n",
    "                    alter = A\n",
    "                if alter in direction:\n",
    "                    num_ignore += 1\n",
    "                    ignore_butter_pasta_flag = True\n",
    "                    no_match_this_recipe_after_ignore.remove(missing_ingre)\n",
    "            \n",
    "    # criteria 6:\n",
    "    # if there are still missing ingre, and if the direction contains 'ingredients', \n",
    "    #    then ignore all missing ingre when calculating stats\n",
    "    if ('ingredient' in row.direction) and (matched_df2.loc[i,'num_no_match'] > num_ignore):\n",
    "        num_ignore = matched_df2.loc[i,'num_no_match']\n",
    "        ignore_all_flag = True\n",
    "        no_match_this_recipe_after_ignore = []\n",
    "    \n",
    "    dict_match_list.append(dict_match_this_recipe)\n",
    "    num_dict_match_list.append(num_dict_match_this_recipe)\n",
    "    num_ignore_list.append(num_ignore)\n",
    "    new_no_match_list.append(no_match_this_recipe)\n",
    "    new_no_match_list_after_ignore.append(no_match_this_recipe_after_ignore)\n",
    "    ignore_some_flag_list.append(ignore_some_flag)\n",
    "    ignore_bean_flag_list.append(ignore_bean_flag)\n",
    "    ignore_unsaltedbutter_flag_list.append(ignore_unsaltedbutter_flag)\n",
    "    ignore_greenchile_flag_list.append(ignore_greenchile_flag)\n",
    "    ignore_butter_pasta_flag_list.append(ignore_butter_pasta_flag)\n",
    "    ignore_all_flag_list.append(ignore_all_flag)\n",
    "\n",
    "    \n",
    "matched_df2 = matched_df2.drop(['no_match'], axis = 1)\n",
    "matched_df2.insert(7, 'dict_match', dict_match_list)\n",
    "matched_df2.insert(8, 'no_match', new_no_match_list)\n",
    "matched_df2.insert(12, 'num_dict_match', num_dict_match_list)\n",
    "matched_df2.insert(14, 'num_ignore', num_ignore_list)\n",
    "matched_df2.insert(15, 'ignore_some_flag', ignore_some_flag_list)\n",
    "matched_df2.insert(16, 'ignore_bean_flag', ignore_bean_flag_list)\n",
    "matched_df2.insert(17, 'ignore_unsaltedbutter_flag', ignore_unsaltedbutter_flag_list)\n",
    "matched_df2.insert(18, 'ignore_greenchile_flag', ignore_greenchile_flag_list)\n",
    "matched_df2.insert(19, 'ignore_butter_pasta_flag', ignore_butter_pasta_flag_list)\n",
    "matched_df2.insert(20, 'ignore_all_flag', ignore_all_flag_list)\n",
    "matched_df2.insert(21, 'no_match_after_ignore', new_no_match_list_after_ignore)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the above 2nd round matching result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_df2.to_csv('OUTPUT_OF_FINAL_CODE/matched_directions_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output some stats and tune the Mapping Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ingredients in all recipes:\n",
      "510860\n",
      "Number of missing ingredients after one-to-one full match:\n",
      "155806\n",
      "Number of missing ingredients after partial match:\n",
      "13684 2.68%\n",
      "Number of missing ingredients after using our mapping dict:\n",
      "9163 1.79%\n",
      "Number of missing ingredients after ignoring ingre with criterion:\n",
      "4808 0.94%\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of ingredients in all recipes:\")\n",
    "print(sum(matched_df2.num_ingredient))\n",
    "print(\"Number of missing ingredients after one-to-one full match:\")\n",
    "print(sum(matched_df2.num_ingredient) - sum(matched_df2.num_perfect_match))\n",
    "print(\"Number of missing ingredients after partial match:\")\n",
    "print(sum(matched_df.num_no_match), \"{0:.2%}\".format(sum(matched_df.num_no_match) / sum(matched_df2.num_ingredient)))\n",
    "print(\"Number of missing ingredients after using our mapping dict:\")\n",
    "print(sum(matched_df2.num_no_match), \"{0:.2%}\".format(sum(matched_df2.num_no_match) / sum(matched_df2.num_ingredient)))\n",
    "print(\"Number of missing ingredients after ignoring ingre with criterion:\")\n",
    "print(sum(matched_df2.num_no_match) - sum(matched_df2.num_ignore), \"{0:.2%}\".format((sum(matched_df2.num_no_match) - sum(matched_df2.num_ignore)) / sum(matched_df2.num_ingredient)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('ground_black_pepper', 64),\n",
       " ('white_sugar', 55),\n",
       " ('kosher_salt', 53),\n",
       " ('sea_salt', 50),\n",
       " ('vanilla_extract', 46),\n",
       " ('onion', 44),\n",
       " ('orange_liqueur', 44),\n",
       " ('italian_seasoning', 42),\n",
       " ('french_baguette', 40),\n",
       " ('seasoned_salt', 38),\n",
       " ('syrup', 37),\n",
       " ('green_bell_pepper', 37),\n",
       " ('garlic', 35),\n",
       " ('tomato_juice', 35),\n",
       " ('strawberry', 34),\n",
       " ('mixed_salad_green', 33),\n",
       " ('parsley', 32),\n",
       " ('ghee', 32),\n",
       " ('cooking_spray', 31),\n",
       " ('cornstarch', 31),\n",
       " (\"confectioners'_coating\", 30),\n",
       " ('dill_pickle', 29),\n",
       " ('brown_sugar', 29),\n",
       " ('clam_juice', 28),\n",
       " ('raisin', 28),\n",
       " ('monosodium_glutamate', 28),\n",
       " ('club_soda', 28),\n",
       " ('pork', 27),\n",
       " ('garlic_powder', 27),\n",
       " ('dried_parsley', 26),\n",
       " ('bourbon', 26),\n",
       " ('seafood_seasoning', 25),\n",
       " ('vegetable_oil', 24),\n",
       " ('wafer', 24),\n",
       " ('hot_dog', 24),\n",
       " ('dried_thyme', 23),\n",
       " ('butter', 23),\n",
       " ('dried_basil', 23),\n",
       " ('mixed_spice', 22),\n",
       " ('pie_crust', 22),\n",
       " ('lemon_zest', 22),\n",
       " ('peanut', 22),\n",
       " ('green_onion', 22),\n",
       " ('potato_nugget', 22),\n",
       " ('bacon_dripping', 21),\n",
       " ('chocolate_candy', 21),\n",
       " ('lemon', 21),\n",
       " ('cornmeal', 21),\n",
       " ('dried_oregano', 21),\n",
       " ('extra_virgin_olive_oil', 20),\n",
       " ('cayenne_pepper', 20),\n",
       " ('sweetener', 20),\n",
       " ('liqueur', 20),\n",
       " ('oil_for_frying', 20),\n",
       " ('oat', 20),\n",
       " ('orange_zest', 20),\n",
       " ('peach', 20),\n",
       " ('luncheon_meat', 19),\n",
       " ('graham_cracker', 19),\n",
       " ('golden_raisin', 19),\n",
       " ('raspberry', 19),\n",
       " ('jam', 18),\n",
       " ('coleslaw', 18),\n",
       " ('coffee', 18),\n",
       " ('almond_extract', 18),\n",
       " ('lettuce', 17),\n",
       " ('red_pepper_flake', 17),\n",
       " ('parmesan_cheese', 17),\n",
       " ('sausage', 17),\n",
       " ('sprinkle', 16),\n",
       " ('wheat_gluten', 16),\n",
       " ('chile_paste', 16),\n",
       " ('hot_sauce', 16),\n",
       " ('flank_steak', 16),\n",
       " ('buttermilk', 16),\n",
       " ('tilapia', 16),\n",
       " ('red_bell_pepper', 16),\n",
       " ('egg', 16),\n",
       " ('halibut', 16),\n",
       " ('beef_chuck', 16),\n",
       " ('cilantro', 15),\n",
       " ('chocolate_cooky', 15),\n",
       " ('brandy', 15),\n",
       " ('red_snapper', 15),\n",
       " ('red_onion', 15),\n",
       " ('sucralose_sweetener', 15),\n",
       " ('frosting', 15),\n",
       " ('bean', 15),\n",
       " ('hazelnut', 15),\n",
       " ('basil', 15),\n",
       " ('lemon_lime_soda', 15),\n",
       " ('candied_cherry', 15),\n",
       " ('hamburger_bun', 15),\n",
       " ('dry_mustard', 15),\n",
       " ('red_wine', 14),\n",
       " ('pumpkin_seed', 14),\n",
       " ('broccoli', 14),\n",
       " ('caramel', 14),\n",
       " ('ground_beef', 14),\n",
       " ('butter_extract', 14),\n",
       " ('pimento_pepper', 14),\n",
       " ('mushroom', 14),\n",
       " ('mandarin_orange', 14),\n",
       " ('stevia', 14),\n",
       " ('radish', 13),\n",
       " ('venison', 13),\n",
       " ('food_coloring', 13),\n",
       " ('pasta', 13),\n",
       " ('dried_rosemary', 13),\n",
       " ('all_purpose_flour', 12),\n",
       " ('paprika', 12),\n",
       " ('olive_oil', 12),\n",
       " ('matzo', 12),\n",
       " ('bread', 12),\n",
       " ('milk', 12),\n",
       " ('chicken', 12),\n",
       " ('vegetable_bouillon', 12),\n",
       " ('vinaigrette', 12),\n",
       " ('baking_soda', 11),\n",
       " ('lime', 11),\n",
       " ('mixed_berry', 11),\n",
       " ('lentil', 11),\n",
       " ('jalapeno_pepper', 11),\n",
       " ('banana', 11),\n",
       " ('round_steak', 11),\n",
       " ('cheddar_cheese', 11),\n",
       " ('wine', 11),\n",
       " ('rosemary', 11),\n",
       " ('pineapple', 11),\n",
       " ('portobello_mushroom', 11),\n",
       " ('beef_part', 11),\n",
       " ('dried_onion', 11),\n",
       " ('skewer', 11),\n",
       " ('vegetarian_crumbles', 10),\n",
       " ('cheese', 10),\n",
       " ('ham', 10),\n",
       " ('milk_chocolate', 10),\n",
       " ('date', 10),\n",
       " ('carrot', 10),\n",
       " ('chicken_base', 10),\n",
       " ('cornflakes_cereal', 10),\n",
       " ('onion_powder', 10),\n",
       " ('cereal', 10),\n",
       " ('shiitake_mushroom', 10),\n",
       " ('lemon_juice', 10),\n",
       " ('pork_shoulder', 10),\n",
       " ('celery_root', 9),\n",
       " ('apple_jam', 9),\n",
       " ('spread_dip', 9),\n",
       " ('mixed_nut', 9),\n",
       " ('trout', 9),\n",
       " ('chicken_bouillon', 9),\n",
       " ('champagne', 9),\n",
       " ('corned_beef', 9),\n",
       " ('sauce', 9),\n",
       " ('kombu', 9),\n",
       " ('white_wine', 9),\n",
       " ('dried_currant', 9),\n",
       " ('whole_black_peppercorn', 9),\n",
       " ('toffee', 9),\n",
       " ('chorizo_sausage', 9),\n",
       " ('hoagie_roll', 9),\n",
       " ('beef_tri_tip', 9),\n",
       " ('salmon', 9),\n",
       " ('garbanzo_bean', 9),\n",
       " ('catfish', 9),\n",
       " ('fruit_juice', 9),\n",
       " ('mixed_baby_green', 9),\n",
       " ('baking_powder', 8),\n",
       " ('mint', 8),\n",
       " ('triple_sec', 8),\n",
       " ('whole_wheat_bread', 8),\n",
       " ('ground_nutmeg', 8),\n",
       " ('mustard', 8),\n",
       " ('gumdrop', 8),\n",
       " ('pork_chop', 8),\n",
       " ('candied_pineapple', 8),\n",
       " ('cashew', 8),\n",
       " ('lemonade', 8),\n",
       " ('egg_noodle', 8),\n",
       " ('gochujang', 8),\n",
       " ('ground_cinnamon', 8),\n",
       " ('thyme', 8),\n",
       " ('shrimp', 8),\n",
       " ('chive', 8),\n",
       " ('salsa', 8),\n",
       " ('bottom_round_roast', 8),\n",
       " ('sweet_potato', 8),\n",
       " ('whiskey', 8),\n",
       " ('seafood_stock', 7),\n",
       " ('cream_cheese', 7),\n",
       " ('mayonnaise', 7),\n",
       " ('ginger', 7),\n",
       " ('bacon', 7),\n",
       " ('apple', 7),\n",
       " ('white_onion', 7),\n",
       " ('pepper_jam', 7),\n",
       " ('irish_cream_liqueur', 7),\n",
       " ('dried_savory', 7),\n",
       " ('cooky', 7),\n",
       " ('rom_tomato', 7),\n",
       " ('nori', 7),\n",
       " ('curry_powder', 7),\n",
       " ('fettuccine_pasta', 7),\n",
       " ('tomato', 7),\n",
       " ('margarine', 7),\n",
       " ('black_walnut', 7),\n",
       " ('pistachio', 7),\n",
       " ('mixed_vegetable', 7),\n",
       " ('chipotle_pepper', 7),\n",
       " ('pea', 7),\n",
       " ('cherry_liqueur', 7),\n",
       " ('dried_sage', 7),\n",
       " ('chili_sauce', 7),\n",
       " ('orange', 7),\n",
       " ('plum', 7),\n",
       " ('evaporated_milk', 7),\n",
       " ('whole_milk', 7),\n",
       " ('yellow_bell_pepper', 7),\n",
       " ('sour_cream', 7),\n",
       " ('brioche', 6),\n",
       " ('french_fried_onion', 6),\n",
       " ('dried_cranberry', 6),\n",
       " ('coconut_extract', 6),\n",
       " ('pink_peppercorn', 6),\n",
       " ('semisweet_chocolate_chip', 6),\n",
       " ('whole_kernel_corn', 6),\n",
       " ('seasoning', 6),\n",
       " ('egg_white', 6),\n",
       " ('candied_citron', 6),\n",
       " ('crescent_roll', 6),\n",
       " ('candy_coated_chocolate', 6),\n",
       " ('buckwheat', 6),\n",
       " ('shortening', 6),\n",
       " ('dried_marjoram', 6),\n",
       " ('blueberry', 6),\n",
       " ('haddock', 6),\n",
       " ('sherry', 6),\n",
       " ('endive', 6),\n",
       " ('chili_powder', 6),\n",
       " ('grape_jam', 6),\n",
       " ('collard_green', 6),\n",
       " ('coconut', 6),\n",
       " ('chocolate_flavored_syrup', 6),\n",
       " (\"confectioners'_sugar\", 6),\n",
       " ('worcestershire_sauce', 6),\n",
       " ('ground_bison', 6),\n",
       " ('yukon_gold_potato', 6),\n",
       " ('bay_leaf', 6),\n",
       " ('beer', 6),\n",
       " ('soy_sauce', 6),\n",
       " ('ground_cumin', 6),\n",
       " ('beef_dripping', 6),\n",
       " ('cinnamon_stick', 5),\n",
       " ('chicken_stock', 5),\n",
       " ('rose_water', 5),\n",
       " ('edamame', 5),\n",
       " ('ground_ginger', 5),\n",
       " ('sweet_onion', 5),\n",
       " ('steak_seasoning', 5),\n",
       " ('red_potato', 5),\n",
       " ('raw_sugar', 5),\n",
       " ('sparkling_wine', 5),\n",
       " ('crabmeat', 5),\n",
       " ('squash', 5),\n",
       " ('zucchini', 5),\n",
       " ('ground_clove', 5),\n",
       " ('plain_yogurt', 5),\n",
       " ('wheat_cereal', 5),\n",
       " ('almond_meal', 5),\n",
       " ('tea', 5),\n",
       " ('frozen_whipped_topping', 5),\n",
       " ('dried_fig', 5),\n",
       " ('lemon_extract', 5),\n",
       " ('applesauce', 5),\n",
       " ('candy', 5),\n",
       " ('oatmeal', 5),\n",
       " ('yellow_squash', 5),\n",
       " ('heavy_cream', 5),\n",
       " ('pepper', 5),\n",
       " ('pork_loin', 5),\n",
       " ('prosciutto', 5),\n",
       " ('beef_stock', 5),\n",
       " ('apricot', 5),\n",
       " ('cucumber', 5),\n",
       " ('granny_smith_apple', 5),\n",
       " ('orange_juice', 5),\n",
       " ('smoked_sausage', 5),\n",
       " ('seedless_grape', 5),\n",
       " ('schnapps', 5),\n",
       " ('italian_salad_dressing', 5),\n",
       " ('bitter', 5),\n",
       " ('oregano', 5),\n",
       " ('prawn', 5),\n",
       " ('mango_nectar', 5),\n",
       " ('white_vinegar', 5),\n",
       " ('beef_sirloin', 5),\n",
       " ('herbes_de_provence', 5),\n",
       " ('barbeque_seasoning', 5),\n",
       " ('strawberry_jam', 5),\n",
       " ('cauliflower', 5),\n",
       " ('sucanat', 5),\n",
       " ('macaroni', 5),\n",
       " ('flavored_syrup', 5),\n",
       " ('ciabatta_roll', 5),\n",
       " ('sparkling_water', 5),\n",
       " ('beau_monde_seasoning', 5),\n",
       " ('chocolate_hazelnut_spread', 4),\n",
       " ('cherry_tomato', 4),\n",
       " ('soup_mix', 4),\n",
       " ('fire_roasted_tomato', 4),\n",
       " ('ground_white_pepper', 4),\n",
       " ('beef', 4),\n",
       " ('pepperoncini_pepper', 4),\n",
       " ('ranch_dressing', 4),\n",
       " ('maple_syrup', 4),\n",
       " ('himalayan_salt', 4),\n",
       " ('cracker', 4),\n",
       " ('cranberry_juice', 4),\n",
       " ('bulgur', 4),\n",
       " ('anise_liqueur', 4),\n",
       " ('whipped_topping', 4),\n",
       " ('avocado', 4),\n",
       " ('green_bean', 4),\n",
       " ('raspberry_jam', 4),\n",
       " ('seashell_pasta', 4),\n",
       " ('ground_turmeric', 4),\n",
       " ('turnip', 4),\n",
       " ('dried_cherry', 4),\n",
       " ('rolled_oat', 4),\n",
       " ('prune', 4),\n",
       " ('other_meat', 4),\n",
       " ('linguine_pasta', 4),\n",
       " ('stewed_tomato', 4),\n",
       " ('beef_tenderloin', 4),\n",
       " ('red_currant_jam', 4),\n",
       " ('tuna', 4),\n",
       " ('flower', 4),\n",
       " ('shallot', 4),\n",
       " ('browning_sauce', 4),\n",
       " ('dried_dill_weed', 4),\n",
       " ('honey', 4),\n",
       " ('wonton_wrapper', 4),\n",
       " ('ketchup', 4),\n",
       " ('farfalle_pasta', 4),\n",
       " ('bratwurst', 4),\n",
       " ('pineapple_juice', 4),\n",
       " ('chuck_roast', 4),\n",
       " ('red_wine_vinegar', 4),\n",
       " ('bread_crumb', 4),\n",
       " ('yam', 4),\n",
       " ('sourdough_bread', 4),\n",
       " ('raspberry_vinaigrette', 4),\n",
       " ('french_bread', 4),\n",
       " ('doughnut', 4),\n",
       " ('arugula', 4),\n",
       " ('lime_juice', 4),\n",
       " ('coconut_sugar', 4),\n",
       " ('spaghetti', 4),\n",
       " ('dinner_roll', 4),\n",
       " ('sherbet', 4),\n",
       " ('queso_fresco', 4),\n",
       " ('garlic_salt', 4),\n",
       " ('celery', 3),\n",
       " ('skirt_steak', 3),\n",
       " ('swordfish', 3),\n",
       " ('lime_zest', 3),\n",
       " ('stuffing', 3),\n",
       " ('maple_extract', 3),\n",
       " ('barley_cereal', 3),\n",
       " ('dry_active_yeast', 3),\n",
       " ('coconut_milk', 3),\n",
       " ('poppy_seed', 3),\n",
       " ('gummy_candy', 3),\n",
       " ('rutabaga', 3),\n",
       " ('parsnip', 3),\n",
       " ('cinnamon_candy', 3),\n",
       " ('apple_juice', 3),\n",
       " ('whole_clove', 3),\n",
       " ('topping', 3),\n",
       " ('black_bean', 3),\n",
       " ('tomato_sauce', 3),\n",
       " ('pear', 3),\n",
       " ('turkey_stock', 3),\n",
       " ('eggplant', 3),\n",
       " ('black_olive', 3),\n",
       " ('adobo_sauce', 3),\n",
       " ('vegetable_protein', 3),\n",
       " ('dried_apricot', 3),\n",
       " ('biscuit', 3),\n",
       " ('marshmallow', 3),\n",
       " ('spearmint', 3),\n",
       " ('cider_vinegar', 3),\n",
       " ('peach_nectar', 3),\n",
       " ('pancetta', 3),\n",
       " ('egg_yolk', 3),\n",
       " ('rice_vermicelli', 3),\n",
       " ('cranberry', 3),\n",
       " ('chicken_broth', 3),\n",
       " ('flavored_vodka', 3),\n",
       " ('bread_roll', 3),\n",
       " ('sunflower_seed', 3),\n",
       " ('sesame_seed', 3),\n",
       " ('sage', 3),\n",
       " ('green_olive', 3),\n",
       " ('marinade', 3),\n",
       " ('corn_tortilla', 3),\n",
       " ('monterey_jack_cheese', 3),\n",
       " ('chayote_squash', 3),\n",
       " ('tomato_paste', 3),\n",
       " ('cantaloupe', 3),\n",
       " ('animal_fat', 3),\n",
       " ('flatbread', 3),\n",
       " ('citric_acid_powder', 3),\n",
       " ('coffee_liqueur', 3),\n",
       " ('dijon_mustard', 3),\n",
       " ('mustard_green', 3),\n",
       " ('walleye', 3),\n",
       " ('cake', 3),\n",
       " ('mixed_fruit', 3),\n",
       " ('cornbread', 3),\n",
       " ('decorating_gel', 3),\n",
       " ('sea_bass', 3),\n",
       " ('artichoke', 2),\n",
       " ('sriracha_sauce', 2),\n",
       " ('almond_flour', 2),\n",
       " ('hawaiian_bread_roll', 2),\n",
       " ('skinless_boneless_chicken_breast', 2),\n",
       " ('barbeque_sauce', 2),\n",
       " ('dark_chocolate', 2),\n",
       " ('poultry_seasoning', 2),\n",
       " ('cassava_flour', 2),\n",
       " ('candied_citrus_peel', 2),\n",
       " ('masa_harina', 2),\n",
       " ('popcorn', 2),\n",
       " ('candied_orange_peel', 2),\n",
       " ('asparagus', 2),\n",
       " ('wood_chip', 2),\n",
       " ('fish_stock', 2),\n",
       " ('poblano_pepper', 2),\n",
       " ('espresso', 2),\n",
       " ('walnut', 2),\n",
       " ('pecan', 2),\n",
       " ('hazelnut_liqueur', 2),\n",
       " ('celery_salt', 2),\n",
       " ('ladyfinger', 2),\n",
       " ('mint_chocolate_chip', 2),\n",
       " ('oat_cereal', 2),\n",
       " ('lamb_shoulder', 2),\n",
       " ('semisweet_chocolate', 2),\n",
       " ('cocoa_powder', 2),\n",
       " ('sea_scallop', 2),\n",
       " ('cherry', 2),\n",
       " ('banana_liqueur', 2),\n",
       " ('angel_hair_pasta', 2),\n",
       " ('processed_cheese', 2),\n",
       " ('onion_salt', 2),\n",
       " ('cabbage', 2),\n",
       " ('vegetable_juice', 2),\n",
       " ('green_tomato', 2),\n",
       " ('roasted_red_pepper', 2),\n",
       " ('vermicelli_pasta', 2),\n",
       " ('maraschino_cherry', 2),\n",
       " ('low_fat_milk', 2),\n",
       " ('green_pea', 2),\n",
       " ('potato_chip', 2),\n",
       " ('romaine_lettuce', 2),\n",
       " ('tortellini', 2),\n",
       " ('veal', 2),\n",
       " ('hash_brown', 2),\n",
       " ('ground_mace', 2),\n",
       " ('kiwi', 2),\n",
       " ('gingersnap_cooky', 2),\n",
       " ('taco_sauce', 2),\n",
       " ('watermelon', 2),\n",
       " ('pierogies', 2),\n",
       " ('rice', 2),\n",
       " ('steak', 2),\n",
       " ('ground_lamb', 2),\n",
       " ('blackberry_jam', 2),\n",
       " ('soda', 2),\n",
       " ('dry_vermouth', 2),\n",
       " ('limeade', 2),\n",
       " ('raspberry_liqueur', 2),\n",
       " ('whole_wheat_tortilla', 2),\n",
       " ('sirloin', 2),\n",
       " ('huckleberry', 2),\n",
       " ('sweet_pickle', 2),\n",
       " ('corn_chip', 2),\n",
       " ('molasses', 2),\n",
       " ('ice', 2),\n",
       " ('habanero_pepper', 2),\n",
       " ('creme_fraiche', 2),\n",
       " ('tomato_puree', 2),\n",
       " ('jicama', 2),\n",
       " ('ground_pork', 2),\n",
       " ('dark_chocolate_chip', 2),\n",
       " ('absinthe_liqueur', 2),\n",
       " ('apple_cider', 2),\n",
       " ('thousand_island_dressing', 2),\n",
       " ('pesto', 2),\n",
       " ('okra', 2),\n",
       " ('caraway_seed', 2),\n",
       " ('fennel_seed', 2),\n",
       " ('aluminum_foil', 2),\n",
       " ('black_eyed_pea', 2),\n",
       " ('chocolate_chip', 2),\n",
       " ('white_chocolate', 2),\n",
       " ('dill', 2),\n",
       " ('rice_flour', 2),\n",
       " ('egg_substitute', 2),\n",
       " ('green_chile_pepper', 2),\n",
       " ('crystallized_ginger', 2),\n",
       " ('pita_bread', 2),\n",
       " ('cannellini_bean', 2),\n",
       " ('kale', 2),\n",
       " ('lard', 2),\n",
       " ('leek', 2),\n",
       " ('chili_oil', 2),\n",
       " ('dried_cilantro', 2),\n",
       " ('colby_cheese', 2),\n",
       " ('pigeon_pea', 2),\n",
       " ('jelly_bean', 2),\n",
       " ('liquid_smoke', 2),\n",
       " ('feta_cheese', 2),\n",
       " ('zucchini_blossom', 2),\n",
       " ('rice_vinegar', 2),\n",
       " ('pork_sausage', 2),\n",
       " ('pine_nut', 2),\n",
       " ('mirin', 2),\n",
       " ('white_fish', 2),\n",
       " ('bologna', 2),\n",
       " ('hot_dog_bun', 2),\n",
       " ('chickpea_flour', 2),\n",
       " ('flavored_gelatin', 2),\n",
       " ('sweet_pickle_relish', 2),\n",
       " ('hemp_seed', 2),\n",
       " ('papaya', 2),\n",
       " ('crouton', 2),\n",
       " ('rib_eye_steak', 2),\n",
       " ('smoked_paprika', 2),\n",
       " ('ground_coriander', 2),\n",
       " ('ground_chile_pepper', 2),\n",
       " ('kitchen_twine', 2),\n",
       " ('salami', 2),\n",
       " ('garlic_paste', 1),\n",
       " ('flavored_rum', 1),\n",
       " ('chicken_carcass', 1),\n",
       " ('key_lime_juice', 1),\n",
       " ('flounder', 1),\n",
       " ('rice_wine', 1),\n",
       " ('puff_pastry', 1),\n",
       " ('ground_allspice', 1),\n",
       " ('skim_milk', 1),\n",
       " ('licorice', 1),\n",
       " ('persimmon', 1),\n",
       " ('walnut_oil', 1),\n",
       " ('apricot_jam', 1),\n",
       " ('nut_butter', 1),\n",
       " ('mexican_crema', 1),\n",
       " ('orange_extract', 1),\n",
       " ('blackberry', 1),\n",
       " ('rice_cereal', 1),\n",
       " ('peppermint_extract', 1),\n",
       " ('peanut_butter', 1),\n",
       " ('apricot_nectar', 1),\n",
       " ('milk_chocolate_chip', 1),\n",
       " ('candy_cane', 1),\n",
       " ('corn_syrup', 1),\n",
       " ('light_cream', 1),\n",
       " ('chocolate_pudding_mix', 1),\n",
       " ('yellow_corn', 1),\n",
       " ('tapioca', 1),\n",
       " ('mussel', 1),\n",
       " ('teriyaki_sauce', 1),\n",
       " ('hominy', 1),\n",
       " ('amaranth', 1),\n",
       " ('tarragon', 1),\n",
       " ('firm_tofu', 1),\n",
       " ('raisin_bread', 1),\n",
       " ('pie_filling', 1),\n",
       " ('golden_delicious_apple', 1),\n",
       " ('cheese_tortellini', 1),\n",
       " ('snow_pea', 1),\n",
       " ('fajita_seasoning', 1),\n",
       " ('baby_carrot', 1),\n",
       " ('pork_roast', 1),\n",
       " ('cherry_pie_filling', 1),\n",
       " ('chicken_breast', 1),\n",
       " ('radicchio', 1),\n",
       " ('white_bean', 1),\n",
       " ('leg_of_lamb', 1),\n",
       " ('white_wine_vinegar', 1),\n",
       " ('biscuit_dough', 1),\n",
       " ('turkey', 1),\n",
       " ('whipped_cream', 1),\n",
       " ('ham_hock', 1),\n",
       " ('apple_butter', 1),\n",
       " ('other_fish', 1),\n",
       " ('drink_mix', 1),\n",
       " ('hot_chocolate_mix', 1),\n",
       " ('fava_bean', 1),\n",
       " ('chicken_drumstick', 1),\n",
       " ('corn', 1),\n",
       " ('sweetened_condensed_milk', 1),\n",
       " ('chocolate_cake_mix', 1),\n",
       " ('phyllo_dough', 1),\n",
       " ('noodle', 1),\n",
       " ('macintosh_apple', 1),\n",
       " ('canning_jar_with_lid_and_ring', 1),\n",
       " ('miso_paste', 1),\n",
       " ('picante_sauce', 1),\n",
       " ('peppermint_candy', 1),\n",
       " ('ear_corn', 1),\n",
       " ('kaffir_lime_leaf', 1),\n",
       " ('kimchi', 1),\n",
       " ('morel_mushroom', 1),\n",
       " ('chanterelle_mushroom', 1),\n",
       " ('garlic_pepper_seasoning', 1),\n",
       " ('celery_seed', 1),\n",
       " ('split_pea', 1),\n",
       " ('goose', 1),\n",
       " ('lamb_stew_meat', 1),\n",
       " ('whole_wheat_flour', 1),\n",
       " ('wheat_berry', 1),\n",
       " ('millet', 1),\n",
       " ('barley', 1),\n",
       " ('toothpick', 1),\n",
       " ('champagne_vinegar', 1),\n",
       " ('chocolate', 1),\n",
       " ('dr_pepper_soda', 1),\n",
       " ('soy_milk', 1),\n",
       " ('rib_roast', 1),\n",
       " ('sweet_and_sour_sauce', 1),\n",
       " ('caper', 1),\n",
       " ('candied_mixed_fruit', 1),\n",
       " ('mahi_mahi', 1),\n",
       " ('sour_cherry', 1),\n",
       " ('baby_corn', 1),\n",
       " ('steak_sauce', 1),\n",
       " ('dill_pickle_juice', 1),\n",
       " ('chile_pepper', 1),\n",
       " ('meat_tenderizer', 1),\n",
       " ('ricotta_cheese', 1),\n",
       " ('creamy_salad_dressing', 1),\n",
       " ('goat_cheese', 1),\n",
       " ('grapefruit', 1),\n",
       " ('spinach', 1),\n",
       " ('cola_soda', 1),\n",
       " ('pumpernickel_bread', 1),\n",
       " ('salt_pork', 1),\n",
       " ('beet', 1),\n",
       " ('greek_yogurt', 1),\n",
       " ('fennel', 1),\n",
       " ('serrano_pepper', 1),\n",
       " ('tomato_soup', 1),\n",
       " ('penne_pasta', 1),\n",
       " ('beef_consomme', 1),\n",
       " ('beef_brisket', 1),\n",
       " ('asiago_cheese', 1),\n",
       " ('other_milk', 1),\n",
       " ('mango', 1),\n",
       " ('pomegranate', 1),\n",
       " ('chia_seed', 1),\n",
       " ('maple_sugar', 1),\n",
       " ('creme_de_cacao_liqueur', 1),\n",
       " ('chocolate_ice_cream', 1),\n",
       " ('water_chestnut', 1),\n",
       " ('grape_leaf', 1),\n",
       " ('tortilla_chip', 1),\n",
       " ('baking_mix', 1),\n",
       " ('spanish_onion', 1),\n",
       " ('banana_pepper', 1),\n",
       " ('balsamic_vinegar', 1),\n",
       " ('dried_apple', 1),\n",
       " ('pickled_ginger', 1),\n",
       " ('dried_mixed_fruit', 1),\n",
       " ('blue_cheese_dressing', 1),\n",
       " ('mung_bean', 1),\n",
       " ('salt_free_seasoning', 1),\n",
       " (\"pig's_part\", 1),\n",
       " ('heart_of_palm', 1),\n",
       " ('eggnog', 1),\n",
       " ('superfine_sugar', 1),\n",
       " ('oyster_sauce', 1),\n",
       " ('coconut_flour', 1),\n",
       " ('enchilada_sauce', 1),\n",
       " ('new_potato', 1),\n",
       " ('chipotle_chile_pepper', 1),\n",
       " ('mexican_style_corn', 1),\n",
       " ('blackening_seasoning', 1),\n",
       " ('turkey_dripping', 1),\n",
       " ('russet_potato', 1),\n",
       " ('herb', 1),\n",
       " ('brown_rice', 1),\n",
       " ('rice_noodle', 1),\n",
       " ('white_rice', 1),\n",
       " ('melon', 1),\n",
       " ('scotch_whiskey', 1),\n",
       " ('cheese_sauce', 1),\n",
       " ('lamb_shank', 1),\n",
       " ('kaiser_roll', 1),\n",
       " ('pumpkin_pie_spice', 1),\n",
       " ('fusilli_pasta', 1),\n",
       " ('sugar', 1),\n",
       " ('southern_comfort_liqueur', 1),\n",
       " ('corn_flour', 1),\n",
       " ('citrus_soda', 1),\n",
       " ('clementine', 1),\n",
       " ('tofu', 1),\n",
       " ('mexican_cheese_blend', 1),\n",
       " ('mozzarella_cheese', 1),\n",
       " ('turkey_carcass', 1),\n",
       " ('sun_dried_tomato', 1),\n",
       " ('sweet_chocolate', 1),\n",
       " ('rose', 1),\n",
       " ('mustard_seed', 1),\n",
       " ('pumpkin_puree', 1),\n",
       " ('tequila', 1),\n",
       " ('liquid_amino', 1),\n",
       " ('canola_oil', 1),\n",
       " ('pearl_onion', 1),\n",
       " ('anise_seed', 1),\n",
       " ('asafoetida_powder', 1),\n",
       " ('pastry_flour', 1),\n",
       " ('cumin_seed', 1),\n",
       " ('unsalted_butter', 1),\n",
       " ('potato', 1),\n",
       " ('wheat', 1),\n",
       " ('buttery_cracker', 1),\n",
       " ('pizza', 1),\n",
       " ('coconut_amino', 1),\n",
       " ('chestnut', 1),\n",
       " ('escarole', 1),\n",
       " ('vanilla_ice_cream', 1),\n",
       " ('protein_powder', 1),\n",
       " ('garam_masala', 1),\n",
       " ('corn_cereal', 1),\n",
       " ('gluten_free_all_purpose_flour', 1),\n",
       " ('roasted_garlic', 1),\n",
       " ('sake', 1),\n",
       " ('peppercorn', 1),\n",
       " ('chutney', 1),\n",
       " ('gouda_cheese', 1),\n",
       " ('cassava', 1),\n",
       " ('coconut_flavored_rum', 1),\n",
       " ('pickle', 1),\n",
       " ('vegetable_stock', 1),\n",
       " ('caramel_topping', 1),\n",
       " ('duck', 1),\n",
       " ('butternut_squash', 1),\n",
       " ('raspberry_extract', 1),\n",
       " ('star_anise', 1),\n",
       " ('cardamom', 1),\n",
       " ('blood_orange', 1),\n",
       " ('beef_bouillon', 1),\n",
       " ('rye_bread', 1),\n",
       " ('pork_tenderloin', 1),\n",
       " ('nutritional_yeast', 1),\n",
       " ('porcini_mushroom', 1),\n",
       " ('milk_powder', 1),\n",
       " ('cornish_game_hen', 1)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ignore_flag = True\n",
    "\n",
    "if ignore_flag:    \n",
    "    # uncomment below to ignore some ingre\n",
    "    no_match_list_flat_2 = list(itertools.chain.from_iterable(matched_df2.no_match_after_ignore))\n",
    "else:\n",
    "    no_match_list_flat_2 = list(itertools.chain.from_iterable(matched_df2.no_match))\n",
    "\n",
    "count_no_match_2 = Counter(no_match_list_flat_2)\n",
    "count_no_match_2 = count_no_match_2.most_common()\n",
    "print(len(count_no_match_2))\n",
    "count_no_match_2 # ingre at least not matched in 1 recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d11b2750bfe4ab2b5817249b33bc122",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=57709.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dict_cluster_count_ignore = defaultdict(int)\n",
    "for i in tqdm(range(0,len(matched_df2))):\n",
    "    recipe_id = matched_df2.loc[i, 'recipe_id']\n",
    "    recipe = [dict_ingredient_clustername[ingre_id] for ingre_id in dict_recipe_ingredients[recipe_id]]\n",
    "    ignore_bean_flag = matched_df2.loc[i, 'ignore_bean_flag']\n",
    "    ignore_some_flag = matched_df2.loc[i, 'ignore_some_flag']\n",
    "    ignore_unsaltedbutter_flag = matched_df2.loc[i, 'ignore_unsaltedbutter_flag']\n",
    "    ignore_greenchile_flag = matched_df2.loc[i, 'ignore_greenchile_flag']\n",
    "    ignore_all_flag = matched_df2.loc[i, 'ignore_all_flag']\n",
    "    \n",
    "    for ingre in recipe:\n",
    "        if ((ingre in ignore_ingre_list) and (ignore_some_flag == True)) \\\n",
    "            or ((ingre == 'bean') and (ignore_bean_flag == True)) \\\n",
    "            or ((ingre == 'unsalted_butter') and (ignore_unsaltedbutter_flag == True))\\\n",
    "            or ((ingre == 'green_chile_pepper') and (ignore_greenchile_flag == True)) \\\n",
    "            or (ignore_all_flag == True):\n",
    "            continue\n",
    "        else:\n",
    "            dict_cluster_count_ignore[ingre] += 1 # this cluster appear +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3435c3b5076e49a8bd639db7682e732e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(4155, 762)\n",
      "There are 57709 recipes in total.\n",
      "There are 4155 recipes with at least 1 ingredient not matched.\n",
      "There are 762 unique ingredients not matched in at least 1 recipe out of 57709 recipes.\n",
      "There are 714 unique ingredients not matched in <= 20 % of its appearances.\n",
      "There are 48 unique ingredients not matched in > 20 % of its appearances.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Not matched in % of its appearances')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_no_match_unique_2 = set(no_match_list_flat_2)\n",
    "\n",
    "if ignore_flag == True:\n",
    "    matched_df_missing_2 = matched_df2.loc[:,['recipe_id', 'no_match_after_ignore']]\n",
    "    no_match_span_df_2 = pd.concat([pd.Series(row['recipe_id'], row['no_match_after_ignore']) for _, row in tqdm(matched_df_missing_2.iterrows())]).reset_index()\n",
    "    no_match_span_df_2.columns = ['missing_ingredient', 'recipe_id']\n",
    "    missing_matrix_2 = pd.pivot_table(no_match_span_df_2, values='missing_ingredient', index=['recipe_id'], columns=['missing_ingredient'], aggfunc=lambda x: len(x))\n",
    "    missing_matrix_2 = missing_matrix_2.fillna(0)\n",
    "    print(missing_matrix_2.shape) # row is each recipe, col is each (missing) ingre\n",
    "    missing_in_num_recipes_2 = [(col, col_sum) for col, col_sum in missing_matrix_2.sum().iteritems()]\n",
    "    missing_pct_2 = [(col, (col_sum / dict_cluster_count_ignore[col])*100) for (col, col_sum) in missing_in_num_recipes_2]\n",
    "else:    \n",
    "    matched_df_missing_2 = matched_df2.loc[:,['recipe_id', 'no_match']]\n",
    "    no_match_span_df_2 = pd.concat([pd.Series(row['recipe_id'], row['no_match']) for _, row in tqdm(matched_df_missing_2.iterrows())]).reset_index()\n",
    "    no_match_span_df_2.columns = ['missing_ingredient', 'recipe_id']\n",
    "    missing_matrix_2 = pd.pivot_table(no_match_span_df_2, values='missing_ingredient', index=['recipe_id'], columns=['missing_ingredient'], aggfunc=lambda x: len(x))\n",
    "    missing_matrix_2 = missing_matrix_2.fillna(0)\n",
    "    print(missing_matrix_2.shape) # row is each recipe, col is each (missing) ingre\n",
    "    missing_in_num_recipes_2 = [(col, col_sum) for col, col_sum in missing_matrix_2.sum().iteritems()]\n",
    "    missing_pct_2 = [(col, (col_sum / dict_cluster_count[col])*100) for (col, col_sum) in missing_in_num_recipes_2]\n",
    "\n",
    "\n",
    "thres_pct = 20\n",
    "print('There are', len(no_match_list), 'recipes in total.')\n",
    "print('There are', len(missing_matrix_2), 'recipes with at least 1 ingredient not matched.')\n",
    "print('There are', len(all_no_match_unique_2), 'unique ingredients not matched in at least 1 recipe out of',len(no_match_list),'recipes.')\n",
    "print('There are', len([col for col, pct in missing_pct_2 if pct <= thres_pct]), 'unique ingredients not matched in <=', thres_pct,'% of its appearances.')\n",
    "print('There are', len(all_no_match_unique_2) - len([col for col, pct in missing_pct_2 if pct <= thres_pct]), 'unique ingredients not matched in >', thres_pct,'% of its appearances.')\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [8, 4]\n",
    "\n",
    "plt.hist([pct for col, pct in missing_pct_2], density=False, bins=200)\n",
    "plt.ylabel('Count of ingredients')\n",
    "plt.xlabel('Not matched in % of its appearances') ### change to pct, not matched / all it appears， sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('beef_part', 44.0),\n",
       " ('gumdrop', 42.10526315789473),\n",
       " ('kombu', 40.909090909090914),\n",
       " ('mixed_spice', 40.74074074074074),\n",
       " ('brioche', 40.0),\n",
       " (\"confectioners'_coating\", 40.0),\n",
       " ('pink_peppercorn', 37.5),\n",
       " ('monosodium_glutamate', 36.36363636363637),\n",
       " ('red_snapper', 35.714285714285715),\n",
       " ('sparkling_wine', 35.714285714285715),\n",
       " ('potato_nugget', 34.92063492063492),\n",
       " ('ghee', 34.40860215053764),\n",
       " ('anise_liqueur', 33.33333333333333),\n",
       " ('beau_monde_seasoning', 33.33333333333333),\n",
       " ('beef_tri_tip', 33.33333333333333),\n",
       " ('bottom_round_roast', 33.33333333333333),\n",
       " ('flower', 30.76923076923077),\n",
       " ('wheat_gluten', 30.18867924528302),\n",
       " ('flatbread', 30.0),\n",
       " ('vinaigrette', 29.268292682926827),\n",
       " ('french_baguette', 29.1970802919708),\n",
       " ('butter_extract', 28.57142857142857),\n",
       " ('seafood_stock', 28.000000000000004),\n",
       " ('sucanat', 27.77777777777778),\n",
       " ('candied_pineapple', 27.586206896551722),\n",
       " ('beef_dripping', 27.27272727272727),\n",
       " ('rice_vermicelli', 27.27272727272727),\n",
       " ('doughnut', 26.666666666666668),\n",
       " ('ground_bison', 26.08695652173913),\n",
       " ('apple_jam', 25.71428571428571),\n",
       " ('orange_liqueur', 25.142857142857146),\n",
       " ('black_walnut', 25.0),\n",
       " ('candied_citron', 25.0),\n",
       " ('cherry_liqueur', 25.0),\n",
       " ('gochujang', 25.0),\n",
       " ('pepper_jam', 25.0),\n",
       " ('spearmint', 25.0),\n",
       " ('vegetarian_crumbles', 25.0),\n",
       " ('walleye', 25.0),\n",
       " ('buckwheat', 22.22222222222222),\n",
       " ('haddock', 22.22222222222222),\n",
       " ('mixed_salad_green', 21.29032258064516),\n",
       " ('pork', 21.25984251968504),\n",
       " ('red_currant_jam', 21.052631578947366),\n",
       " ('celery_root', 20.930232558139537),\n",
       " ('mixed_baby_green', 20.930232558139537),\n",
       " ('ciabatta_roll', 20.833333333333336),\n",
       " ('liqueur', 20.618556701030926)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls = [(col,pct) for col, pct in missing_pct_2 if pct > thres_pct]\n",
    "ls.sort(key=lambda x:x[1], reverse = True)\n",
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output stats file with the counts of mappings for each ingre cluster name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stats_file(has_review_data_only_flag = True, matched_df = matched_df2):\n",
    "    # Create dict to store the count of each mapping\n",
    "    dict_mapping_count = copy.deepcopy(dict_ingre_mapping)\n",
    "\n",
    "    for cluster, values in dict_mapping_count.items():\n",
    "        # initialize parent count\n",
    "        parent_list = values['parent']\n",
    "        values['parent'] = {}\n",
    "        for parent in parent_list:\n",
    "            values['parent'][parent] = 0\n",
    "\n",
    "        # initialize child count\n",
    "        child_list = values['child']\n",
    "        values['child'] = {}\n",
    "        for child in child_list:\n",
    "            values['child'][child] = 0\n",
    "\n",
    "        # initialize synonym count\n",
    "        synonym_list = values['synonym']\n",
    "        values['synonym'] = {}\n",
    "        for synonym in synonym_list:\n",
    "            values['synonym'][synonym] = 0\n",
    "\n",
    "        # initialize short term count\n",
    "        short_list = values['short']\n",
    "        values['short'] = {}\n",
    "        for short in short_list:\n",
    "            values['short'][short] = 0\n",
    "\n",
    "        # initialize full match count\n",
    "        values['full'] = 0\n",
    "\n",
    "        # initialize no match count\n",
    "        values['no'] = 0\n",
    "\n",
    "    for cluster_name,_ in dict_cluster_count.items():\n",
    "        if cluster_name not in dict_mapping_count.keys():\n",
    "            dict_mapping_count[cluster_name]['full'] = 0\n",
    "            dict_mapping_count[cluster_name]['no'] = 0\n",
    "            dict_mapping_count[cluster_name]['short'] = {}\n",
    "            dict_mapping_count[cluster_name]['parent'] = {}\n",
    "            dict_mapping_count[cluster_name]['synonym'] = {}\n",
    "            dict_mapping_count[cluster_name]['child'] = {}\n",
    "\n",
    "    # calculate the counts\n",
    "    for i in tqdm(range(0,len(matched_df2))):\n",
    "        row = matched_df2.iloc[i,:]\n",
    "        recipe_id = row.recipe_id\n",
    "\n",
    "        if ((has_review_data_only_flag == True) and (row.recipe_id in recipe_id_has_review_list)) \\\n",
    "            or (has_review_data_only_flag == False):\n",
    "\n",
    "            perfect_match = literal_eval(row.perfect_match)\n",
    "            partial_match = literal_eval(row.partial_match)\n",
    "            dict_match = row.dict_match\n",
    "            no_match = row.no_match\n",
    "\n",
    "            # count full match\n",
    "            for match in perfect_match:\n",
    "                dict_mapping_count[match]['full'] += 1\n",
    "\n",
    "            # count partial match\n",
    "            for match in partial_match:\n",
    "                cluster_name = match[0]\n",
    "                short_terms = match[1]\n",
    "                for short in short_terms:\n",
    "                    dict_mapping_count[cluster_name]['short'][short] += 1\n",
    "\n",
    "            # count parent, child, synonym match\n",
    "            for match in dict_match:\n",
    "                cluster_name = match[0]\n",
    "                matched_terms = match[1]\n",
    "                parents = dict_ingre_mapping[cluster_name]['parent']\n",
    "                childs = dict_ingre_mapping[cluster_name]['child']\n",
    "                synonyms = dict_ingre_mapping[cluster_name]['synonym']\n",
    "                for term in matched_terms:\n",
    "                    if term in parents:\n",
    "                        dict_mapping_count[cluster_name]['parent'][term] += 1\n",
    "                    elif term in childs:\n",
    "                        dict_mapping_count[cluster_name]['child'][term] += 1\n",
    "                    elif term in synonyms:\n",
    "                        dict_mapping_count[cluster_name]['synonym'][term] += 1\n",
    "                    else:\n",
    "                        print(\"error!\")\n",
    "\n",
    "            # count no match\n",
    "            for cluster_name in no_match:\n",
    "                dict_mapping_count[cluster_name]['no'] += 1\n",
    "        else:\n",
    "            # if the has_review_data_only_flag is True but the recipe id has no review data\n",
    "            continue\n",
    "\n",
    "\n",
    "    # create df storing the counts in dict_mapping_count\n",
    "    cluster_name_list = []\n",
    "    cluster_count_list = []\n",
    "    full_match_count_list = []\n",
    "    no_match_count_list = []\n",
    "    partial_match_count_list = []\n",
    "    partial_match_total_list = []\n",
    "    parent_match_count_list = []\n",
    "    parent_match_total_list = []\n",
    "    child_match_count_list = []\n",
    "    child_match_total_list = []\n",
    "    synonym_match_count_list = []\n",
    "    synonym_match_total_list = []\n",
    "\n",
    "    for cluster_name, values in dict_mapping_count.items():\n",
    "        cluster_name_list.append(cluster_name)\n",
    "        \n",
    "        if has_review_data_only_flag == True:\n",
    "            cluster_count_list.append(dict_cluster_count_has_review[cluster_name])\n",
    "        else:\n",
    "            cluster_count_list.append(dict_cluster_count[cluster_name])\n",
    "        full_match_count_list.append(values['full'])\n",
    "        no_match_count_list.append(values['no'])\n",
    "\n",
    "        partial_matches = values['short']\n",
    "        parent_matches = values['parent']\n",
    "        child_matches = values['child']\n",
    "        synonym_matches = values['synonym']\n",
    "\n",
    "        partial_match_total = 0\n",
    "        parent_match_total = 0\n",
    "        child_match_total = 0\n",
    "        synonym_match_total = 0\n",
    "\n",
    "        partial_matches_this_cluster = []\n",
    "        for term, value in partial_matches.items():\n",
    "            partial_matches_this_cluster.append([term, value])\n",
    "            partial_match_total += value\n",
    "\n",
    "        parent_matches_this_cluster = []\n",
    "        for term, value in parent_matches.items():\n",
    "            parent_matches_this_cluster.append([term, value])\n",
    "            parent_match_total += value\n",
    "\n",
    "        child_matches_this_cluster = []\n",
    "        for term, value in child_matches.items():\n",
    "            child_matches_this_cluster.append([term, value])\n",
    "            child_match_total += value\n",
    "\n",
    "        synonym_matches_this_cluster = []\n",
    "        for term, value in synonym_matches.items():\n",
    "            synonym_matches_this_cluster.append([term, value])\n",
    "            synonym_match_total += value\n",
    "\n",
    "        partial_match_count_list.append(partial_matches_this_cluster)\n",
    "        parent_match_count_list.append(parent_matches_this_cluster)\n",
    "        child_match_count_list.append(child_matches_this_cluster)\n",
    "        synonym_match_count_list.append(synonym_matches_this_cluster)\n",
    "\n",
    "        partial_match_total_list.append(partial_match_total)\n",
    "        parent_match_total_list.append(parent_match_total)\n",
    "        child_match_total_list.append(child_match_total)\n",
    "        synonym_match_total_list.append(synonym_match_total)\n",
    "\n",
    "    df_stats = pd.DataFrame({\n",
    "        'cluster_name': cluster_name_list,\n",
    "        'num_of_recipes': cluster_count_list,\n",
    "        'full_match_stat': full_match_count_list,\n",
    "        'no_match_stat': no_match_count_list,\n",
    "        'partial_match': partial_match_count_list,\n",
    "        'partial_match_stat': partial_match_total_list,\n",
    "        'parent_match': parent_match_count_list,\n",
    "        'parent_match_stat': parent_match_total_list,\n",
    "        'child_match': child_match_count_list,\n",
    "        'child_match_stat': child_match_total_list,\n",
    "        'synonym_match': synonym_match_count_list,\n",
    "        'synonym_match_stat': synonym_match_total_list,\n",
    "    })\n",
    "    \n",
    "    return df_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baaa4797c758475890c6952ba62d8a78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=57709.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "307f9aea929e410996f2543598645e77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=57709.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Note: Set has_review_data_only_flag true if we only want stats file for recipe data that has reviews\n",
    "#       if set as false, then the stats file of all recipes will be created\n",
    "\n",
    "df_stats = create_stats_file(has_review_data_only_flag = True, matched_df = matched_df2)\n",
    "df_stats.to_csv('OUTPUT_OF_FINAL_CODE/stats_directions_match_hasReview.csv')\n",
    "\n",
    "df_stats = create_stats_file(has_review_data_only_flag = False, matched_df = matched_df2)\n",
    "df_stats.to_csv('OUTPUT_OF_FINAL_CODE/stats_directions_match_all.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
